{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abstract-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from scipy.stats import skew, norm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "determined-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Jupyter\\\\CUAI\\\\3월_IMC\\\\Adv_IMC_train.csv')\n",
    "dtest = pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Jupyter\\\\CUAI\\\\3월_IMC\\\\Adv_IMC_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-principal",
   "metadata": {},
   "source": [
    "# Let's take a look into the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "comparable-aging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Product</th>\n",
       "      <th>TypeName</th>\n",
       "      <th>Inches</th>\n",
       "      <th>ScreenResolution</th>\n",
       "      <th>Cpu</th>\n",
       "      <th>Ram</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Gpu</th>\n",
       "      <th>OpSys</th>\n",
       "      <th>Weight</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP</td>\n",
       "      <td>250 G6</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1366x768</td>\n",
       "      <td>Intel Core i5 7200U 2.5GHz</td>\n",
       "      <td>4GB</td>\n",
       "      <td>500GB HDD</td>\n",
       "      <td>Intel HD Graphics 620</td>\n",
       "      <td>No OS</td>\n",
       "      <td>1.86kg</td>\n",
       "      <td>393.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Asus</td>\n",
       "      <td>X541NA (N3350/4GB/1TB/FHD/W10)</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Full HD 1920x1080</td>\n",
       "      <td>Intel Celeron Dual Core N3350 1.1GHz</td>\n",
       "      <td>4GB</td>\n",
       "      <td>1TB HDD</td>\n",
       "      <td>Intel HD Graphics 500</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>2kg</td>\n",
       "      <td>344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HP</td>\n",
       "      <td>15-AC110nv (i7-6500U/6GB/1TB/Radeon</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1366x768</td>\n",
       "      <td>Intel Core i7 6500U 2.5GHz</td>\n",
       "      <td>6GB</td>\n",
       "      <td>1TB HDD</td>\n",
       "      <td>AMD Radeon R5 M330</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>2.19kg</td>\n",
       "      <td>764.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell</td>\n",
       "      <td>Inspiron 7559</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>15.6</td>\n",
       "      <td>IPS Panel Touchscreen / 4K Ultra HD 3840x2160</td>\n",
       "      <td>Intel Core i7 6700HQ 2.6GHz</td>\n",
       "      <td>16GB</td>\n",
       "      <td>128GB SSD +  1TB HDD</td>\n",
       "      <td>Nvidia GeForce GTX 960M</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>2.72kg</td>\n",
       "      <td>1099.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Razer</td>\n",
       "      <td>Blade Stealth</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>12.5</td>\n",
       "      <td>IPS Panel 4K Ultra HD / Touchscreen 3840x2160</td>\n",
       "      <td>Intel Core i7 7500U 2.5GHz</td>\n",
       "      <td>16GB</td>\n",
       "      <td>512GB SSD</td>\n",
       "      <td>Intel HD Graphics 620</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>1.29kg</td>\n",
       "      <td>1799.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company                              Product   TypeName  Inches  \\\n",
       "0      HP                               250 G6   Notebook    15.6   \n",
       "1    Asus       X541NA (N3350/4GB/1TB/FHD/W10)   Notebook     NaN   \n",
       "2      HP  15-AC110nv (i7-6500U/6GB/1TB/Radeon   Notebook    15.6   \n",
       "3    Dell                        Inspiron 7559     Gaming    15.6   \n",
       "4   Razer                        Blade Stealth  Ultrabook    12.5   \n",
       "\n",
       "                                ScreenResolution  \\\n",
       "0                                       1366x768   \n",
       "1                              Full HD 1920x1080   \n",
       "2                                       1366x768   \n",
       "3  IPS Panel Touchscreen / 4K Ultra HD 3840x2160   \n",
       "4  IPS Panel 4K Ultra HD / Touchscreen 3840x2160   \n",
       "\n",
       "                                    Cpu   Ram                Memory  \\\n",
       "0            Intel Core i5 7200U 2.5GHz   4GB             500GB HDD   \n",
       "1  Intel Celeron Dual Core N3350 1.1GHz   4GB               1TB HDD   \n",
       "2            Intel Core i7 6500U 2.5GHz   6GB               1TB HDD   \n",
       "3           Intel Core i7 6700HQ 2.6GHz  16GB  128GB SSD +  1TB HDD   \n",
       "4            Intel Core i7 7500U 2.5GHz  16GB             512GB SSD   \n",
       "\n",
       "                       Gpu       OpSys  Weight   price  \n",
       "0    Intel HD Graphics 620       No OS  1.86kg   393.9  \n",
       "1    Intel HD Graphics 500  Windows 10     2kg   344.0  \n",
       "2       AMD Radeon R5 M330  Windows 10  2.19kg   764.0  \n",
       "3  Nvidia GeForce GTX 960M  Windows 10  2.72kg  1099.0  \n",
       "4    Intel HD Graphics 620  Windows 10  1.29kg  1799.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-alberta",
   "metadata": {},
   "source": [
    "### TypeName\n",
    "We can see 'TypeName' has the same values in the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "boolean-nursery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Notebook', 'Gaming', 'Ultrabook', '2 in 1 Convertible', 'Netbook', 'Workstation']\n",
      "['Notebook', 'Ultrabook', '2 in 1 Convertible', 'Gaming', 'Workstation', 'Netbook']\n"
     ]
    }
   ],
   "source": [
    "print(dtrain['TypeName'].unique().tolist())\n",
    "print(dtest['TypeName'].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-camping",
   "metadata": {},
   "source": [
    "### Inches\n",
    "We can use the 'Inches' feature by deleting the NaN values and changing the rest into floats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-baseball",
   "metadata": {},
   "source": [
    "### ScreenResolution\n",
    "In the 'ScreenResolution' column we can see that every value has a (number)x(number) at the end so he can take this value and store it in another column. Also we can find that there are a few words that repeatedly shows up in the values.\n",
    "\n",
    "For example) 'Full HD', 'Touchscreen', 'Quad HD+' etc.\n",
    "I believe that these words have meaning when it comes to predicting the prices of the laptops so we will process them into individual columns as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liked-picture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1366x768',\n",
       " 'Full HD 1920x1080',\n",
       " 'IPS Panel Touchscreen / 4K Ultra HD 3840x2160',\n",
       " 'IPS Panel 4K Ultra HD / Touchscreen 3840x2160',\n",
       " 'Touchscreen 2400x1600',\n",
       " 'IPS Panel Full HD 1920x1080',\n",
       " 'Full HD / Touchscreen 1920x1080',\n",
       " 'IPS Panel Retina Display 2304x1440',\n",
       " 'IPS Panel Quad HD+ / Touchscreen 3200x1800',\n",
       " 'Touchscreen 1366x768',\n",
       " 'IPS Panel Full HD / Touchscreen 1920x1080',\n",
       " '1600x900',\n",
       " 'IPS Panel Quad HD+ 2560x1440',\n",
       " '2560x1440',\n",
       " '4K Ultra HD 3840x2160',\n",
       " 'IPS Panel Full HD 1366x768',\n",
       " 'Touchscreen 2256x1504',\n",
       " 'Touchscreen 2560x1440',\n",
       " 'IPS Panel 4K Ultra HD 3840x2160',\n",
       " 'IPS Panel Retina Display 2880x1800',\n",
       " 'Quad HD+ / Touchscreen 3200x1800',\n",
       " 'IPS Panel 1366x768',\n",
       " 'IPS Panel 2560x1440',\n",
       " 'IPS Panel Retina Display 2560x1600',\n",
       " 'IPS Panel Touchscreen 1920x1200',\n",
       " 'Touchscreen / Quad HD+ 3200x1800',\n",
       " '1440x900',\n",
       " '4K Ultra HD / Touchscreen 3840x2160',\n",
       " 'Touchscreen / 4K Ultra HD 3840x2160',\n",
       " 'IPS Panel Retina Display 2736x1824',\n",
       " 'Touchscreen / Full HD 1920x1080',\n",
       " 'IPS Panel Full HD 2160x1440',\n",
       " 'IPS Panel Touchscreen 2560x1440',\n",
       " 'IPS Panel Touchscreen 1366x768',\n",
       " 'Quad HD+ 3200x1800',\n",
       " '1920x1080',\n",
       " 'IPS Panel Touchscreen 2400x1600',\n",
       " 'IPS Panel Quad HD+ 3200x1800']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain['ScreenResolution'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "identified-soldier",
   "metadata": {},
   "source": [
    "### Cpu\n",
    "We can see that the Cpu feature contains Intel and AMD Cpu's. Which we will have to convert into individual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exceptional-travel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Intel Core i5 7200U 2.5GHz',\n",
       " 'Intel Celeron Dual Core N3350 1.1GHz',\n",
       " 'Intel Core i7 6500U 2.5GHz',\n",
       " 'Intel Core i7 6700HQ 2.6GHz',\n",
       " 'Intel Core i7 7500U 2.5GHz',\n",
       " 'Intel Core i5 7300U 2.6GHz',\n",
       " 'Intel Core i5 7Y57 1.2GHz',\n",
       " 'Intel Core i7 8550U 1.8GHz',\n",
       " 'Intel Core i7 7700HQ 2.8GHz',\n",
       " 'Intel Core i7 6820HK 2.7GHz',\n",
       " 'Intel Core i5 6200U 2.3GHz',\n",
       " 'Intel Core M 1.2GHz',\n",
       " 'Intel Core i7 7500U 2.7GHz',\n",
       " 'Intel Core i3 7100U 2.4GHz',\n",
       " 'Intel Celeron Dual Core N3060 1.6GHz',\n",
       " 'AMD Ryzen 1600 3.2GHz',\n",
       " 'Intel Core i3 6006U 2GHz',\n",
       " 'AMD A4-Series 7210 2.2GHz',\n",
       " 'Intel Core i7 7820HQ 2.9GHz',\n",
       " 'Intel Core i5 8250U 1.6GHz',\n",
       " 'Intel Celeron Quad Core N3450 1.1GHz',\n",
       " 'Intel Celeron Dual Core 3205U 1.5GHz',\n",
       " 'Intel Core i5 1.6GHz',\n",
       " 'Intel Core i7 6500U 2.50GHz',\n",
       " 'Intel Core i5 7300HQ 2.5GHz',\n",
       " 'Intel Celeron Dual Core N3050 1.6GHz',\n",
       " 'Intel Atom X5-Z8350 1.44GHz',\n",
       " 'AMD A6-Series 9220 2.5GHz',\n",
       " 'Intel Atom x5-Z8350 1.44GHz',\n",
       " 'Intel Core M 6Y75 1.2GHz',\n",
       " 'Intel Core i7 7600U 2.8GHz',\n",
       " 'Intel Core i7 7660U 2.5GHz',\n",
       " 'AMD A10-Series A10-9620P 2.5GHz',\n",
       " 'Intel Core i3 6006U 2.0GHz',\n",
       " 'Intel Core M M7-6Y75 1.2GHz',\n",
       " 'Intel Core M 6Y30 0.9GHz',\n",
       " 'Intel Atom x5-Z8300 1.44GHz',\n",
       " 'AMD E-Series 7110 1.8GHz',\n",
       " 'Intel Core i3 6100U 2.1GHz',\n",
       " 'Intel Core i7 2.7GHz',\n",
       " 'Intel Core i7 7560U 2.4GHz',\n",
       " 'AMD A9-Series A9-9420 3GHz',\n",
       " 'Intel Core i7 6820HQ 2.7GHz',\n",
       " 'Intel Core i3 6100U 2.3GHz',\n",
       " 'Intel Pentium Quad Core N3710 1.6GHz',\n",
       " 'AMD A9-Series 9420 3GHz',\n",
       " 'Intel Core i7 7820HK 2.9GHz',\n",
       " 'Intel Core i7 7Y75 1.3GHz',\n",
       " 'Intel Celeron Dual Core N3350 2GHz',\n",
       " 'Intel Core i7 2.8GHz',\n",
       " 'Intel Celeron Quad Core N3710 1.6GHz',\n",
       " 'Intel Core i5 6300U 2.4GHz',\n",
       " 'Intel Core i7 6600U 2.6GHz',\n",
       " 'Intel Core i7 2.2GHz',\n",
       " 'AMD A10-Series 9620P 2.5GHz',\n",
       " 'AMD A6-Series A6-9220 2.5GHz',\n",
       " 'AMD Ryzen 1700 3GHz',\n",
       " 'AMD FX 8800P 2.1GHz',\n",
       " 'Intel Core i3 7130U 2.7GHz',\n",
       " 'Intel Core i5 2.0GHz',\n",
       " 'Intel Pentium Quad Core N4200 1.1GHz',\n",
       " 'Intel Atom x5-Z8550 1.44GHz',\n",
       " 'Intel Xeon E3-1505M V6 3GHz',\n",
       " 'Intel Core M 1.1GHz',\n",
       " 'Intel Core i5 7440HQ 2.8GHz',\n",
       " 'Intel Celeron Quad Core N3160 1.6GHz',\n",
       " 'AMD A8-Series 7410 2.2GHz',\n",
       " 'Intel Core i5 3.1GHz',\n",
       " 'Intel Core M m3-7Y30 2.2GHz',\n",
       " 'Intel Core i7 6920HQ 2.9GHz',\n",
       " 'Intel Core i5 1.8GHz',\n",
       " 'AMD A12-Series 9720P 3.6GHz',\n",
       " 'Intel Core i7 8650U 1.9GHz',\n",
       " 'Intel Core i5 2.3GHz',\n",
       " 'AMD A6-Series 9220 2.9GHz',\n",
       " 'AMD FX 9830P 3GHz',\n",
       " 'AMD A6-Series 7310 2GHz',\n",
       " 'Intel Core i5 7200U 2.50GHz',\n",
       " 'AMD A10-Series 9600P 2.4GHz',\n",
       " 'Intel Core i7 7700HQ 2.7GHz',\n",
       " 'Intel Celeron Dual Core 3855U 1.6GHz',\n",
       " 'Intel Core i3 6006U 2.2GHz',\n",
       " 'AMD A12-Series 9720P 2.7GHz',\n",
       " 'Intel Core i7 6560U 2.2GHz',\n",
       " 'AMD E-Series E2-9000e 1.5GHz',\n",
       " 'AMD E-Series 9000 2.2GHz',\n",
       " 'Intel Core M m7-6Y75 1.2GHz',\n",
       " 'Intel Core i5 7Y54 1.2GHz',\n",
       " 'Intel Core M M3-6Y30 0.9GHz',\n",
       " 'Intel Core M 6Y54 1.1GHz',\n",
       " 'Intel Core i5 7500U 2.7GHz',\n",
       " 'Intel Core i7 2.9GHz',\n",
       " 'AMD E-Series 6110 1.5GHz',\n",
       " 'AMD A9-Series 9410 2.9GHz',\n",
       " 'Intel Xeon E3-1535M v5 2.9GHz',\n",
       " 'Intel Pentium Quad Core N3700 1.6GHz',\n",
       " 'Samsung Cortex A72&A53 2.0GHz',\n",
       " 'Intel Pentium Dual Core N4200 1.1GHz',\n",
       " 'Intel Core M 7Y30 1.0GHz',\n",
       " 'Intel Core M m3 1.2GHz',\n",
       " 'Intel Core i5 6300HQ 2.3GHz',\n",
       " 'Intel Core i5 6440HQ 2.6GHz',\n",
       " 'Intel Core i5 7200U 2.70GHz']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain['Cpu'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-absolute",
   "metadata": {},
   "source": [
    "### Ram\n",
    "Ram can easily be processed by just deleting the 'GB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smart-purse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4GB', '6GB', '16GB', '8GB', '64GB', '12GB', '32GB', '2GB', '24GB']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain['Ram'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-ending",
   "metadata": {},
   "source": [
    "### Memory\n",
    "We can do the same stuff we did with the ScreenResolution column to the Memory column but just a little differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "inner-giving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['500GB HDD',\n",
       " '1TB HDD',\n",
       " '128GB SSD +  1TB HDD',\n",
       " '512GB SSD',\n",
       " '256GB SSD',\n",
       " '512GB SSD +  1TB HDD',\n",
       " '1TB SSD',\n",
       " '128GB SSD',\n",
       " '256GB SSD +  1TB HDD',\n",
       " '512GB Flash Storage',\n",
       " '128GB HDD',\n",
       " '180GB SSD',\n",
       " '256GB SSD +  1.0TB Hybrid',\n",
       " '2TB HDD',\n",
       " '32GB Flash Storage',\n",
       " '16GB SSD',\n",
       " '256GB Flash Storage',\n",
       " '512GB SSD +  512GB SSD',\n",
       " '128GB SSD +  2TB HDD',\n",
       " '16GB Flash Storage',\n",
       " '256GB SSD +  2TB HDD',\n",
       " '1TB SSD +  1TB HDD',\n",
       " '1.0TB Hybrid',\n",
       " '64GB Flash Storage',\n",
       " '128GB Flash Storage',\n",
       " '32GB SSD',\n",
       " '512GB SSD +  2TB HDD',\n",
       " '8GB SSD',\n",
       " '1.0TB HDD',\n",
       " '256GB SSD +  500GB HDD',\n",
       " '512GB SSD +  256GB SSD',\n",
       " '256GB SSD +  256GB SSD',\n",
       " '240GB SSD',\n",
       " '508GB Hybrid',\n",
       " '1TB HDD +  1TB HDD',\n",
       " '64GB SSD']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain['Memory'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innocent-dance",
   "metadata": {},
   "source": [
    "### Gpu\n",
    "basically the same thing as the Cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "julian-mortality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Intel HD Graphics 620',\n",
       " 'Intel HD Graphics 500',\n",
       " 'AMD Radeon R5 M330',\n",
       " 'Nvidia GeForce GTX 960M',\n",
       " 'Intel HD Graphics 615',\n",
       " 'Intel UHD Graphics 620',\n",
       " 'Nvidia GeForce GTX 1070',\n",
       " 'Nvidia GeForce GTX 980 ',\n",
       " 'Intel HD Graphics 520',\n",
       " 'AMD Radeon R5 M315',\n",
       " 'Intel HD Graphics 515',\n",
       " 'Nvidia GeForce GTX 1060',\n",
       " 'AMD Radeon R5 M420',\n",
       " 'AMD Radeon R5 M430',\n",
       " 'Nvidia GeForce GTX 980M',\n",
       " 'Intel HD Graphics 400',\n",
       " 'AMD Radeon RX 580',\n",
       " 'AMD Radeon R7 M445',\n",
       " 'AMD Radeon R3',\n",
       " 'Nvidia Quadro M2200M',\n",
       " 'AMD R17M-M1-70',\n",
       " 'Nvidia GeForce 930MX',\n",
       " 'Nvidia GeForce GTX 970M',\n",
       " 'Nvidia Quadro M520M',\n",
       " 'Intel HD Graphics',\n",
       " 'Intel HD Graphics 6000',\n",
       " 'Nvidia GeForce 920MX',\n",
       " 'Nvidia GeForce 940MX',\n",
       " 'Nvidia GeForce GTX 1050',\n",
       " 'Nvidia Quadro M1200',\n",
       " 'Intel HD Graphics 620 ',\n",
       " 'AMD R4 Graphics',\n",
       " 'AMD Radeon 520',\n",
       " 'AMD Radeon 530',\n",
       " 'Nvidia GeForce GTX 1050 Ti',\n",
       " 'AMD Radeon RX 550',\n",
       " 'Nvidia GeForce 930M',\n",
       " 'Intel Iris Plus Graphics 640',\n",
       " 'Nvidia GeForce 930MX ',\n",
       " 'Nvidia GeForce GTX 950M',\n",
       " 'AMD Radeon R2 Graphics',\n",
       " 'AMD Radeon Pro 455',\n",
       " 'Nvidia Quadro M620',\n",
       " 'Intel HD Graphics 405',\n",
       " 'AMD Radeon R5',\n",
       " 'Nvidia GeForce 920MX ',\n",
       " 'AMD Radeon Pro 555',\n",
       " 'Nvidia GeForce 920M',\n",
       " 'Nvidia GeForce MX150',\n",
       " 'Nvidia GeForce GTX 940MX',\n",
       " 'Intel Iris Pro Graphics',\n",
       " 'Nvidia GeForce GT 940MX',\n",
       " 'AMD Radeon RX 540',\n",
       " 'AMD Radeon R4 Graphics',\n",
       " 'AMD Radeon R9 M385',\n",
       " 'Intel Iris Graphics 540',\n",
       " 'Nvidia GeForce GTX1050 Ti',\n",
       " 'Nvidia Quadro M2200',\n",
       " 'Intel HD Graphics 5300',\n",
       " 'AMD Radeon R5 M420X',\n",
       " 'Nvidia Quadro M1000M',\n",
       " 'Nvidia GeForce GTX 960',\n",
       " 'Nvidia GeForce GTX 940M',\n",
       " 'Intel HD Graphics 505',\n",
       " 'Intel Iris Plus Graphics 650',\n",
       " 'Nvidia GeForce GTX 1050Ti',\n",
       " 'Nvidia GeForce GTX 1080',\n",
       " 'AMD Radeon R7 M440',\n",
       " 'Nvidia GTX 980 SLI',\n",
       " 'AMD Radeon 540',\n",
       " 'AMD Radeon R4',\n",
       " 'Nvidia Quadro M500M',\n",
       " 'Nvidia GeForce 920',\n",
       " 'Nvidia GeForce MX130',\n",
       " 'Nvidia GeForce GTX 1070M',\n",
       " 'AMD Radeon RX 560',\n",
       " 'Nvidia GeForce 150MX',\n",
       " 'AMD Radeon R7 M465',\n",
       " 'Intel HD Graphics 510',\n",
       " 'AMD Radeon R2',\n",
       " 'Nvidia GeForce GTX 960<U+039C>',\n",
       " 'Nvidia GeForce GTX 965M',\n",
       " 'Nvidia GeForce GTX1060',\n",
       " 'Nvidia GeForce GTX 1050M',\n",
       " 'AMD Radeon Pro 560',\n",
       " 'Nvidia GeForce GTX1080',\n",
       " 'AMD FirePro W4190M ',\n",
       " 'Nvidia Quadro M2000M',\n",
       " 'AMD Radeon R7 M460',\n",
       " 'Intel HD Graphics 630',\n",
       " 'Nvidia GeForce GTX 930MX',\n",
       " 'Nvidia Quadro M3000M',\n",
       " 'ARM Mali T860 MP4',\n",
       " 'Nvidia Quadro M620M',\n",
       " 'AMD Radeon R5 520',\n",
       " 'Nvidia Quadro 3000M',\n",
       " 'AMD FirePro W4190M',\n",
       " 'AMD Radeon R7',\n",
       " 'AMD FirePro W5130M',\n",
       " 'Intel Graphics 620',\n",
       " 'Nvidia GeForce 960M',\n",
       " 'Intel HD Graphics 530']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain['Gpu'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-heaven",
   "metadata": {},
   "source": [
    "### OpSys\n",
    "We can see that the values for the train data and the test data are different. So I got rid of the Android value because I considered it as noise(I also didn't want to waste a column just for the 'android' value) and dropped it. Then I put the Windows OS'/Mac OS' into 1 column with different integer values(ex: Windows7 = 1, Windows10 = 2 etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "auburn-saint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No OS',\n",
       " 'Windows 10',\n",
       " 'Chrome OS',\n",
       " 'Windows 7',\n",
       " 'Mac OS X',\n",
       " 'Linux',\n",
       " 'Windows 10 S',\n",
       " 'macOS',\n",
       " 'Android']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.OpSys.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "supported-extreme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Windows 10',\n",
       " 'No OS',\n",
       " 'Linux',\n",
       " 'Chrome OS',\n",
       " 'Windows 10 S',\n",
       " 'macOS',\n",
       " 'Windows 7']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest.OpSys.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-symposium",
   "metadata": {},
   "source": [
    "### Weight\n",
    "The Weight column can also be used by just deleting the 'Kg' and then changing it into a float just like what we did with the 'Ram'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cultural-dairy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.86kg\n",
       "1       2kg\n",
       "2    2.19kg\n",
       "3    2.72kg\n",
       "4    1.29kg\n",
       "Name: Weight, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain.Weight.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-heath",
   "metadata": {},
   "source": [
    "# Drop noise\n",
    "row 889 - has Samsung Cortex for Cpu and ARM Mali for Gpu(which is not in the test set and has nothing in common with the other index's)\n",
    "\n",
    "row 16, 287, 314, 920, 956 = Intel Core M without further info / 889 has Samsung Cortex for Cpu and ARM Mali for Gpu(which is not in the test set and has nothing in common with the other index's)\n",
    "\n",
    "row 219 contains 'Intel Iris Pro Graphics' which doesn't contain any information about its serial number nor generation.\n",
    "\n",
    "row 268 & 712 contains 'Android' in OpSys which doesn't exist in the test set and there are only 2 rows containing 'Android' so I assumed the two rows as noise and dropped them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "interpreted-working",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([268, 712], dtype=int64), array([9, 9], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(dtrain.values == 'Android')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "twelve-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.where(dtrain.values == 'Intel Iris Pro Graphics')\n",
    "#np.where(dtrain.values == 'Android')\n",
    "#dtrain.Gpu[219]\n",
    "#dtrain.OpSys[268]\n",
    "#dtrain.OpSys[712]\n",
    "dtrain.drop(dtrain.index[[16, 219, 268, 287, 314, 712, 889, 920, 956]], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-daniel",
   "metadata": {},
   "source": [
    "# Drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fitted-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dtrain.duplicated().sum()\n",
    "#dtrain.loc[dtrain.duplicated(keep='last'),:] # keep = first / last / False\n",
    "dtrain.drop_duplicates(keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-camping",
   "metadata": {},
   "source": [
    "# Drop NaN in Inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "comparable-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = dtrain.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-amount",
   "metadata": {},
   "source": [
    "# Reset index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "banned-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain.reset_index(drop=True, inplace=True) # reset the index to 0~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-repeat",
   "metadata": {},
   "source": [
    "# Skewed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "buried-string",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skewness: 1.282906\n",
      "Kurtosis: 2.516151\n"
     ]
    }
   ],
   "source": [
    "#skewness and kurtosis\n",
    "print(\"Skewness: %f\" % dtrain['price'].skew())\n",
    "print(\"Kurtosis: %f\" % dtrain['price'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "middle-japan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer range (low) of the distribution:\n",
      "[[-1.38226695]\n",
      " [-1.35664461]\n",
      " [-1.3507758 ]\n",
      " [-1.34648155]\n",
      " [-1.34089903]\n",
      " [-1.33216739]\n",
      " [-1.32959085]\n",
      " [-1.31069616]\n",
      " [-1.30353908]\n",
      " [-1.30353908]]\n",
      "\n",
      "outer range (high) of the distribution:\n",
      "[[2.88335265]\n",
      " [3.09090797]\n",
      " [3.37719116]\n",
      " [3.50573232]\n",
      " [3.60679029]\n",
      " [3.93687481]\n",
      " [4.02190092]\n",
      " [4.05854517]\n",
      " [4.65115138]\n",
      " [6.24002312]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#standardizing data\n",
    "\n",
    "price_scaled = StandardScaler().fit_transform(dtrain['price'][:,np.newaxis]);\n",
    "low_range = price_scaled[price_scaled[:,0].argsort()][:10]\n",
    "high_range= price_scaled[price_scaled[:,0].argsort()][-10:]\n",
    "\n",
    "print('outer range (low) of the distribution:')\n",
    "print(low_range)\n",
    "print('\\nouter range (high) of the distribution:')\n",
    "print(high_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "golden-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain['price'] = np.log1p(dtrain['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "explicit-swift",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5.978633\n",
       "1      6.639876\n",
       "2      7.003065\n",
       "3      7.495542\n",
       "4      7.155186\n",
       "         ...   \n",
       "994    6.908755\n",
       "995    6.684612\n",
       "996    6.445720\n",
       "997    6.747187\n",
       "998    6.173786\n",
       "Name: price, Length: 999, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-cathedral",
   "metadata": {},
   "source": [
    "# Combine train and test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "velvet-board",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = dtrain['price'].reset_index(drop=True)\n",
    "train = dtrain.drop(['price'], axis=1)\n",
    "test = dtest\n",
    "features = pd.concat([train, test]).reset_index(drop=True)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-heritage",
   "metadata": {},
   "source": [
    "# Preprocessing 'Cpu' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "typical-chicken",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CPU_transform(data):\n",
    "    \n",
    "    # Extract GHz from Cpu\n",
    "    data['Cpu'] = data[\"Cpu\"].str.replace(\" \", \"+\")\n",
    "    data['GHz'] = data[\"Cpu\"].str.replace(r\".+[+]\", \"\").str.replace(r\"GHz\", \"\").astype(float)\n",
    "    #-------------------------------------------------------------------------------------------\n",
    "    # Intel Xeon E3\n",
    "    data['Cpu_Xeon'] = data[\"Cpu\"].str.replace(r\"Intel[+]Xeon[+]E3[-]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\")\n",
    "    data['Cpu_Xeon'] = data['Cpu_Xeon'].replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    \n",
    "    # Intel Core M - 가격 / 출시 날짜를 고려하여 인코딩\n",
    "    data['Cpu_CoreM'] = data[\"Cpu\"].str.replace(r\"Intel[+]Core[+]M[+]\", \"\").str.replace(r\"M\\d[-]\", \"\").str.replace(r\"6Y30\", \"1\").str.replace(r\"6Y54\", \"1\").str.replace(r\"6Y75\", \"2\").str.replace(r\"7Y30\", \"3\")\n",
    "    data['Cpu_CoreM'] = data[\"Cpu_CoreM\"].str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    \n",
    "    # Intel Pentium Dual / Quad Core\n",
    "    data['Cpu_Pentium2'] = data[\"Cpu\"].str.replace(r\"Intel[+]Pentium[+]Dual[+]Core[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    data['Cpu_Pentium4'] = data[\"Cpu\"].str.replace(r\"Intel[+]Pentium[+]Quad[+]Core[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "\n",
    "    # Intel Atom\n",
    "    data['Cpu_Atom'] = data[\"Cpu\"].str.replace(r\"Intel[+]Atom[+]\\D\\d[-]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "\n",
    "    # Intel Celeron Dual / Quad Core\n",
    "    data['Cpu_Celeron2'] = data[\"Cpu\"].str.replace(r\"Intel[+]Celeron[+]Dual[+]Core[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    data['Cpu_Celeron4'] = data[\"Cpu\"].str.replace(r\"Intel[+]Celeron[+]Quad[+]Core[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "\n",
    "    # Intel Core i-series\n",
    "    data['Cpu_i3'] = data[\"Cpu\"].str.replace(r\"Intel[+]Core[+]i3[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    data['Cpu_i5'] = data[\"Cpu\"].str.replace(r\"Intel[+]Core[+]i5[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    data['Cpu_i7'] = data[\"Cpu\"].str.replace(r\"Intel[+]Core[+]i7[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "\n",
    "    # AMD_A Series\n",
    "    data['Cpu_AMD_A'] = data[\"Cpu\"].str.replace(r\"AMD[+]A\", \"\").str.replace(r\"[-].+[+].+[-]\", \"\").str.replace(r\"[-]\\D+[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "\n",
    "    # AMD Ryzen\n",
    "    data['Cpu_AMD_Ryzen'] = data[\"Cpu\"].str.replace(r\"AMD[+]Ryzen[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "\n",
    "    # AMD FX\n",
    "    data['Cpu_AMD_FX'] = data[\"Cpu\"].str.replace(r\"AMD[+]FX[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "\n",
    "    # AMD E-Series\n",
    "    data['Cpu_AMD_E'] = data[\"Cpu\"].str.replace(r\"AMD[+]E[-]\\D+\", \"\").str.replace(r\".+[-]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "chubby-remark",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = CPU_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-university",
   "metadata": {},
   "source": [
    "# Preprocessing 'Gpu' Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "seven-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPU_transform(data):\n",
    "    \n",
    "    # AMD R17M-M1-70 is the same as AMD Radeon R7 M530\n",
    "    data['Gpu'] = data[\"Gpu\"].str.replace(\"AMD R17M-M1-70\", \"AMD Radeon R7 M530\")\n",
    "    data['Gpu'] = data[\"Gpu\"].str.replace(\" \", \"+\")\n",
    "    \n",
    "    # Intel HD Graphics\n",
    "    # 참고문헌 - https://en.wikipedia.org/wiki/List_of_Intel_graphics_processing_units\n",
    "    for a in data[(data['Gpu'] == 'Intel+HD+Graphics') & ((data['Cpu'] == 'Intel+Atom+x5-Z8350+1.44GHz') | (data['Cpu'] == 'Intel+Atom+X5-Z8350+1.44GHz') | (data['Cpu'] == 'Intel+Celeron+Dual+Core+N3060+1.6GHz'))].index:\n",
    "        data['Gpu'][a] = data['Gpu'][a].replace('Intel+HD+Graphics', 'Intel+HD+Graphics+400')\n",
    "    for b in data[(data['Gpu'] == 'Intel+HD+Graphics') & (data['Cpu'] == 'Intel+Pentium+Quad+Core+N3710+1.6GHz')].index:\n",
    "        data['Gpu'][b] = data['Gpu'][b].replace('Intel+HD+Graphics', 'Intel+HD+Graphics+405')\n",
    "    for c in data[(data['Gpu'] == 'Intel+HD+Graphics') & ((data['Cpu'] == 'Intel+Core+i5+7200U+2.5GHz') | (data['Cpu'] == 'Intel+Core+i7+7600U+2.8GHz'))].index:\n",
    "        data['Gpu'][c] = data['Gpu'][c].replace('Intel+HD+Graphics', 'Intel+HD+Graphics+620')\n",
    "    # 남아 있는 Intel HD Graphics들은 전부 8세대이므로 묶어줍니다.\n",
    "    data['Gpu_HDG_default'] = data[\"Gpu\"].str.replace(r\"Intel[+]HD[+]Graphics\", \"\").replace(r'^\\s*$', 1, regex=True).str.replace(r\"[+].+\", \"\").replace(np.nan, 1, regex=True).str.replace(r\"\\D\", \"\").replace(np.nan, 1, regex=True).replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    data['Gpu_Intel_HD'] = data[\"Gpu\"].str.replace(r\"Intel[+]HD[+]Graphics[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    \n",
    "    # Intel UHD Graphics\n",
    "    data['Gpu_Intel_UHD'] = data[\"Gpu\"].str.replace(r\"Intel[+]UHD[+]\\D+[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    \n",
    "    # Intel Iris (default)/Plus\n",
    "    data['Gpu_Intel_Iris'] = data[\"Gpu\"].str.replace(r\"Intel[+]Iris[+]Plus[+]\\D+\", \"\").str.replace(r\"Intel[+]Iris[+]\\D+\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    \n",
    "    # Nvidia Geforce GTX_Ti\n",
    "    data['Gpu_Nvidia_GTX_Ti'] = data[\"Gpu\"].str.replace(r\"Nvidia[+]GeForce[+]GTX.+Ti\", \"1\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    \n",
    "    # Nvidia GeForce GTX_M\n",
    "    # Ti들을 미리 삭제\n",
    "    data['Gpu_Nvidia_GTX_M'] = data[\"Gpu\"].str.replace(r\"Nvidia[+]GeForce[+]GTX.+Ti\", \"0\") # Ti들을 미리 삭제\n",
    "    data['Gpu_Nvidia_GTX_M'] = data[\"Gpu_Nvidia_GTX_M\"].str.replace(r\"Nvidia[+]GeForce[+]GTX.+MX\", \"\")\n",
    "    data['Gpu_Nvidia_GTX_M'] = data[\"Gpu_Nvidia_GTX_M\"].str.replace(r\"Nvidia[+]GeForce[+]GTX[+]\", \"\")\n",
    "\n",
    "    data['Gpu_Nvidia_GTX_M'] = data[\"Gpu_Nvidia_GTX_M\"].str.replace(r\"[+].+\", \"\")\n",
    "    data['Gpu_Nvidia_GTX_M'] = data[\"Gpu_Nvidia_GTX_M\"].str.replace(r\"[^\\d+M]\", '')\n",
    "    data['Gpu_Nvidia_GTX_M1'] = data['Gpu_Nvidia_GTX_M'].str.split('M')\n",
    "\n",
    "    for i in range(len(data['Gpu_Nvidia_GTX_M'])):\n",
    "        if len(data['Gpu_Nvidia_GTX_M'].str.split('M')[i]) == 2:\n",
    "            data['Gpu_Nvidia_GTX_M1'][i] = data['Gpu_Nvidia_GTX_M'].str.split('M')[i][0]\n",
    "\n",
    "    data['Gpu_Nvidia_GTX_M'] = data['Gpu_Nvidia_GTX_M1'].str.replace(r\"[.+]\", '')\n",
    "    data['Gpu_Nvidia_GTX_M'] = data['Gpu_Nvidia_GTX_M'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    data['Gpu_Nvidia_GTX_M'] = data['Gpu_Nvidia_GTX_M'].fillna(0)\n",
    "    data['Gpu_Nvidia_GTX_M'] = data['Gpu_Nvidia_GTX_M'].astype(int)\n",
    "    \n",
    "    # Nvidia GeForce GTX_MX\n",
    "    # Ti들을 미리 삭제\n",
    "    data['Gpu_Nvidia_GTX_MX'] = data[\"Gpu\"].str.replace(r\"Nvidia[+]GeForce[+]GTX.+Ti\", \"0\") # Ti들을 미리 삭제\n",
    "    data['Gpu_Nvidia_GTX_MX'] = data[\"Gpu_Nvidia_GTX_MX\"].str.replace(r\"Nvidia[+]GeForce[+]GTX[+]\", \"\")\n",
    "\n",
    "    data['Gpu_Nvidia_GTX_MX'] = data[\"Gpu_Nvidia_GTX_MX\"].str.replace(r\"[+].+\", \"\")\n",
    "    data['Gpu_Nvidia_GTX_MX'] = data[\"Gpu_Nvidia_GTX_MX\"].str.replace(r\"[^\\d+MX]\", '')\n",
    "    data['Gpu_Nvidia_GTX_MX1'] = data['Gpu_Nvidia_GTX_MX'].str.split('MX')\n",
    "\n",
    "    for i in range(len(data['Gpu_Nvidia_GTX_MX'])):\n",
    "        if len(data['Gpu_Nvidia_GTX_MX'].str.split('MX')[i]) == 2:\n",
    "            data['Gpu_Nvidia_GTX_MX1'][i] = data['Gpu_Nvidia_GTX_MX'].str.split('M')[i][0]\n",
    "\n",
    "    data['Gpu_Nvidia_GTX_MX'] = data['Gpu_Nvidia_GTX_MX1'].str.replace(r\"[.+]\", '')\n",
    "    data['Gpu_Nvidia_GTX_MX'] = data['Gpu_Nvidia_GTX_MX'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "    data['Gpu_Nvidia_GTX_MX'] = data['Gpu_Nvidia_GTX_MX'].fillna(0)\n",
    "    data['Gpu_Nvidia_GTX_MX'] = data['Gpu_Nvidia_GTX_MX'].astype(int)\n",
    "    \n",
    "    # Nvidia GeForce GTX\n",
    "    # Ti들을 미리 삭제\n",
    "    data['Gpu_Nvidia_GTX'] = data[\"Gpu\"].str.replace(r\"Nvidia[+]GeForce[+]GTX.+Ti\", \"0\").str.replace(r\"Nvidia[+]GeForce[+]GTX.+MX?\", \"\").str.replace(r\"Nvidia[+]GeForce[+]GTX[+]?\", \"\").str.replace(r\"<.+>\", \"\")\n",
    "    # Nvidia GTX 980 SLI drop 하긴 아까운 데이터라 그냥 이렇게 처리\n",
    "    data['Gpu_Nvidia_GTX'] = data[\"Gpu_Nvidia_GTX\"].str.replace(r\"Nvidia[+]GTX[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D+\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    \n",
    "    # Nvidia GeForce GT\n",
    "    #GTX 들을 미리 삭제\n",
    "    data['Gpu_Nvidia_GT'] = data[\"Gpu\"].str.replace(r\"Nvidia[+]GeForce[+]GTX.+\", \"\").str.replace(r\"Nvidia[+]GeForce[+]GT[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D+\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    \n",
    "    # Nvidia Quadro\n",
    "    data['Gpu_Nvidia_Q'] = data[\"Gpu\"].str.replace(r\"Nvidia[+]Quadro[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D+\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    \n",
    "    # Nvidia GeForce(M, MX, default)구분없이\n",
    "    data['Gpu_Nvidia_MX'] = data[\"Gpu\"].str.replace(r\"Nvidia[+]GeForce[+]\", \"\").str.replace(r\"GT.+\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D+\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    \n",
    "    # AMD Radeon R_Series\n",
    "    data['Gpu_AMD_R'] = data[\"Gpu\"].str.replace(r\"AMD[+]Radeon[+]R\", \"\").str.replace(r\"AMD[+]FirePro.+\", \"\").str.replace(r\"Intel.+\", \"\").str.replace(r\"Nvidia.+\", \"\").str.replace(r\"[+]M\", \".\").str.replace(r\"X\", \"10\").str.replace(r\"[+]\", \".\").str.replace(r\"AMD.Radeon.+\", \"\").str.replace(r\"Graphics\", \"\").str.replace(r\"AMD.R\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(float)\n",
    "    \n",
    "    # AMD FirePro\n",
    "    data['Gpu_AMD_FP'] = data[\"Gpu\"].str.replace(r\"AMD[+]FirePro[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D+\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    \n",
    "    # AMD Pro\n",
    "    data['Gpu_AMD_Pro'] = data[\"Gpu\"].str.replace(r\"AMD[+]Radeon[+]Pro[+]\", \"\").str.replace(r\"[+].+\", \"\").str.replace(r\"\\D+\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "    \n",
    "    # AMD Radeon 이후에 숫자\n",
    "    data['Gpu_AMD_NUM'] = data[\"Gpu\"].str.replace(r\"AMD[+]Radeon[+]R.+\", \"\").str.replace(r\"AMD[+]Radeon[+]Pro.+\", \"\").str.replace(r\"AMD[+]Radeon[+]\", \"\").str.replace(r\"AMD[+]FirePro.+\", \"\").str.replace(r\"Intel.+\", \"\").str.replace(r\"Nvidia.+\", \"\").str.replace(r\"\\D+\", \"\").replace(r'^\\s*$', np.nan, regex=True).fillna(0).astype(int)\n",
    "\n",
    "    data = data.drop(['Gpu_Nvidia_GTX_M1','Gpu_Nvidia_GTX_MX1'],axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "legislative-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = GPU_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asian-nothing",
   "metadata": {},
   "source": [
    "# ScreenResolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "controversial-facial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SR_transform(data):\n",
    "    \n",
    "    data['SR_4K'] = data['ScreenResolution'].str.findall('.*4K Ultra HD.*')\n",
    "    data['SR_4K'] = data['SR_4K'].explode('SR_4K').str.replace(r'.+', '1').replace(np.nan, 0, regex=True).astype(int)\n",
    "\n",
    "    data['SR_Touch'] = data['ScreenResolution'].str.findall('.*Touchscreen.*')\n",
    "    data['SR_Touch'] = data['SR_Touch'].explode('SR_Touch').str.replace(r'.+', '1').replace(np.nan, 0, regex=True).astype(int)\n",
    "\n",
    "    data['SR_QuadHD'] = data['ScreenResolution'].str.findall('.*Quad HD.*')\n",
    "    data['SR_QuadHD'] = data['SR_QuadHD'].explode('SR_QuadHD').str.replace(r'.+', '1').replace(np.nan, 0, regex=True).astype(int)\n",
    "\n",
    "    data['SR_Retina'] = data['ScreenResolution'].str.findall('.*Retina Display.*')\n",
    "    data['SR_Retina'] = data['SR_Retina'].explode('SR_Retina').str.replace(r'.+', '1').replace(np.nan, 0, regex=True).astype(int)\n",
    "\n",
    "    data['SR_FullHD'] = data['ScreenResolution'].str.findall('.*Full HD.*')\n",
    "    data['SR_FullHD'] = data['SR_FullHD'].explode('SR_FullHD').str.replace(r'.+', '1').replace(np.nan, 0, regex=True).astype(int)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "broken-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = SR_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "rational-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Memory_transform(data):\n",
    "    \n",
    "    data['Memory'] = data['Memory'].astype(str).replace('\\.0', '', regex=True) \n",
    "    data[\"Memory\"] = data[\"Memory\"].str.replace('GB', '')\n",
    "    data[\"Memory\"] = data[\"Memory\"].str.replace('TB', '000')\n",
    "    SSD_HDD_FS_Hy = data[\"Memory\"].str.split(\"+\", n = 1, expand = True)\n",
    "    data[\"first\"]= SSD_HDD_FS_Hy[0]\n",
    "    data[\"first\"]= data[\"first\"].str.strip()\n",
    "    data[\"second\"]= SSD_HDD_FS_Hy[1]\n",
    "    data[\"HDD1\"] = data[\"first\"].apply(lambda data: 1 if \"HDD\" in data else 0)\n",
    "    data[\"SSD1\"] = data[\"first\"].apply(lambda data: 1 if \"SSD\" in data else 0)\n",
    "    data[\"Hybrid1\"] = data[\"first\"].apply(lambda data: 1 if \"Hybrid\" in data else 0)\n",
    "    data[\"Flash_Storage1\"] = data[\"first\"].apply(lambda data: 1 if \"Flash Storage\" in data else 0)\n",
    "    data['first'] = data['first'].str.replace(r'\\D', '')\n",
    "    data[\"second\"].fillna(\"0\", inplace = True)\n",
    "    data[\"HDD2\"] = data[\"second\"].apply(lambda data: 1 if \"HDD\" in data else 0)\n",
    "    data[\"SSD2\"] = data[\"second\"].apply(lambda data: 1 if \"SSD\" in data else 0)\n",
    "    data[\"Hybrid2\"] = data[\"second\"].apply(lambda data: 1 if \"Hybrid\" in data else 0)\n",
    "    data[\"Flash_Storage2\"] = data[\"second\"].apply(lambda data: 1 if \"Flash Storage\" in data else 0)\n",
    "    data['second'] = data['second'].str.replace(r'\\D', '')\n",
    "    data[\"first\"] = data[\"first\"].astype(int)\n",
    "    data[\"second\"] = data[\"second\"].astype(int)\n",
    "    data['HDD'] = data[\"first\"]*data['HDD1'] + data[\"second\"]*data['HDD2']\n",
    "    data['SSD'] = data[\"first\"]*data['SSD1'] + data[\"second\"]*data['SSD2']\n",
    "    data['Hybrid'] = data[\"first\"]*data['Hybrid1'] + data[\"second\"]*data['Hybrid2']\n",
    "    data['Flash_Storage'] = data[\"first\"]*data['Flash_Storage1'] + data[\"second\"]*data['Flash_Storage2']\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "abstract-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Memory_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "convinced-professional",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SR_XY_transform(data):\n",
    "    \n",
    "    SR = data[\"ScreenResolution\"].str.split(\"x\", n = 1, expand = True)\n",
    "    data[\"xres\"]= SR[0]\n",
    "    data[\"yres\"]= SR[1]\n",
    "    data[\"xres\"] = data['xres'].str.replace(r'\\D+.\\d?\\D+', '').astype(int)\n",
    "    data[\"yres\"] = data[\"yres\"].astype(int)\n",
    "    data[\"ScreenResolution\"]=(data[\"xres\"]*data[\"yres\"]).astype(int)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "respective-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = SR_XY_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "duplicate-planning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ram_transform(data):\n",
    "    \n",
    "    data[\"Ram\"] = data[\"Ram\"].str.replace('GB', '') ## remove 'GB'\n",
    "    data[\"Ram\"] = data[\"Ram\"].astype(int)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "mineral-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Ram_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fossil-basin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weight_transform(data):\n",
    "    \n",
    "    data[\"Weight\"] = data[\"Weight\"].str.replace('kg', '') ## remove 'kg'\n",
    "    data[\"Weight\"] = data[\"Weight\"].astype(float)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sensitive-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Weight_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "secret-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Drop_transform(data):\n",
    "    \n",
    "    data = data.drop(['Cpu', 'Gpu', 'Memory','first',\n",
    "                'second','HDD1','SSD1','Hybrid1','Flash_Storage1',\n",
    "                'HDD2','SSD2','Hybrid2','Flash_Storage2'],axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "juvenile-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Drop_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-adolescent",
   "metadata": {},
   "source": [
    "# Skewed data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "athletic-consciousness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inches : -0.3928637699786714\n",
      "ScreenResolution : 8.287261093618255\n",
      "Ram : 2.7142714072211556\n",
      "Weight : 1.1749102414430983\n",
      "GHz : -0.8602792756995731\n",
      "HDD : 0.8723019420763266\n",
      "SSD : 1.3859198286201797\n",
      "Hybrid : 11.3889012162699\n",
      "Flash_Storage : 10.229713218500967\n",
      "xres : 8.339105253062645\n",
      "yres : 2.1478910455470204\n"
     ]
    }
   ],
   "source": [
    "skewcolumn = ['Inches','ScreenResolution','Ram','Weight','GHz','HDD','SSD','Hybrid','Flash_Storage','xres','yres']\n",
    "for i in skewcolumn:\n",
    "    print('{} : {}'.format(i, features[i].skew()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "stupid-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "features['ScreenResolution'] = np.log1p(features['ScreenResolution'])\n",
    "features['Weight'] = np.log1p(features['Weight'])\n",
    "features['xres'] = np.log1p(features['xres'])\n",
    "features['yres'] = np.log1p(features['yres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "median-semester",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Product</th>\n",
       "      <th>TypeName</th>\n",
       "      <th>Inches</th>\n",
       "      <th>ScreenResolution</th>\n",
       "      <th>Ram</th>\n",
       "      <th>OpSys</th>\n",
       "      <th>Weight</th>\n",
       "      <th>GHz</th>\n",
       "      <th>Cpu_Xeon</th>\n",
       "      <th>...</th>\n",
       "      <th>SR_Touch</th>\n",
       "      <th>SR_QuadHD</th>\n",
       "      <th>SR_Retina</th>\n",
       "      <th>SR_FullHD</th>\n",
       "      <th>HDD</th>\n",
       "      <th>SSD</th>\n",
       "      <th>Hybrid</th>\n",
       "      <th>Flash_Storage</th>\n",
       "      <th>xres</th>\n",
       "      <th>yres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP</td>\n",
       "      <td>250 G6</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>15.6</td>\n",
       "      <td>13.863433</td>\n",
       "      <td>4</td>\n",
       "      <td>No OS</td>\n",
       "      <td>1.050822</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.220374</td>\n",
       "      <td>6.645091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP</td>\n",
       "      <td>15-AC110nv (i7-6500U/6GB/1TB/Radeon</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>15.6</td>\n",
       "      <td>13.863433</td>\n",
       "      <td>6</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>1.160021</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.220374</td>\n",
       "      <td>6.645091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dell</td>\n",
       "      <td>Inspiron 7559</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>15.6</td>\n",
       "      <td>15.931091</td>\n",
       "      <td>16</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>1.313724</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.253488</td>\n",
       "      <td>7.678326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Razer</td>\n",
       "      <td>Blade Stealth</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>12.5</td>\n",
       "      <td>15.931091</td>\n",
       "      <td>16</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>0.828552</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.253488</td>\n",
       "      <td>7.678326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell</td>\n",
       "      <td>Latitude 5480</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.544797</td>\n",
       "      <td>8</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>0.970779</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.560601</td>\n",
       "      <td>6.985642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>Dell</td>\n",
       "      <td>Inspiron 7378</td>\n",
       "      <td>2 in 1 Convertible</td>\n",
       "      <td>13.3</td>\n",
       "      <td>14.544797</td>\n",
       "      <td>12</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>0.955511</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.560601</td>\n",
       "      <td>6.985642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>HP</td>\n",
       "      <td>Probook 470</td>\n",
       "      <td>Notebook</td>\n",
       "      <td>17.3</td>\n",
       "      <td>14.544797</td>\n",
       "      <td>8</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>1.252763</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.560601</td>\n",
       "      <td>6.985642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>Dell</td>\n",
       "      <td>Precision 7720</td>\n",
       "      <td>Workstation</td>\n",
       "      <td>17.3</td>\n",
       "      <td>14.544797</td>\n",
       "      <td>16</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>1.486140</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.560601</td>\n",
       "      <td>6.985642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>Lenovo</td>\n",
       "      <td>Thinkpad T470p</td>\n",
       "      <td>Ultrabook</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.120161</td>\n",
       "      <td>8</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>0.993252</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.848153</td>\n",
       "      <td>7.273093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>Lenovo</td>\n",
       "      <td>Legion Y520-15IKBN</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>15.6</td>\n",
       "      <td>14.544797</td>\n",
       "      <td>8</td>\n",
       "      <td>Windows 10</td>\n",
       "      <td>1.252763</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.560601</td>\n",
       "      <td>6.985642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company                              Product            TypeName  Inches  \\\n",
       "0         HP                               250 G6            Notebook    15.6   \n",
       "1         HP  15-AC110nv (i7-6500U/6GB/1TB/Radeon            Notebook    15.6   \n",
       "2       Dell                        Inspiron 7559              Gaming    15.6   \n",
       "3      Razer                        Blade Stealth           Ultrabook    12.5   \n",
       "4       Dell                        Latitude 5480            Notebook    14.0   \n",
       "...      ...                                  ...                 ...     ...   \n",
       "1255    Dell                        Inspiron 7378  2 in 1 Convertible    13.3   \n",
       "1256      HP                          Probook 470            Notebook    17.3   \n",
       "1257    Dell                       Precision 7720         Workstation    17.3   \n",
       "1258  Lenovo                       Thinkpad T470p           Ultrabook    14.0   \n",
       "1259  Lenovo                   Legion Y520-15IKBN              Gaming    15.6   \n",
       "\n",
       "      ScreenResolution  Ram       OpSys    Weight  GHz  Cpu_Xeon  ...  \\\n",
       "0            13.863433    4       No OS  1.050822  2.5         0  ...   \n",
       "1            13.863433    6  Windows 10  1.160021  2.5         0  ...   \n",
       "2            15.931091   16  Windows 10  1.313724  2.6         0  ...   \n",
       "3            15.931091   16  Windows 10  0.828552  2.5         0  ...   \n",
       "4            14.544797    8  Windows 10  0.970779  2.6         0  ...   \n",
       "...                ...  ...         ...       ...  ...       ...  ...   \n",
       "1255         14.544797   12  Windows 10  0.955511  2.7         0  ...   \n",
       "1256         14.544797    8  Windows 10  1.252763  1.8         0  ...   \n",
       "1257         14.544797   16  Windows 10  1.486140  2.9         0  ...   \n",
       "1258         15.120161    8  Windows 10  0.993252  2.8         0  ...   \n",
       "1259         14.544797    8  Windows 10  1.252763  2.8         0  ...   \n",
       "\n",
       "      SR_Touch  SR_QuadHD  SR_Retina  SR_FullHD   HDD  SSD  Hybrid  \\\n",
       "0            0          0          0          0   500    0       0   \n",
       "1            0          0          0          0  1000    0       0   \n",
       "2            1          0          0          0  1000  128       0   \n",
       "3            1          0          0          0     0  512       0   \n",
       "4            0          0          0          1     0  256       0   \n",
       "...        ...        ...        ...        ...   ...  ...     ...   \n",
       "1255         1          0          0          1     0  256       0   \n",
       "1256         0          0          0          1     0  256       0   \n",
       "1257         0          0          0          1     0  256       0   \n",
       "1258         0          0          0          1     0  512       0   \n",
       "1259         0          0          0          1  1000  128       0   \n",
       "\n",
       "      Flash_Storage      xres      yres  \n",
       "0                 0  7.220374  6.645091  \n",
       "1                 0  7.220374  6.645091  \n",
       "2                 0  8.253488  7.678326  \n",
       "3                 0  8.253488  7.678326  \n",
       "4                 0  7.560601  6.985642  \n",
       "...             ...       ...       ...  \n",
       "1255              0  7.560601  6.985642  \n",
       "1256              0  7.560601  6.985642  \n",
       "1257              0  7.560601  6.985642  \n",
       "1258              0  7.848153  7.273093  \n",
       "1259              0  7.560601  6.985642  \n",
       "\n",
       "[1260 rows x 49 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-technical",
   "metadata": {},
   "source": [
    "# One-Hot Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "peaceful-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_TypeName(data):\n",
    "    TN = pd.get_dummies(data['TypeName'])\n",
    "    return TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "surface-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = one_hot_TypeName(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "apart-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_OpSys(data):\n",
    "    OS = pd.get_dummies(data['OpSys'])\n",
    "    \n",
    "    OS['Windows'] = OS['Windows 7'] + OS['Windows 10 S'] + OS['Windows 10']\n",
    "    OS = OS.drop(['Windows 7', 'Windows 10 S', 'Windows 10'], axis=1)\n",
    "    OS['MacOS'] = OS['Mac OS X']*1 + OS['macOS']*2 # macOS가 더 좋은 OS\n",
    "    OS = OS.drop(['Mac OS X', 'macOS'], axis=1)\n",
    "    return OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bearing-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "OS = one_hot_OpSys(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ancient-spoke",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HP',\n",
       " 'Dell',\n",
       " 'Razer',\n",
       " 'Google',\n",
       " 'LG',\n",
       " 'MSI',\n",
       " 'Asus',\n",
       " 'Acer',\n",
       " 'Lenovo',\n",
       " 'Toshiba',\n",
       " 'Apple',\n",
       " 'Vero',\n",
       " 'Mediacom',\n",
       " 'Samsung',\n",
       " 'Microsoft',\n",
       " 'Chuwi',\n",
       " 'Xiaomi',\n",
       " 'Huawei',\n",
       " 'Fujitsu']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.Company.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afraid-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_Company(data):\n",
    "    Company = pd.get_dummies(data['Company'])\n",
    "    return Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "peaceful-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "CP = one_hot_Company(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "empirical-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_Product(data):\n",
    "    Product = pd.get_dummies(data['Product'])\n",
    "    return Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "behavioral-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pr = one_hot_Product(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "colonial-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_dummy():\n",
    "    for i in TN.columns:\n",
    "        features[i] = TN[i]\n",
    "    for i in OS.columns:\n",
    "        features[i] = OS[i]\n",
    "    for i in CP.columns:\n",
    "        features[i] = CP[i]\n",
    "    for i in Pr.columns:\n",
    "        features[i] = Pr[i]\n",
    "\n",
    "input_dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "demographic-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "accepted-charm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Inches</th>\n",
       "      <th>ScreenResolution</th>\n",
       "      <th>Ram</th>\n",
       "      <th>Weight</th>\n",
       "      <th>GHz</th>\n",
       "      <th>Cpu_Xeon</th>\n",
       "      <th>Cpu_CoreM</th>\n",
       "      <th>Cpu_Pentium2</th>\n",
       "      <th>Cpu_Pentium4</th>\n",
       "      <th>Cpu_Atom</th>\n",
       "      <th>...</th>\n",
       "      <th>ZenBook UX430UN</th>\n",
       "      <th>ZenBook UX510UX-CN211T</th>\n",
       "      <th>ZenBook UX530UQ-PRO</th>\n",
       "      <th>Zenbook 3</th>\n",
       "      <th>Zenbook Flip</th>\n",
       "      <th>Zenbook UX330UA-AH5Q</th>\n",
       "      <th>Zenbook UX390UA</th>\n",
       "      <th>Zenbook UX410UA-GV027T</th>\n",
       "      <th>Zenbook UX430UA</th>\n",
       "      <th>Zenbook UX510UW-FI095T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.6</td>\n",
       "      <td>13.863433</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.050822</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.6</td>\n",
       "      <td>13.863433</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.160021</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.6</td>\n",
       "      <td>15.931091</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.313724</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.5</td>\n",
       "      <td>15.931091</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.828552</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.0</td>\n",
       "      <td>14.544797</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.970779</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>13.3</td>\n",
       "      <td>14.544797</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.955511</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>17.3</td>\n",
       "      <td>14.544797</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.252763</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>17.3</td>\n",
       "      <td>14.544797</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.486140</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>14.0</td>\n",
       "      <td>15.120161</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.993252</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>15.6</td>\n",
       "      <td>14.544797</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.252763</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows × 686 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Inches  ScreenResolution   Ram    Weight  GHz  Cpu_Xeon  Cpu_CoreM  \\\n",
       "0       15.6         13.863433   4.0  1.050822  2.5       0.0        0.0   \n",
       "1       15.6         13.863433   6.0  1.160021  2.5       0.0        0.0   \n",
       "2       15.6         15.931091  16.0  1.313724  2.6       0.0        0.0   \n",
       "3       12.5         15.931091  16.0  0.828552  2.5       0.0        0.0   \n",
       "4       14.0         14.544797   8.0  0.970779  2.6       0.0        0.0   \n",
       "...      ...               ...   ...       ...  ...       ...        ...   \n",
       "1255    13.3         14.544797  12.0  0.955511  2.7       0.0        0.0   \n",
       "1256    17.3         14.544797   8.0  1.252763  1.8       0.0        0.0   \n",
       "1257    17.3         14.544797  16.0  1.486140  2.9       0.0        0.0   \n",
       "1258    14.0         15.120161   8.0  0.993252  2.8       0.0        0.0   \n",
       "1259    15.6         14.544797   8.0  1.252763  2.8       0.0        0.0   \n",
       "\n",
       "      Cpu_Pentium2  Cpu_Pentium4  Cpu_Atom  ...  ZenBook UX430UN  \\\n",
       "0              0.0           0.0       0.0  ...              0.0   \n",
       "1              0.0           0.0       0.0  ...              0.0   \n",
       "2              0.0           0.0       0.0  ...              0.0   \n",
       "3              0.0           0.0       0.0  ...              0.0   \n",
       "4              0.0           0.0       0.0  ...              0.0   \n",
       "...            ...           ...       ...  ...              ...   \n",
       "1255           0.0           0.0       0.0  ...              0.0   \n",
       "1256           0.0           0.0       0.0  ...              0.0   \n",
       "1257           0.0           0.0       0.0  ...              0.0   \n",
       "1258           0.0           0.0       0.0  ...              0.0   \n",
       "1259           0.0           0.0       0.0  ...              0.0   \n",
       "\n",
       "      ZenBook UX510UX-CN211T  ZenBook UX530UQ-PRO  Zenbook 3  Zenbook Flip  \\\n",
       "0                        0.0                  0.0        0.0           0.0   \n",
       "1                        0.0                  0.0        0.0           0.0   \n",
       "2                        0.0                  0.0        0.0           0.0   \n",
       "3                        0.0                  0.0        0.0           0.0   \n",
       "4                        0.0                  0.0        0.0           0.0   \n",
       "...                      ...                  ...        ...           ...   \n",
       "1255                     0.0                  0.0        0.0           0.0   \n",
       "1256                     0.0                  0.0        0.0           0.0   \n",
       "1257                     0.0                  0.0        0.0           0.0   \n",
       "1258                     0.0                  0.0        0.0           0.0   \n",
       "1259                     0.0                  0.0        0.0           0.0   \n",
       "\n",
       "      Zenbook UX330UA-AH5Q  Zenbook UX390UA  Zenbook UX410UA-GV027T  \\\n",
       "0                      0.0              0.0                     0.0   \n",
       "1                      0.0              0.0                     0.0   \n",
       "2                      0.0              0.0                     0.0   \n",
       "3                      0.0              0.0                     0.0   \n",
       "4                      0.0              0.0                     0.0   \n",
       "...                    ...              ...                     ...   \n",
       "1255                   0.0              0.0                     0.0   \n",
       "1256                   0.0              0.0                     0.0   \n",
       "1257                   0.0              0.0                     0.0   \n",
       "1258                   0.0              0.0                     0.0   \n",
       "1259                   0.0              0.0                     0.0   \n",
       "\n",
       "      Zenbook UX430UA  Zenbook UX510UW-FI095T  \n",
       "0                 0.0                     0.0  \n",
       "1                 0.0                     0.0  \n",
       "2                 0.0                     0.0  \n",
       "3                 0.0                     0.0  \n",
       "4                 0.0                     0.0  \n",
       "...               ...                     ...  \n",
       "1255              0.0                     0.0  \n",
       "1256              0.0                     0.0  \n",
       "1257              0.0                     0.0  \n",
       "1258              0.0                     0.0  \n",
       "1259              0.0                     0.0  \n",
       "\n",
       "[1260 rows x 686 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "continental-curve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inches                    float64\n",
       "ScreenResolution          float64\n",
       "Ram                         int32\n",
       "Weight                    float64\n",
       "GHz                       float64\n",
       "                           ...   \n",
       "Zenbook UX330UA-AH5Q        uint8\n",
       "Zenbook UX390UA             uint8\n",
       "Zenbook UX410UA-GV027T      uint8\n",
       "Zenbook UX430UA             uint8\n",
       "Zenbook UX510UW-FI095T      uint8\n",
       "Length: 686, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "oriental-facial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Inches',\n",
       " 'ScreenResolution',\n",
       " 'Ram',\n",
       " 'Weight',\n",
       " 'GHz',\n",
       " 'Cpu_Xeon',\n",
       " 'Cpu_CoreM',\n",
       " 'Cpu_Pentium2',\n",
       " 'Cpu_Pentium4',\n",
       " 'Cpu_Atom',\n",
       " 'Cpu_Celeron2',\n",
       " 'Cpu_Celeron4',\n",
       " 'Cpu_i3',\n",
       " 'Cpu_i5',\n",
       " 'Cpu_i7',\n",
       " 'Cpu_AMD_A',\n",
       " 'Cpu_AMD_Ryzen',\n",
       " 'Cpu_AMD_FX',\n",
       " 'Cpu_AMD_E',\n",
       " 'Gpu_HDG_default',\n",
       " 'Gpu_Intel_HD',\n",
       " 'Gpu_Intel_UHD',\n",
       " 'Gpu_Intel_Iris',\n",
       " 'Gpu_Nvidia_GTX_Ti',\n",
       " 'Gpu_Nvidia_GTX_M',\n",
       " 'Gpu_Nvidia_GTX_MX',\n",
       " 'Gpu_Nvidia_GTX',\n",
       " 'Gpu_Nvidia_GT',\n",
       " 'Gpu_Nvidia_Q',\n",
       " 'Gpu_Nvidia_MX',\n",
       " 'Gpu_AMD_R',\n",
       " 'Gpu_AMD_FP',\n",
       " 'Gpu_AMD_Pro',\n",
       " 'Gpu_AMD_NUM',\n",
       " 'SR_4K',\n",
       " 'SR_Touch',\n",
       " 'SR_QuadHD',\n",
       " 'SR_Retina',\n",
       " 'SR_FullHD',\n",
       " 'HDD',\n",
       " 'SSD',\n",
       " 'Hybrid',\n",
       " 'Flash_Storage',\n",
       " 'xres',\n",
       " 'yres',\n",
       " '2 in 1 Convertible',\n",
       " 'Gaming',\n",
       " 'Netbook',\n",
       " 'Notebook',\n",
       " 'Ultrabook',\n",
       " 'Workstation',\n",
       " 'Chrome OS',\n",
       " 'Linux',\n",
       " 'No OS',\n",
       " 'Windows',\n",
       " 'MacOS',\n",
       " 'Acer',\n",
       " 'Apple',\n",
       " 'Asus',\n",
       " 'Chuwi',\n",
       " 'Dell',\n",
       " 'Fujitsu',\n",
       " 'Google',\n",
       " 'HP',\n",
       " 'Huawei',\n",
       " 'LG',\n",
       " 'Lenovo',\n",
       " 'MSI',\n",
       " 'Mediacom',\n",
       " 'Microsoft',\n",
       " 'Razer',\n",
       " 'Samsung',\n",
       " 'Toshiba',\n",
       " 'Vero',\n",
       " 'Xiaomi',\n",
       " '110-15ACL (A6-7310/4GB/500GB/W10)',\n",
       " '14-am079na (N3710/8GB/2TB/W10)',\n",
       " '15-AC110nv (i7-6500U/6GB/1TB/Radeon',\n",
       " '15-AY023na (N3710/8GB/2TB/W10)',\n",
       " '15-BA015wm (E2-7110/4GB/500GB/W10)',\n",
       " '15-BS026nv (i5-7200U/8GB/256GB/Radeon',\n",
       " '15-BS028nv (i3-6006U/4GB/1TB/Radeon',\n",
       " '15-BS078nr (i7-7500U/8GB/1TB/W10)',\n",
       " '15-BS101nv (i7-8550U/8GB/256GB/FHD/W10)',\n",
       " '15-BS103nv (i5-8250U/6GB/256GB/Radeon',\n",
       " '15-BW004nv (A9-9420/4GB/256GB/Radeon',\n",
       " '15-BW037na (A9-9420/4GB/1TB/Radeon',\n",
       " '15-BW091ND (A9-9420/6GB/1TB',\n",
       " '15-BW094nd (A6-9220/8GB/128GB/W10)',\n",
       " '15-ay047nv (i3-6006U/6GB/1TB/Radeon',\n",
       " '15-ba043na (A12-9700P/8GB/2TB/W10)',\n",
       " '15-bs002nv (i3-6006U/4GB/128GB/FHD/W10)',\n",
       " '15-bs005nv (i3-6006U/4GB/1TB',\n",
       " '15-bs011nv (i7-7500U/4GB/500GB/Radeon',\n",
       " '15-bs012nv (i7-7500U/8GB/1TB/Radeon',\n",
       " '15-bs015dx (i5-7200U/8GB/1TB/W10)',\n",
       " '15-bs017nv (i7-7500U/8GB/256GB/Radeon',\n",
       " '15-bs018nq (i3-6006U/4GB/500GB/FHD/No',\n",
       " '15-bs023nv (i3-6006U/4GB/1TB/FHD/W10)',\n",
       " '15-bs024nv (i5-7200U/8GB/128GB/W10)',\n",
       " '15-bs025nv (i5-7200U/8GB/256GB/W10)',\n",
       " '15-bs053od (i7-7500U/6GB/1TB/W10)',\n",
       " '15-bs078cl (i7-7500U/8GB/2TB/W10)',\n",
       " '15-bs190od (i5-8250U/4GB/1TB/W10)',\n",
       " '15-bw000nv (E2-9000e/4GB/500GB/Radeon',\n",
       " '15-bw002nv (A6-9220/4GB/256GB/Radeon',\n",
       " '15-bw003nv (A9-Series-9420/4GB/256GB/FHD/W10)',\n",
       " '15-bw007nv (A10-9620P/6GB/128GB/Radeon',\n",
       " '15-bw009nv (A12-9720P/6GB/1TB/Radeon',\n",
       " '15-bw011nv (A6-9220/4GB/1TB/FHD/W10)',\n",
       " '15-cb003na (i5-7300HQ/8GB/1TB',\n",
       " '15-cd005nv (A9-9420/6GB/256GB/Radeon',\n",
       " '15-ra044nv (N3060/4GB/500GB/W10)',\n",
       " '15-rb013nv (E2-9000e/4GB/500GB/W10)',\n",
       " '17-AK091ND (A9-9420/8GB/1TB/W10)',\n",
       " '17-BS037cl (i3-6006U/8GB/1TB/W10)',\n",
       " '17-BS092ND (i3-6006U/8GB/256GB/W10)',\n",
       " '17-X047na (i3-6006U/8GB/1TB/W10)',\n",
       " '17-Y002nv (A10-9600P/6GB/2TB/Radeon',\n",
       " '17-ak001nv (A6-9220/4GB/500GB/Radeon',\n",
       " '17-ak002nv (A10-9620P/6GB/2TB/Radeon',\n",
       " '17-bs000nv I3',\n",
       " '250 G4',\n",
       " '250 G5',\n",
       " '250 G6',\n",
       " '255 G6',\n",
       " '320-15ISK (i3-6006U/4GB/1TB/GeForce',\n",
       " 'A541NA-GO342 (N3350/4GB/500GB/Linux)',\n",
       " 'A715-71G-59DH (i5-7300HQ/8GB/1TB/GeForce',\n",
       " 'Alienware 15',\n",
       " 'Alienware 17',\n",
       " 'Aspire 1',\n",
       " 'Aspire 3',\n",
       " 'Aspire 5',\n",
       " 'Aspire 7',\n",
       " 'Aspire A315-31',\n",
       " 'Aspire A315-51',\n",
       " 'Aspire A515-51G',\n",
       " 'Aspire A515-51G-32MX',\n",
       " 'Aspire A515-51G-37JS',\n",
       " 'Aspire A515-51G-59QF',\n",
       " 'Aspire A517-51G',\n",
       " 'Aspire A715-71G',\n",
       " 'Aspire E5-475',\n",
       " 'Aspire E5-575',\n",
       " 'Aspire E5-576G',\n",
       " 'Aspire E5-774G',\n",
       " 'Aspire ES1-523',\n",
       " 'Aspire ES1-531',\n",
       " 'Aspire ES1-533',\n",
       " 'Aspire ES1-572',\n",
       " 'Aspire F5-573G',\n",
       " 'Aspire F5-573G-510L',\n",
       " 'Aspire R7',\n",
       " 'Aspire VX5-591G',\n",
       " 'B51-80 (i5-6200U/8GB/1008GB/Radeon',\n",
       " 'B51-80 (i5-6200U/8GB/1TB/Radeon',\n",
       " 'B51-80 (i7-6500U/4GB/1008GB/FHD/W7)',\n",
       " 'B51-80 (i7-6500U/8GB/1008GB/Radeon',\n",
       " 'Blade Pro',\n",
       " 'Blade Stealth',\n",
       " 'C740-C9QX (3205U/2GB/32GB/Chrome',\n",
       " 'CB5-132T-C9KK (N3160/4GB/32GB/Chrome',\n",
       " 'Chromebook 11',\n",
       " 'Chromebook 13',\n",
       " 'Chromebook 14',\n",
       " 'Chromebook 3',\n",
       " 'Chromebook C202SA',\n",
       " 'Chromebook C731-C78G',\n",
       " 'Chromebook C738T-C2EJ',\n",
       " 'Chromebook C910-C2ST',\n",
       " 'Chromebook CB5-571-C1DZ',\n",
       " 'Chromebook Flip',\n",
       " 'Chromebook N23',\n",
       " 'Chromebook X360',\n",
       " 'E402WA-GA007T (E2-6110/4GB/64GB/W10',\n",
       " 'E402WA-GA010T (E2-6110/2GB/32GB/W10)',\n",
       " 'E5 774G',\n",
       " 'ENVY -',\n",
       " 'ES1-523-84K7 (A8-7410/8GB/256GB/FHD/W10)',\n",
       " 'EliteBook 1030',\n",
       " 'EliteBook 1040',\n",
       " 'EliteBook 820',\n",
       " 'EliteBook 840',\n",
       " 'EliteBook 850',\n",
       " 'EliteBook Folio',\n",
       " 'EliteBook x360',\n",
       " 'Elitebook 1040',\n",
       " 'Elitebook 820',\n",
       " 'Elitebook 840',\n",
       " 'Elitebook 850',\n",
       " 'Elitebook Folio',\n",
       " 'Envy 13-AB002nv',\n",
       " 'Envy 13-AB020nr',\n",
       " 'Envy 13-AB077cl',\n",
       " 'Envy 13-AD007nv',\n",
       " 'Envy 13-ad009n',\n",
       " 'Envy 17-U275cl',\n",
       " 'Envy x360',\n",
       " 'Extensa EX2540',\n",
       " 'Extensa EX2540-58KR',\n",
       " 'F756UX-T4201D (i7-7500U/8GB/128GB',\n",
       " 'FX502VM-AS73 (i7-7700HQ/16GB/1TB',\n",
       " 'FX502VM-DM105T (i7-6700HQ/8GB/1TB/GeForce',\n",
       " 'FX502VM-DM560T (i7-7700HQ/8GB/1TB',\n",
       " 'FX503VD-E4022T (i7-7700HQ/8GB/1TB/GeForce',\n",
       " 'FX503VM-E4007T (i7-7700HQ/16GB/1TB',\n",
       " 'FX550IK-DM018T (FX-9830P/8GB/1TB/Radeon',\n",
       " 'FX553VD-DM627T (i5-7300HQ/8GB/1TB',\n",
       " 'FX553VD-FY647T (i7-7700HQ/8GB/256GB/GeForce',\n",
       " 'FX753VD-GC007T (i7-7700HQ/8GB/1TB',\n",
       " 'FX753VD-GC071T (i7-7700HQ/8GB/1TB/GeForce',\n",
       " 'FX753VD-GC086T (i5-7300HQ/8GB/1TB',\n",
       " 'FX753VD-GC461T (i7-7700HQ/16GB/1TB',\n",
       " 'FX753VE-GC093 (i7-7700HQ/12GB/1TB/GeForce',\n",
       " 'FX753VE-GC155T (i7-7700HQ/16GB/1TB',\n",
       " 'Flex 5',\n",
       " 'FlexBook Edge',\n",
       " 'G701VO-IH74K (i7-6820HK/32GB/2x',\n",
       " 'G752VY-GC162T (i7-6700HQ/16GB/1TB',\n",
       " 'GE62 Apache',\n",
       " 'GE63VR 7RE',\n",
       " 'GE63VR 7RF',\n",
       " 'GE72 Apache',\n",
       " 'GE72MVR 7RG',\n",
       " 'GE72VR 6RF',\n",
       " 'GE72VR Apache',\n",
       " 'GE73VR 7RE',\n",
       " 'GE73VR 7RF',\n",
       " 'GL553VE-FY082T (i7-7700HQ/8GB/1TB',\n",
       " 'GL62 6QF',\n",
       " 'GL62M (i5-7300HQ/8GB/1TB',\n",
       " 'GL62M 7RD',\n",
       " 'GL62M 7RDX',\n",
       " 'GL62M 7REX',\n",
       " 'GL72M 7RDX',\n",
       " 'GL72M 7REX',\n",
       " 'GP62 7RDX',\n",
       " 'GP62M 7RDX',\n",
       " 'GP62M 7REX',\n",
       " 'GP62M Leopard',\n",
       " 'GP62MVR 6RF',\n",
       " 'GP72M 7REX',\n",
       " 'GP72MVR 7RFX',\n",
       " 'GP72VR Leopard',\n",
       " 'GS40 Phantom',\n",
       " 'GS43VR 7RE',\n",
       " 'GS60 Ghost',\n",
       " 'GS63VR 6RF',\n",
       " 'GS63VR 7RF',\n",
       " 'GS63VR 7RG',\n",
       " 'GS70 Stealth',\n",
       " 'GS73VR 7RF',\n",
       " 'GS73VR 7RG',\n",
       " 'GS73VR Stealth',\n",
       " 'GT62VR 6RD',\n",
       " 'GT62VR 7RE',\n",
       " 'GT72S Dominator',\n",
       " 'GT72VR Dominator',\n",
       " 'GT73EVR 7RE',\n",
       " 'GT73VR Titan',\n",
       " 'GT80S 6QE',\n",
       " 'GT80S 6QF-074US',\n",
       " 'GV62 7RD-1686NL',\n",
       " 'GV62M 7RD',\n",
       " 'Gram 14Z970',\n",
       " 'Gram 15Z970',\n",
       " 'Gram 15Z975',\n",
       " 'IdeaPad 100S-14IBR',\n",
       " 'IdeaPad 110-15IBR',\n",
       " 'IdeaPad 110-15ISK',\n",
       " 'IdeaPad 110-17ACL',\n",
       " 'IdeaPad 120S-14IAP',\n",
       " 'IdeaPad 300-17ISK',\n",
       " 'IdeaPad 310-15ABR',\n",
       " 'IdeaPad 310-15IKB',\n",
       " 'IdeaPad 310-15ISK',\n",
       " 'IdeaPad 320-14IAP',\n",
       " 'IdeaPad 320-15ABR',\n",
       " 'IdeaPad 320-15AST',\n",
       " 'IdeaPad 320-15IAP',\n",
       " 'IdeaPad 320-15IKB',\n",
       " 'IdeaPad 320-15IKBN',\n",
       " 'IdeaPad 320-15ISK',\n",
       " 'IdeaPad 320-17IKB',\n",
       " 'IdeaPad 320-17IKBR',\n",
       " 'IdeaPad 320-17ISK',\n",
       " 'IdeaPad 320s-14IKB',\n",
       " 'IdeaPad 500-15ISK',\n",
       " 'IdeaPad 510-15IKB',\n",
       " 'IdeaPad 510-15ISK',\n",
       " 'IdeaPad 510s-14IKB',\n",
       " 'IdeaPad 520S-14IKB',\n",
       " 'IdeaPad 520s-14IKB',\n",
       " 'IdeaPad 720S-13IKB',\n",
       " 'IdeaPad 720S-14IKB',\n",
       " 'IdeaPad Y700-15ISK',\n",
       " 'IdeaPad Y900-17ISK',\n",
       " 'IdeaPad Y910-17ISK',\n",
       " 'Ideapad 310-15ISK',\n",
       " 'Ideapad 320-15IAP',\n",
       " 'Ideapad 320-15IKBN',\n",
       " 'Ideapad 320-15IKBR',\n",
       " 'Ideapad 320-15ISK',\n",
       " 'Ideapad 510S-13IKB',\n",
       " 'Ideapad 520-15IKBR',\n",
       " 'Ideapad 700-15ISK',\n",
       " 'Inspiron 3168',\n",
       " 'Inspiron 3179',\n",
       " 'Inspiron 3552',\n",
       " 'Inspiron 3567',\n",
       " 'Inspiron 3576',\n",
       " 'Inspiron 5368',\n",
       " 'Inspiron 5370',\n",
       " 'Inspiron 5378',\n",
       " 'Inspiron 5379',\n",
       " 'Inspiron 5567',\n",
       " 'Inspiron 5568',\n",
       " 'Inspiron 5570',\n",
       " 'Inspiron 5577',\n",
       " 'Inspiron 5578',\n",
       " 'Inspiron 5579',\n",
       " 'Inspiron 5767',\n",
       " 'Inspiron 5770',\n",
       " 'Inspiron 7378',\n",
       " 'Inspiron 7559',\n",
       " 'Inspiron 7560',\n",
       " 'Inspiron 7567',\n",
       " 'Inspiron 7570',\n",
       " 'Inspiron 7577',\n",
       " 'Inspiron 7579',\n",
       " 'Inspiron 7773',\n",
       " 'Inspiron 7779',\n",
       " 'Insprion 5767',\n",
       " 'K146 (N3350/4GB/32GB/W10)',\n",
       " 'K147 (N3350/4GB/32GB/FHD/W10)',\n",
       " 'K556UR-DM621T (i7-7500U/8GB/256GB/GeForce',\n",
       " 'K756UX-T4340T (i5-7200U/8GB/500GB',\n",
       " 'L403NA-GA013TS (N3350/4GB/32GB/W10)',\n",
       " 'L502NA-GO052T (N3350/4GB/128GB/W10)',\n",
       " 'LapBook 12.3',\n",
       " 'LapBook 15.6\"',\n",
       " 'Lapbook 15,6',\n",
       " 'Laptop MSI',\n",
       " 'Latitude 3180',\n",
       " 'Latitude 3380',\n",
       " 'Latitude 3480',\n",
       " 'Latitude 3570',\n",
       " 'Latitude 3580',\n",
       " 'Latitude 5289',\n",
       " 'Latitude 5480',\n",
       " 'Latitude 5490',\n",
       " 'Latitude 5580',\n",
       " 'Latitude 5590',\n",
       " 'Latitude 7280',\n",
       " 'Latitude 7390',\n",
       " 'Latitude 7480',\n",
       " 'Latitude E5270',\n",
       " 'Latitude E5470',\n",
       " 'Latitude E5570',\n",
       " 'Latitude E7270',\n",
       " 'Latitude E7470',\n",
       " 'Legion Y520-15IKBN',\n",
       " 'Legion Y720-15IKB',\n",
       " 'Lenovo IdeaPad',\n",
       " 'Leopard GP72M',\n",
       " 'LifeBook A556',\n",
       " 'LifeBook A557',\n",
       " 'Lifebook A557',\n",
       " 'MacBook 12\"',\n",
       " 'MacBook Air',\n",
       " 'MacBook Pro',\n",
       " 'Macbook Air',\n",
       " 'MateBook X',\n",
       " 'Mi Notebook',\n",
       " 'N23 (N3060/4GB/128GB/W10)',\n",
       " 'N42-20 Chromebook',\n",
       " 'Nitro 5',\n",
       " 'Nitro AN515-51',\n",
       " 'Noteb Pav',\n",
       " 'Notebook 9',\n",
       " 'Notebook Odyssey',\n",
       " 'Omen -',\n",
       " 'Omen 15-AX205na',\n",
       " 'Omen 15-ce006nv',\n",
       " 'Omen 15-ce007nv',\n",
       " 'Omen 17-AN010nv',\n",
       " 'Omen 17-W006na',\n",
       " 'Omen 17-W295',\n",
       " 'Omen 17-an006nv',\n",
       " 'Omen 17-an012dx',\n",
       " 'Omen 17-w207nv',\n",
       " 'Omen 17-w212nv',\n",
       " 'PL60 7RD',\n",
       " 'Pavilion 14-BK001nv',\n",
       " 'Pavilion 15-AW003nv',\n",
       " 'Pavilion 15-BC000nv',\n",
       " 'Pavilion 15-CK000nv',\n",
       " 'Pavilion 15-cb003nv',\n",
       " 'Pavilion Power',\n",
       " 'Pavilion X360',\n",
       " 'Pavilion x360',\n",
       " 'Pixelbook (Core',\n",
       " 'Port??Z30-C-16K',\n",
       " 'Port??Z30-C-188',\n",
       " 'Portege A30-C-1CZ',\n",
       " 'Portege X20W-D-10V',\n",
       " 'Portege X30-D-10J',\n",
       " 'Portege X30-D-10K',\n",
       " 'Portege X30-D-10L',\n",
       " 'Portege X30-D-10V',\n",
       " 'Portege X30-D-10X',\n",
       " 'Portege Z30-C-16H',\n",
       " 'Portege Z30-C-16J',\n",
       " 'Portege Z30-C-16L',\n",
       " 'Portege Z30-C-16P',\n",
       " 'Portege Z30-C-16Z',\n",
       " 'Portege Z30-C-1CV',\n",
       " 'Portege Z30-C-1CW',\n",
       " 'Portege Z30T-C-133',\n",
       " 'Precision 3510',\n",
       " 'Precision 3520',\n",
       " 'Precision 7520',\n",
       " 'Precision 7720',\n",
       " 'Precision M5520',\n",
       " 'Predator 17',\n",
       " 'Predator G9-793',\n",
       " 'Pro P2540UA-AB51',\n",
       " 'Pro P2540UA-XO0192R',\n",
       " 'Pro P2540UA-XO0198T',\n",
       " 'Pro P2540UA-XS51',\n",
       " 'ProBook 430',\n",
       " 'ProBook 440',\n",
       " 'ProBook 450',\n",
       " 'ProBook 470',\n",
       " 'ProBook 640',\n",
       " 'ProBook 650',\n",
       " 'ProBook x360',\n",
       " 'Probook 430',\n",
       " 'Probook 440',\n",
       " 'Probook 450',\n",
       " 'Probook 470',\n",
       " 'Probook 640',\n",
       " 'Probook 650',\n",
       " 'Q304UA-BHI5T11 (i5-7200U/6GB/1TB/FHD/W10)',\n",
       " 'Q524UQ-BHI7T15 (i7-7500U/12GB/2TB/GeForce',\n",
       " 'Q534UX-BHI7T19 (i7-7500U/16GB/2TB',\n",
       " 'R417NA-RS01 (N3350/4GB/32GB/W10)',\n",
       " 'R558UA-DM966T (i5-7200U/8GB/128GB/FHD/W10)',\n",
       " 'ROG G701VI',\n",
       " 'ROG G701VO',\n",
       " 'ROG G703VI-E5062T',\n",
       " 'ROG G752VSK-GC493T',\n",
       " 'ROG GL553VE-FY022',\n",
       " 'ROG GL703VD-GC028T',\n",
       " 'ROG Strix',\n",
       " 'ROG Zephyrus',\n",
       " 'Rog G701VIK-BA060T',\n",
       " 'Rog G752VL-GC088D',\n",
       " 'Rog G752VL-UH71T',\n",
       " 'Rog G752VS-BA171T',\n",
       " 'Rog G752VT-GC073T',\n",
       " 'Rog G752VY-GC229T',\n",
       " 'Rog GL502VM-DS74',\n",
       " 'Rog GL502VS',\n",
       " 'Rog GL552VW-CN470T',\n",
       " 'Rog GL552VW-DM201T',\n",
       " 'Rog GL553VE-DS74',\n",
       " 'Rog GL553VE-FY052T',\n",
       " 'Rog GL702VM-GC017T',\n",
       " 'Rog GL702VM-GC354T',\n",
       " 'Rog GL702VS-BA023T',\n",
       " 'Rog GL702VS-GC095T',\n",
       " 'Rog GL752VW-T4308T',\n",
       " 'Rog GL753VD-GC042T',\n",
       " 'Rog GL753VD-GC082T',\n",
       " 'Rog GL753VE-DS74',\n",
       " 'Rog GL753VE-GC070T',\n",
       " 'Rog Strix',\n",
       " 'SP315-51 (i7-7500U/12GB/1TB/FHD/W10)',\n",
       " 'SP714-51 (i7-7Y75/8GB/256GB/FHD/W10)',\n",
       " 'Satellite Pro',\n",
       " 'SmartBook 130',\n",
       " 'SmartBook 140',\n",
       " 'SmartBook 141',\n",
       " 'SmartBook Edge',\n",
       " 'Smartbook 142',\n",
       " 'Spectre 13-V100nv',\n",
       " 'Spectre 13-V111dx',\n",
       " 'Spectre Pro',\n",
       " 'Spectre X360',\n",
       " 'Spectre x360',\n",
       " 'Spin 3',\n",
       " 'Spin 5',\n",
       " 'Spin SP111-31',\n",
       " 'Stream 11-Y000na',\n",
       " 'Stream 14-AX000nv',\n",
       " 'Stream 14-AX001nv',\n",
       " 'Stream 14-AX040wm',\n",
       " 'Surface Laptop',\n",
       " 'Swift 3',\n",
       " 'Swift 7',\n",
       " 'Swift SF114-31-P5HY',\n",
       " 'TMX349-G2-M-50FS (i5-7200U/8GB/256GB/FHD/W10)',\n",
       " 'TP501UA-CJ131T (i5-7200U/8GB/1TB/W10)',\n",
       " 'Tecra A40-C-1DF',\n",
       " 'Tecra A40-C-1E5',\n",
       " 'Tecra A40-C-1KF',\n",
       " 'Tecra A50-C-1ZV',\n",
       " 'Tecra A50-C-218',\n",
       " 'Tecra A50-C-21G',\n",
       " 'Tecra A50-D-11D',\n",
       " 'Tecra A50-D-11M',\n",
       " 'Tecra X40-D-10G',\n",
       " 'Tecra X40-D-10H',\n",
       " 'Tecra X40-D-10Z',\n",
       " 'Tecra Z40-C-12X',\n",
       " 'Tecra Z40-C-12Z',\n",
       " 'Tecra Z40-C-136',\n",
       " 'Tecra Z40-C-161',\n",
       " 'Tecra Z50-C-140',\n",
       " 'Tecra Z50-C-144',\n",
       " 'Tecra Z50-D-10E',\n",
       " 'ThinkPad 13',\n",
       " 'ThinkPad E470',\n",
       " 'ThinkPad E480',\n",
       " 'ThinkPad E570',\n",
       " 'ThinkPad E580',\n",
       " 'ThinkPad L460',\n",
       " 'ThinkPad L470',\n",
       " 'ThinkPad L570',\n",
       " 'ThinkPad P40',\n",
       " 'ThinkPad P51',\n",
       " 'ThinkPad P51s',\n",
       " 'ThinkPad P70',\n",
       " 'ThinkPad T460',\n",
       " 'ThinkPad T460s',\n",
       " 'ThinkPad T470',\n",
       " 'ThinkPad T470p',\n",
       " 'ThinkPad T470s',\n",
       " 'ThinkPad T560',\n",
       " 'ThinkPad T570',\n",
       " 'ThinkPad X1',\n",
       " 'ThinkPad X270',\n",
       " 'ThinkPad Yoga',\n",
       " 'Thinkpad 13',\n",
       " 'Thinkpad E470',\n",
       " 'Thinkpad E570',\n",
       " 'Thinkpad L560',\n",
       " 'Thinkpad P50',\n",
       " 'Thinkpad P51',\n",
       " 'Thinkpad P51s',\n",
       " 'Thinkpad P71',\n",
       " 'Thinkpad T460',\n",
       " 'Thinkpad T460p',\n",
       " 'Thinkpad T460s',\n",
       " 'Thinkpad T470',\n",
       " 'Thinkpad T470p',\n",
       " 'Thinkpad T470s',\n",
       " 'Thinkpad T560',\n",
       " 'Thinkpad T570',\n",
       " 'Thinkpad X1',\n",
       " 'Thinkpad X260',\n",
       " 'Thinkpad X270',\n",
       " 'Thinkpad Yoga',\n",
       " 'TravelMate B',\n",
       " 'TravelMate B117-M',\n",
       " 'TravelMate P238-M',\n",
       " 'TravelMate P259-G2',\n",
       " 'UX410UA-GV097T (i3-7100U/4GB/256GB/FHD/W10)',\n",
       " 'UX410UA-GV350T (i5-8250U/8GB/256GB/FHD/W10)',\n",
       " 'UX430UQ-GV209R (i7-7500U/8GB/256GB/GeForce',\n",
       " 'UX510UX-CN269T (i7-7500U/8GB/256GB',\n",
       " 'V110-15IAP (N3350/4GB/128GB/No',\n",
       " 'V110-15IAP (N3350/4GB/1TB/No',\n",
       " 'V110-15IKB (i5-7200U/4GB/128GB/W10)',\n",
       " 'V110-15ISK (3855U/4GB/500GB/W10)',\n",
       " 'V110-15ISK (i3-6006U/4GB/128GB/W10)',\n",
       " 'V110-15ISK (i3-6006U/4GB/1TB/No',\n",
       " 'V110-15ISK (i3-6006U/4GB/1TB/Radeon',\n",
       " 'V110-15ISK (i3-6006U/4GB/500GB/W10)',\n",
       " 'V110-15ISK (i5-6200U/4GB/128GB/W10)',\n",
       " 'V110-15ISK (i5-6200U/4GB/500GB/No',\n",
       " 'V110-15ISK (i5-6200U/4GB/500GB/W10)',\n",
       " 'V131 (X5-Z8350/4GB/32GB/FHD/W10)',\n",
       " 'V142 (X5-Z8350/2GB/32GB/W10)',\n",
       " 'V310-15IKB (i5-7200U/4GB/1TB/FHD/W10)',\n",
       " 'V310-15IKB (i5-7200U/4GB/1TB/No',\n",
       " 'V310-15IKB (i5-7200U/8GB/1TB',\n",
       " 'V310-15ISK (i3-6006U/4GB/128GB/FHD/No',\n",
       " 'V310-15ISK (i3-6006U/4GB/1TB/FHD/W10)',\n",
       " 'V310-15ISK (i3-6006U/4GB/500GB/No',\n",
       " 'V310-15ISK (i5-6200U/4GB/1TB/FHD/No',\n",
       " 'V310-15ISK (i5-7200U/4GB/1TB/FHD/W10)',\n",
       " 'V310-15ISK (i5-7200U/8GB/1TB',\n",
       " 'V320-17ISK (i3-6006U/4GB/500GB/FHD/No',\n",
       " 'V330-15IKB (i3-7130U/4GB/128GB/FHD/W10)',\n",
       " 'V330-15IKB (i5-8250U/4GB/256GB/FHD/W10)',\n",
       " 'V330-15IKB (i5-8250U/4GB/500GB/FHD/W10)',\n",
       " 'V330-15IKB (i5-8250U/8GB/256GB/FHD/W10)',\n",
       " 'V330-15IKB (i7-8550U/8GB/256GB/FHD/W10)',\n",
       " 'V510-15IKB (i5-7200U/8GB/256GB/FHD/No',\n",
       " 'VivoBook E12',\n",
       " 'VivoBook E201NA',\n",
       " 'VivoBook E403NA',\n",
       " 'VivoBook Flip',\n",
       " 'VivoBook L402NA',\n",
       " 'VivoBook Max',\n",
       " 'VivoBook Pro',\n",
       " 'VivoBook S14',\n",
       " 'VivoBook S15',\n",
       " 'VivoBook X540YA-XX519T',\n",
       " 'Vivobook E200HA',\n",
       " 'Vivobook Max',\n",
       " 'Vivobook X541UV-DM1217T',\n",
       " 'Vostro 3559',\n",
       " 'Vostro 3568',\n",
       " 'Vostro 5370',\n",
       " 'Vostro 5468',\n",
       " 'Vostro 5471',\n",
       " 'Vostro 5568',\n",
       " 'X505BP-BR019T (A9-9420/4GB/1TB/Radeon',\n",
       " 'X540SA-RBPDN09 (N3710/4GB/1TB/W10)',\n",
       " 'X540UA-DM186 (i3-6006U/4GB/1TB/FHD/Linux)',\n",
       " 'X541NA (N3350/4GB/1TB/Linux)',\n",
       " 'X541NA (N4200/4GB/1TB/W10)',\n",
       " 'X541NA-GO020T (N3350/4GB/1TB/W10)',\n",
       " 'X541NA-GO121 (N4200/4GB/1TB/Linux)',\n",
       " 'X541NA-GO414T (N3350/8GB/1TB/W10)',\n",
       " 'X541NA-PD1003Y (N4200/4GB/500GB/W10)',\n",
       " 'X541UA-DM1897 (i3-6006U/4GB/256GB/FHD/Linux)',\n",
       " 'X541UV-DM1439T (i3-7100U/6GB/256GB/GeForce',\n",
       " 'X542UQ-DM117 (i3-7100U/8GB/1TB/GeForce',\n",
       " 'X542UQ-GO005 (i5-7200U/8GB/1TB/GeForce',\n",
       " 'X550VX-XX015D (i5-6300HQ/4GB/1TB/GeForce',\n",
       " 'X553SA-XX021T (N3050/4GB/500GB/W10)',\n",
       " 'X553SA-XX031T (N3050/4GB/500GB/W10)',\n",
       " 'X555BP-XX180T (A9-9420/4GB/1TB/Radeon',\n",
       " 'X555QG-DM242T (A10-9620P/4GB/1TB',\n",
       " 'X556UJ-XO044T (i7-6500U/4GB/500GB/GeForce',\n",
       " 'X705UV-BX074T (i3-6006U/4GB/1TB/GeForce',\n",
       " 'X751NV-TY001 (N4200/4GB/1TB/GeForce',\n",
       " 'X751NV-TY001T (N4200/4GB/1TB/GeForce',\n",
       " 'X751SV-TY001T (N3710/4GB/1TB/GeForce',\n",
       " 'XPS 13',\n",
       " 'XPS 15',\n",
       " 'Yoga 11e',\n",
       " 'Yoga 500-14IBD',\n",
       " 'Yoga 500-14ISK',\n",
       " 'Yoga 500-15ISK',\n",
       " 'Yoga 510-15IKB',\n",
       " 'Yoga 520-14IKB',\n",
       " 'Yoga 700-11ISK',\n",
       " 'Yoga 720-13IKB',\n",
       " 'Yoga 720-15IKB',\n",
       " 'Yoga 730',\n",
       " 'Yoga 900-13ISK',\n",
       " 'Yoga 900S-12ISK',\n",
       " 'Yoga 910-13IKB',\n",
       " 'Yoga 920-13IKB',\n",
       " 'Yoga Book',\n",
       " 'ZBook 15',\n",
       " 'ZBook 15u',\n",
       " 'ZBook 17',\n",
       " 'ZBook Studio',\n",
       " 'Zbook 15',\n",
       " 'Zbook 17',\n",
       " 'ZenBook 3',\n",
       " 'ZenBook Flip',\n",
       " 'ZenBook Pro',\n",
       " 'ZenBook UX305CA-UBM1',\n",
       " 'ZenBook UX310UA-FB485T',\n",
       " 'ZenBook UX310UA-WB71',\n",
       " 'ZenBook UX310UQ-GL026T',\n",
       " 'ZenBook UX410UA-GV183T',\n",
       " 'ZenBook UX430UA',\n",
       " 'ZenBook UX430UN',\n",
       " 'ZenBook UX510UX-CN211T',\n",
       " 'ZenBook UX530UQ-PRO',\n",
       " 'Zenbook 3',\n",
       " 'Zenbook Flip',\n",
       " 'Zenbook UX330UA-AH5Q',\n",
       " 'Zenbook UX390UA',\n",
       " 'Zenbook UX410UA-GV027T',\n",
       " 'Zenbook UX430UA',\n",
       " 'Zenbook UX510UW-FI095T']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "confirmed-sperm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((999, 686), (999,), (261, 686))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = features.iloc[:len(train_labels), :]\n",
    "test = features.iloc[len(train_labels):, :]\n",
    "train.shape, train_labels.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-republic",
   "metadata": {},
   "source": [
    "# BayesianOptimizer\n",
    "With the BayesianOptimizer we will kind the ideal values for the parameters in each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "tamil-savannah",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor, XGBRegressor\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-prayer",
   "metadata": {},
   "source": [
    "# Models\n",
    "Find what each parameters mean in each model by looking into the link below every model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-theme",
   "metadata": {},
   "source": [
    "## LightGBM\n",
    "LightGBM - https://neptune.ai/blog/lightgbm-parameters-guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-thursday",
   "metadata": {},
   "source": [
    "## XGB Regressor\n",
    "https://xgboost.readthedocs.io/en/latest/parameter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "recognized-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 탐색 대상 함수 (XGBRegressor)\n",
    "def XGB_cv(max_depth, learning_rate, n_estimators, gamma\n",
    "             ,min_child_weight, subsample\n",
    "             ,colsample_bytree, reg_alpha, reg_lambda, objective='reg:linear', silent=True, nthread=-1):\n",
    "\n",
    "    # 모델 정의\n",
    "    model = XGBRegressor(max_depth=int(max_depth),\n",
    "                           learning_rate=learning_rate,\n",
    "                           n_estimators=int(n_estimators),\n",
    "                           gamma=gamma,\n",
    "                           min_child_weight=min_child_weight,\n",
    "                           subsample=subsample,\n",
    "                           colsample_bytree=colsample_bytree,\n",
    "                           reg_alpha=reg_alpha,\n",
    "                           reg_lambda = reg_lambda,\n",
    "                           objective=objective,\n",
    "                           nthread=nthread\n",
    "                           )\n",
    "\n",
    "    # metric 계산\n",
    "    rmse = np.sqrt(-cross_val_score(model, train, train_labels, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "\n",
    "    \n",
    "    # 오차 최적화로 사용할 metric 반환\n",
    "    return -rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "technological-immunology",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | learni... | max_depth | min_ch... | n_esti... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------------------\n",
      "[23:30:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:30:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:30:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:30:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:30:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.237   \u001b[0m | \u001b[0m 0.4996  \u001b[0m | \u001b[0m 0.9507  \u001b[0m | \u001b[0m 0.07347 \u001b[0m | \u001b[0m 5.993   \u001b[0m | \u001b[0m 0.4681  \u001b[0m | \u001b[0m 2.404e+0\u001b[0m | \u001b[0m 0.2904  \u001b[0m | \u001b[0m 8.662   \u001b[0m | \u001b[0m 0.8006  \u001b[0m |\n",
      "[23:30:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:30:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:31:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:31:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:31:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.1864  \u001b[0m | \u001b[95m 0.7665  \u001b[0m | \u001b[95m 0.02058 \u001b[0m | \u001b[95m 0.09702 \u001b[0m | \u001b[95m 7.162   \u001b[0m | \u001b[95m 0.637   \u001b[0m | \u001b[95m 2.636e+0\u001b[0m | \u001b[95m 0.917   \u001b[0m | \u001b[95m 3.042   \u001b[0m | \u001b[95m 0.7624  \u001b[0m |\n",
      "[23:31:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:31:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:31:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:31:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:31:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.2283  \u001b[0m | \u001b[0m 0.5456  \u001b[0m | \u001b[0m 0.2912  \u001b[0m | \u001b[0m 0.06157 \u001b[0m | \u001b[0m 3.697   \u001b[0m | \u001b[0m 0.8764  \u001b[0m | \u001b[0m 4.297e+0\u001b[0m | \u001b[0m 2.28    \u001b[0m | \u001b[0m 7.852   \u001b[0m | \u001b[0m 0.5998  \u001b[0m |\n",
      "[23:31:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:31:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:31:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:32:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:32:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2561  \u001b[0m | \u001b[0m 0.6114  \u001b[0m | \u001b[0m 0.5924  \u001b[0m | \u001b[0m 0.005599\u001b[0m | \u001b[0m 6.038   \u001b[0m | \u001b[0m 0.5116  \u001b[0m | \u001b[0m 1.585e+0\u001b[0m | \u001b[0m 4.744   \u001b[0m | \u001b[0m 9.656   \u001b[0m | \u001b[0m 0.9042  \u001b[0m |\n",
      "[23:32:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:32:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:32:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:32:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:32:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.1859  \u001b[0m | \u001b[95m 0.4437  \u001b[0m | \u001b[95m 0.09767 \u001b[0m | \u001b[95m 0.06874 \u001b[0m | \u001b[95m 5.201   \u001b[0m | \u001b[95m 0.3661  \u001b[0m | \u001b[95m 5.457e+0\u001b[0m | \u001b[95m 0.1719  \u001b[0m | \u001b[95m 9.093   \u001b[0m | \u001b[95m 0.6294  \u001b[0m |\n",
      "[23:32:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:33:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:33:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:33:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:34:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.2328  \u001b[0m | \u001b[0m 0.73    \u001b[0m | \u001b[0m 0.3117  \u001b[0m | \u001b[0m 0.05249 \u001b[0m | \u001b[0m 5.734   \u001b[0m | \u001b[0m 0.5546  \u001b[0m | \u001b[0m 9.726e+0\u001b[0m | \u001b[0m 3.876   \u001b[0m | \u001b[0m 9.395   \u001b[0m | \u001b[0m 0.9474  \u001b[0m |\n",
      "[23:34:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:34:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:35:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:35:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:35:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.2502  \u001b[0m | \u001b[0m 0.6783  \u001b[0m | \u001b[0m 0.9219  \u001b[0m | \u001b[0m 0.009761\u001b[0m | \u001b[0m 3.98    \u001b[0m | \u001b[0m 0.1357  \u001b[0m | \u001b[0m 3.928e+0\u001b[0m | \u001b[0m 1.943   \u001b[0m | \u001b[0m 2.713   \u001b[0m | \u001b[0m 0.9144  \u001b[0m |\n",
      "[23:35:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:35:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:35:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:35:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:35:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2492  \u001b[0m | \u001b[0m 0.4854  \u001b[0m | \u001b[0m 0.2809  \u001b[0m | \u001b[0m 0.05473 \u001b[0m | \u001b[0m 3.705   \u001b[0m | \u001b[0m 2.407   \u001b[0m | \u001b[0m 1.671e+0\u001b[0m | \u001b[0m 4.934   \u001b[0m | \u001b[0m 7.722   \u001b[0m | \u001b[0m 0.5994  \u001b[0m |\n",
      "[23:35:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:35:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:35:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:35:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:35:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2431  \u001b[0m | \u001b[0m 0.2044  \u001b[0m | \u001b[0m 0.8155  \u001b[0m | \u001b[0m 0.07098 \u001b[0m | \u001b[0m 6.645   \u001b[0m | \u001b[0m 2.314   \u001b[0m | \u001b[0m 1.666e+0\u001b[0m | \u001b[0m 1.792   \u001b[0m | \u001b[0m 1.159   \u001b[0m | \u001b[0m 0.9316  \u001b[0m |\n",
      "[23:35:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:36:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:36:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:36:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:36:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2351  \u001b[0m | \u001b[0m 0.6986  \u001b[0m | \u001b[0m 0.3309  \u001b[0m | \u001b[0m 0.007292\u001b[0m | \u001b[0m 4.555   \u001b[0m | \u001b[0m 0.9755  \u001b[0m | \u001b[0m 7.566e+0\u001b[0m | \u001b[0m 3.188   \u001b[0m | \u001b[0m 8.872   \u001b[0m | \u001b[0m 0.7361  \u001b[0m |\n",
      "[23:36:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:37:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:37:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:37:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:37:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.2493  \u001b[0m | \u001b[0m 0.3872  \u001b[0m | \u001b[0m 0.5881  \u001b[0m | \u001b[0m 0.0575  \u001b[0m | \u001b[0m 5.421   \u001b[0m | \u001b[0m 1.65    \u001b[0m | \u001b[0m 5.426e+0\u001b[0m | \u001b[0m 2.827   \u001b[0m | \u001b[0m 7.155   \u001b[0m | \u001b[0m 0.5548  \u001b[0m |\n",
      "[23:37:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:37:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:37:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:38:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:38:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.2387  \u001b[0m | \u001b[0m 0.44    \u001b[0m | \u001b[0m 0.8913  \u001b[0m | \u001b[0m 0.02371 \u001b[0m | \u001b[0m 6.894   \u001b[0m | \u001b[0m 0.07578 \u001b[0m | \u001b[0m 2.632e+0\u001b[0m | \u001b[0m 0.2578  \u001b[0m | \u001b[0m 4.07    \u001b[0m | \u001b[0m 0.6015  \u001b[0m |\n",
      "[23:38:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:38:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:38:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:38:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:38:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.2575  \u001b[0m | \u001b[0m 0.5506  \u001b[0m | \u001b[0m 0.954   \u001b[0m | \u001b[0m 0.01928 \u001b[0m | \u001b[0m 7.67    \u001b[0m | \u001b[0m 1.327   \u001b[0m | \u001b[0m 3.345e+0\u001b[0m | \u001b[0m 3.039   \u001b[0m | \u001b[0m 4.039   \u001b[0m | \u001b[0m 0.699   \u001b[0m |\n",
      "[23:38:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:39:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:39:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:39:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:40:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.2446  \u001b[0m | \u001b[0m 0.401   \u001b[0m | \u001b[0m 0.5514  \u001b[0m | \u001b[0m 0.09354 \u001b[0m | \u001b[0m 5.752   \u001b[0m | \u001b[0m 0.6467  \u001b[0m | \u001b[0m 9.726e+0\u001b[0m | \u001b[0m 3.877   \u001b[0m | \u001b[0m 8.271   \u001b[0m | \u001b[0m 0.9281  \u001b[0m |\n",
      "[23:40:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:40:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:40:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:40:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:40:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.2544  \u001b[0m | \u001b[0m 0.2731  \u001b[0m | \u001b[0m 0.8723  \u001b[0m | \u001b[0m 0.04724 \u001b[0m | \u001b[0m 3.31    \u001b[0m | \u001b[0m 2.87    \u001b[0m | \u001b[0m 5.457e+0\u001b[0m | \u001b[0m 1.832   \u001b[0m | \u001b[0m 9.907   \u001b[0m | \u001b[0m 0.602   \u001b[0m |\n",
      "[23:40:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:41:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:41:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:41:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:41:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2518  \u001b[0m | \u001b[0m 0.8626  \u001b[0m | \u001b[0m 0.8927  \u001b[0m | \u001b[0m 0.07651 \u001b[0m | \u001b[0m 4.537   \u001b[0m | \u001b[0m 0.478   \u001b[0m | \u001b[0m 5.457e+0\u001b[0m | \u001b[0m 2.127   \u001b[0m | \u001b[0m 7.605   \u001b[0m | \u001b[0m 0.5762  \u001b[0m |\n",
      "[23:41:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:41:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:41:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:42:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:42:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.2323  \u001b[0m | \u001b[0m 0.3154  \u001b[0m | \u001b[0m 0.2651  \u001b[0m | \u001b[0m 0.09732 \u001b[0m | \u001b[0m 7.837   \u001b[0m | \u001b[0m 1.891   \u001b[0m | \u001b[0m 1.971e+0\u001b[0m | \u001b[0m 4.343   \u001b[0m | \u001b[0m 0.1199  \u001b[0m | \u001b[0m 0.9593  \u001b[0m |\n",
      "[23:42:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:42:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:42:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:42:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:43:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.2771  \u001b[0m | \u001b[0m 0.5487  \u001b[0m | \u001b[0m 0.9868  \u001b[0m | \u001b[0m 0.002032\u001b[0m | \u001b[0m 6.867   \u001b[0m | \u001b[0m 2.851   \u001b[0m | \u001b[0m 7.929e+0\u001b[0m | \u001b[0m 4.308   \u001b[0m | \u001b[0m 6.742   \u001b[0m | \u001b[0m 0.5377  \u001b[0m |\n",
      "[23:43:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:43:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:43:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:44:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:44:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2598  \u001b[0m | \u001b[0m 0.585   \u001b[0m | \u001b[0m 0.9133  \u001b[0m | \u001b[0m 0.06144 \u001b[0m | \u001b[0m 4.491   \u001b[0m | \u001b[0m 2.493   \u001b[0m | \u001b[0m 6.96e+03\u001b[0m | \u001b[0m 3.94    \u001b[0m | \u001b[0m 4.802   \u001b[0m | \u001b[0m 0.7528  \u001b[0m |\n",
      "[23:44:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:44:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:44:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:45:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:45:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2399  \u001b[0m | \u001b[0m 0.3674  \u001b[0m | \u001b[0m 0.7885  \u001b[0m | \u001b[0m 0.07614 \u001b[0m | \u001b[0m 6.957   \u001b[0m | \u001b[0m 2.605   \u001b[0m | \u001b[0m 6.783e+0\u001b[0m | \u001b[0m 1.569   \u001b[0m | \u001b[0m 7.569   \u001b[0m | \u001b[0m 0.7968  \u001b[0m |\n",
      "[23:45:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:45:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:45:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:45:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:46:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.2066  \u001b[0m | \u001b[0m 0.4844  \u001b[0m | \u001b[0m 0.2435  \u001b[0m | \u001b[0m 0.09601 \u001b[0m | \u001b[0m 4.28    \u001b[0m | \u001b[0m 0.1634  \u001b[0m | \u001b[0m 4.348e+0\u001b[0m | \u001b[0m 0.7914  \u001b[0m | \u001b[0m 3.934   \u001b[0m | \u001b[0m 0.6713  \u001b[0m |\n",
      "[23:46:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:46:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:46:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:46:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:46:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.2321  \u001b[0m | \u001b[0m 0.7877  \u001b[0m | \u001b[0m 0.4739  \u001b[0m | \u001b[0m 0.02155 \u001b[0m | \u001b[0m 4.642   \u001b[0m | \u001b[0m 2.014   \u001b[0m | \u001b[0m 3.257e+0\u001b[0m | \u001b[0m 1.797   \u001b[0m | \u001b[0m 3.542   \u001b[0m | \u001b[0m 0.6243  \u001b[0m |\n",
      "[23:46:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:46:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:47:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:47:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.2564  \u001b[0m | \u001b[0m 0.2187  \u001b[0m | \u001b[0m 0.7102  \u001b[0m | \u001b[0m 0.03491 \u001b[0m | \u001b[0m 5.937   \u001b[0m | \u001b[0m 1.149   \u001b[0m | \u001b[0m 3.997e+0\u001b[0m | \u001b[0m 4.348   \u001b[0m | \u001b[0m 6.944   \u001b[0m | \u001b[0m 0.8228  \u001b[0m |\n",
      "[23:47:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:47:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:47:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:47:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:47:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.2644  \u001b[0m | \u001b[0m 0.9135  \u001b[0m | \u001b[0m 0.964   \u001b[0m | \u001b[0m 0.03854 \u001b[0m | \u001b[0m 3.916   \u001b[0m | \u001b[0m 0.0109  \u001b[0m | \u001b[0m 1.643e+0\u001b[0m | \u001b[0m 4.709   \u001b[0m | \u001b[0m 5.058   \u001b[0m | \u001b[0m 0.7665  \u001b[0m |\n",
      "[23:47:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:47:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:48:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:48:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:48:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.2565  \u001b[0m | \u001b[0m 0.8174  \u001b[0m | \u001b[0m 0.8615  \u001b[0m | \u001b[0m 0.03755 \u001b[0m | \u001b[0m 5.108   \u001b[0m | \u001b[0m 2.694   \u001b[0m | \u001b[0m 8.206e+0\u001b[0m | \u001b[0m 4.627   \u001b[0m | \u001b[0m 7.255   \u001b[0m | \u001b[0m 0.8352  \u001b[0m |\n",
      "[23:49:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:49:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:49:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:49:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:49:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.226   \u001b[0m | \u001b[0m 0.5698  \u001b[0m | \u001b[0m 0.3918  \u001b[0m | \u001b[0m 0.006276\u001b[0m | \u001b[0m 3.352   \u001b[0m | \u001b[0m 2.075   \u001b[0m | \u001b[0m 6.582e+0\u001b[0m | \u001b[0m 0.2326  \u001b[0m | \u001b[0m 4.159   \u001b[0m | \u001b[0m 0.9549  \u001b[0m |\n",
      "[23:49:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:50:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:50:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:50:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:50:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.2113  \u001b[0m | \u001b[0m 0.5872  \u001b[0m | \u001b[0m 0.06543 \u001b[0m | \u001b[0m 0.0425  \u001b[0m | \u001b[0m 5.747   \u001b[0m | \u001b[0m 0.8912  \u001b[0m | \u001b[0m 6.628e+0\u001b[0m | \u001b[0m 4.279   \u001b[0m | \u001b[0m 1.31    \u001b[0m | \u001b[0m 0.7267  \u001b[0m |\n",
      "[23:50:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:51:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:51:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:51:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:51:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.2408  \u001b[0m | \u001b[0m 0.7192  \u001b[0m | \u001b[0m 0.7971  \u001b[0m | \u001b[0m 0.02546 \u001b[0m | \u001b[0m 4.699   \u001b[0m | \u001b[0m 0.9043  \u001b[0m | \u001b[0m 3.876e+0\u001b[0m | \u001b[0m 1.391   \u001b[0m | \u001b[0m 4.266   \u001b[0m | \u001b[0m 0.8002  \u001b[0m |\n",
      "[23:51:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:51:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:51:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:52:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:52:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "| \u001b[95m 29      \u001b[0m | \u001b[95m-0.1842  \u001b[0m | \u001b[95m 0.5153  \u001b[0m | \u001b[95m 0.02107 \u001b[0m | \u001b[95m 0.07604 \u001b[0m | \u001b[95m 6.81    \u001b[0m | \u001b[95m 2.761   \u001b[0m | \u001b[95m 6.136e+0\u001b[0m | \u001b[95m 1.319   \u001b[0m | \u001b[95m 1.441   \u001b[0m | \u001b[95m 0.7778  \u001b[0m |\n",
      "[23:52:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:52:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:53:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[23:53:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/objective/regression_obj.cu:170: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0.46095713553362483, 0.9260270392150202, 0.09244284071662473, 6.407415809804234, 0.15231707395951977, 9459.08082558617, 3.8412632521577366, 9.672230913592067, 0.7942408483555771)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-abf7dd02cb24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mbo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXGB_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mbo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ei'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-0777a272fbfb>\u001b[0m in \u001b[0;36mXGB_cv\u001b[1;34m(max_depth, learning_rate, n_estimators, gamma, min_child_weight, subsample, colsample_bytree, reg_alpha, reg_lambda, objective, silent, nthread)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# metric 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"neg_mean_squared_error\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 242\u001b[1;33m     scores = parallel(\n\u001b[0m\u001b[0;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    595\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'eval_metric'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         self._Booster = train(params, train_dmatrix,\n\u001b[0m\u001b[0;32m    598\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \"\"\"\n\u001b[1;32m--> 227\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    228\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1280\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 실험해보고자하는 hyperparameter 집합\n",
    "pbounds = {'max_depth': (3, 8),\n",
    "            'learning_rate': (0.001, 0.1),\n",
    "            'n_estimators': (1000, 10000),\n",
    "            'gamma': (0, 1),\n",
    "            'min_child_weight': (0, 3),\n",
    "            'subsample': (0.5, 1),\n",
    "            'colsample_bytree' : (0.2, 1),\n",
    "            'reg_alpha' : (0,5),\n",
    "            'reg_lambda' : (0,10),\n",
    "            }\n",
    "\n",
    "bo=BayesianOptimization(f=XGB_cv, pbounds=pbounds, verbose=2, random_state=42)\n",
    "\n",
    "bo.maximize(init_points=10, n_iter=30, acq='ei', xi=0.01)\n",
    "\n",
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-slovak",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'target': -0.1841129313945096, 'params': {'colsample_bytree': 0.5152651581814524, 'gamma': 0.021071952664826532, 'learning_rate': 0.07603995749131016, 'max_depth': 6.809844347927643, 'min_child_weight': 2.761301161457484, 'n_estimators': 6136.355874258778, 'reg_alpha': 1.3188365258147017, 'reg_lambda': 1.4406194115140336, 'subsample': 0.7777929105084442}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-tension",
   "metadata": {},
   "source": [
    "## Ridge\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "personal-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 탐색 대상 함수 (Ridge)\n",
    "def Ridge_cv(alpha):\n",
    "\n",
    "    # 모델 정의\n",
    "    model = make_pipeline(RobustScaler(), Ridge(alpha=alpha))\n",
    "\n",
    "    # metric 계산\n",
    "    rmse = np.sqrt(-cross_val_score(model, train, train_labels, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "\n",
    "    # 오차 최적화로 사용할 metric 반환\n",
    "    return -rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "chinese-aging",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2259  \u001b[0m | \u001b[0m 3.746   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2351  \u001b[0m | \u001b[0m 9.507   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.2325  \u001b[0m | \u001b[0m 7.32    \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2305  \u001b[0m | \u001b[0m 5.987   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.2189  \u001b[0m | \u001b[95m 1.561   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.2189  \u001b[0m | \u001b[95m 1.561   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.2162  \u001b[0m | \u001b[95m 0.5818  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2342  \u001b[0m | \u001b[0m 8.662   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2305  \u001b[0m | \u001b[0m 6.012   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2322  \u001b[0m | \u001b[0m 7.081   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.2203  \u001b[0m | \u001b[0m 0.2068  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.2353  \u001b[0m | \u001b[0m 9.699   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.2338  \u001b[0m | \u001b[0m 8.325   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.221   \u001b[0m | \u001b[0m 2.124   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.2199  \u001b[0m | \u001b[0m 1.819   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.22    \u001b[0m | \u001b[0m 1.835   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.224   \u001b[0m | \u001b[0m 3.043   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.2292  \u001b[0m | \u001b[0m 5.248   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2273  \u001b[0m | \u001b[0m 4.32    \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2236  \u001b[0m | \u001b[0m 2.913   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.2169  \u001b[0m | \u001b[0m 1.006   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.2171  \u001b[0m | \u001b[0m 1.076   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.2249  \u001b[0m | \u001b[0m 3.357   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.2239  \u001b[0m | \u001b[0m 2.998   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.2199  \u001b[0m | \u001b[0m 1.82    \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.2324  \u001b[0m | \u001b[0m 7.241   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.2162  \u001b[0m | \u001b[0m 0.5741  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.232   \u001b[0m | \u001b[0m 6.952   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.2328  \u001b[0m | \u001b[0m 7.577   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.2313  \u001b[0m | \u001b[0m 6.526   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.2255  \u001b[0m | \u001b[0m 3.588   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-0.2328  \u001b[0m | \u001b[0m 7.571   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.2216  \u001b[0m | \u001b[0m 2.304   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.2261  \u001b[0m | \u001b[0m 3.824   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.2261  \u001b[0m | \u001b[0m 3.828   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-0.2321  \u001b[0m | \u001b[0m 7.008   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.229   \u001b[0m | \u001b[0m 5.174   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-0.2349  \u001b[0m | \u001b[0m 9.371   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.2318  \u001b[0m | \u001b[0m 6.848   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-0.2224  \u001b[0m | \u001b[0m 2.516   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.2233  \u001b[0m | \u001b[0m 2.829   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-0.2348  \u001b[0m | \u001b[0m 9.221   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-0.2311  \u001b[0m | \u001b[0m 6.382   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-0.2296  \u001b[0m | \u001b[0m 5.497   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-0.2245  \u001b[0m | \u001b[0m 3.217   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.2288  \u001b[0m | \u001b[0m 5.042   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-0.2171  \u001b[0m | \u001b[0m 1.053   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.2314  \u001b[0m | \u001b[0m 6.543   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.2248  \u001b[0m | \u001b[0m 3.329   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.2164  \u001b[0m | \u001b[0m 0.8251  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.2349  \u001b[0m | \u001b[0m 9.353   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.2347  \u001b[0m | \u001b[0m 9.139   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.2353  \u001b[0m | \u001b[0m 9.709   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.2286  \u001b[0m | \u001b[0m 4.94    \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.2347  \u001b[0m | \u001b[0m 9.18    \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-0.2301  \u001b[0m | \u001b[0m 5.746   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-0.23    \u001b[0m | \u001b[0m 5.709   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-0.2315  \u001b[0m | \u001b[0m 6.631   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-0.223   \u001b[0m | \u001b[0m 2.724   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-0.2337  \u001b[0m | \u001b[0m 8.278   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-0.2352  \u001b[0m | \u001b[0m 9.622   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m-0.2233  \u001b[0m | \u001b[0m 2.802   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m-0.2165  \u001b[0m | \u001b[0m 0.4826  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-0.2349  \u001b[0m | \u001b[0m 0.04615 \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-0.2356  \u001b[0m | \u001b[0m 9.998   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-0.2279  \u001b[0m | \u001b[0m 4.594   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m-0.2181  \u001b[0m | \u001b[0m 1.341   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m-0.2333  \u001b[0m | \u001b[0m 7.934   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-0.2268  \u001b[0m | \u001b[0m 4.103   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m-0.2344  \u001b[0m | \u001b[0m 8.866   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m-0.2229  \u001b[0m | \u001b[0m 2.681   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m-0.2339  \u001b[0m | \u001b[0m 8.424   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-0.2351  \u001b[0m | \u001b[0m 9.575   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-0.2171  \u001b[0m | \u001b[0m 1.073   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-0.2351  \u001b[0m | \u001b[0m 9.527   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m-0.2267  \u001b[0m | \u001b[0m 4.058   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-0.2296  \u001b[0m | \u001b[0m 5.475   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-0.2278  \u001b[0m | \u001b[0m 4.544   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m-0.232   \u001b[0m | \u001b[0m 6.944   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-0.2354  \u001b[0m | \u001b[0m 9.852   \u001b[0m |\n",
      "=====================================\n",
      "{'target': -0.2162339615853202, 'params': {'alpha': 0.5817780380698264}}\n"
     ]
    }
   ],
   "source": [
    "# 실험해보고자하는 hyperparameter 집합\n",
    "pbounds = {'alpha': (0.001, 10)}\n",
    "\n",
    "bo=BayesianOptimization(f=Ridge_cv, pbounds=pbounds, verbose=2, random_state=42)\n",
    "bo.maximize(init_points=20, n_iter=60, acq='ei', xi=0.01)\n",
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'target': -0.2162339615853202, 'params': {'alpha': 0.5817780380698264}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-grammar",
   "metadata": {},
   "source": [
    "## Lasso\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "orange-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 탐색 대상 함수 (Lasso)\n",
    "def Lasso_cv(alpha):\n",
    "\n",
    "    # 모델 정의\n",
    "    model = make_pipeline(RobustScaler(), Lasso(alpha=alpha))\n",
    "\n",
    "    # metric 계산\n",
    "    rmse = np.sqrt(-cross_val_score(model, train, train_labels, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "\n",
    "    # 오차 최적화로 사용할 metric 반환\n",
    "    return -rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "unnecessary-olive",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.3971  \u001b[0m | \u001b[0m 0.3745  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.4003  \u001b[0m | \u001b[0m 0.9507  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.3993  \u001b[0m | \u001b[0m 0.732   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.3985  \u001b[0m | \u001b[0m 0.5987  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.3623  \u001b[0m | \u001b[95m 0.156   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.3623  \u001b[0m | \u001b[95m 0.156   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.3082  \u001b[0m | \u001b[95m 0.05808 \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.3999  \u001b[0m | \u001b[0m 0.8662  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.3986  \u001b[0m | \u001b[0m 0.6011  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.3992  \u001b[0m | \u001b[0m 0.7081  \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-0.2751  \u001b[0m | \u001b[95m 0.02058 \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.4004  \u001b[0m | \u001b[0m 0.9699  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.3997  \u001b[0m | \u001b[0m 0.8324  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.388   \u001b[0m | \u001b[0m 0.2123  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.374   \u001b[0m | \u001b[0m 0.1818  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.3748  \u001b[0m | \u001b[0m 0.1834  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.3968  \u001b[0m | \u001b[0m 0.3042  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.3981  \u001b[0m | \u001b[0m 0.5248  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.3974  \u001b[0m | \u001b[0m 0.4319  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.3967  \u001b[0m | \u001b[0m 0.2912  \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m-0.2415  \u001b[0m | \u001b[95m 1.163e-0\u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.337   \u001b[0m | \u001b[0m 0.1003  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.4006  \u001b[0m | \u001b[0m 0.9999  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.3977  \u001b[0m | \u001b[0m 0.4784  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.3995  \u001b[0m | \u001b[0m 0.7833  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.399   \u001b[0m | \u001b[0m 0.658   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.3077  \u001b[0m | \u001b[0m 0.05731 \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.3992  \u001b[0m | \u001b[0m 0.6952  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.3994  \u001b[0m | \u001b[0m 0.7577  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.399   \u001b[0m | \u001b[0m 0.6526  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.397   \u001b[0m | \u001b[0m 0.3587  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-0.3994  \u001b[0m | \u001b[0m 0.757   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.3938  \u001b[0m | \u001b[0m 0.2303  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.3971  \u001b[0m | \u001b[0m 0.3823  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.3971  \u001b[0m | \u001b[0m 0.3828  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-0.3992  \u001b[0m | \u001b[0m 0.7008  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.398   \u001b[0m | \u001b[0m 0.5173  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-0.4002  \u001b[0m | \u001b[0m 0.9371  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.3991  \u001b[0m | \u001b[0m 0.6848  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-0.3962  \u001b[0m | \u001b[0m 0.2515  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.3967  \u001b[0m | \u001b[0m 0.2829  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-0.4002  \u001b[0m | \u001b[0m 0.9221  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-0.3988  \u001b[0m | \u001b[0m 0.6382  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-0.3982  \u001b[0m | \u001b[0m 0.5497  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-0.3968  \u001b[0m | \u001b[0m 0.3216  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.3979  \u001b[0m | \u001b[0m 0.5041  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-0.3397  \u001b[0m | \u001b[0m 0.1052  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.399   \u001b[0m | \u001b[0m 0.6542  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.3969  \u001b[0m | \u001b[0m 0.3328  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.3244  \u001b[0m | \u001b[0m 0.08242 \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.4002  \u001b[0m | \u001b[0m 0.9353  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.4001  \u001b[0m | \u001b[0m 0.9139  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.4004  \u001b[0m | \u001b[0m 0.9709  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.3978  \u001b[0m | \u001b[0m 0.494   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.4001  \u001b[0m | \u001b[0m 0.918   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-0.3984  \u001b[0m | \u001b[0m 0.5746  \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-0.3983  \u001b[0m | \u001b[0m 0.5708  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-0.3991  \u001b[0m | \u001b[0m 0.663   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-0.3967  \u001b[0m | \u001b[0m 0.2723  \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-0.3997  \u001b[0m | \u001b[0m 0.8278  \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-0.4004  \u001b[0m | \u001b[0m 0.9622  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m-0.3967  \u001b[0m | \u001b[0m 0.2801  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m-0.3012  \u001b[0m | \u001b[0m 0.04816 \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-0.2557  \u001b[0m | \u001b[0m 0.004515\u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-0.3526  \u001b[0m | \u001b[0m 0.1322  \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-0.3975  \u001b[0m | \u001b[0m 0.453   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m-0.3721  \u001b[0m | \u001b[0m 0.1779  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m-0.2985  \u001b[0m | \u001b[0m 0.04456 \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-0.3981  \u001b[0m | \u001b[0m 0.5377  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m-0.3996  \u001b[0m | \u001b[0m 0.7899  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m-0.3967  \u001b[0m | \u001b[0m 0.2681  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m-0.3998  \u001b[0m | \u001b[0m 0.8424  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-0.4003  \u001b[0m | \u001b[0m 0.9575  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-0.3408  \u001b[0m | \u001b[0m 0.1072  \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-0.4003  \u001b[0m | \u001b[0m 0.9527  \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m-0.3972  \u001b[0m | \u001b[0m 0.4058  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-0.3982  \u001b[0m | \u001b[0m 0.5475  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-0.3976  \u001b[0m | \u001b[0m 0.4543  \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m-0.3992  \u001b[0m | \u001b[0m 0.6944  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-0.4005  \u001b[0m | \u001b[0m 0.9852  \u001b[0m |\n",
      "=====================================\n",
      "{'target': -0.24154720402835123, 'params': {'alpha': 1.1634755367141103e-05}}\n"
     ]
    }
   ],
   "source": [
    "# 실험해보고자하는 hyperparameter 집합\n",
    "\n",
    "pbounds = {'alpha': (1e-15, 1)}\n",
    "\n",
    "bo=BayesianOptimization(f=Lasso_cv, pbounds=pbounds, verbose=2, random_state=42)\n",
    "bo.maximize(init_points=20, n_iter=60, acq='ei', xi=0.01)\n",
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alone-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'target': -0.24154720402835123, 'params': {'alpha': 1.1634755367141103e-05}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustainable-smith",
   "metadata": {},
   "source": [
    "## Elastic Net\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "hazardous-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 탐색 대상 함수 (ElasticNet)\n",
    "def ElasticNet_cv(alpha):\n",
    "\n",
    "    # 모델 정의\n",
    "    model = make_pipeline(RobustScaler(), ElasticNet(alpha=alpha))\n",
    "\n",
    "    # metric 계산\n",
    "    rmse = np.sqrt(-cross_val_score(model, train, train_labels, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "\n",
    "    # 오차 최적화로 사용할 metric 반환\n",
    "    return -rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "sublime-member",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |   alpha   |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.3787  \u001b[0m | \u001b[0m 0.3745  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.3977  \u001b[0m | \u001b[0m 0.9507  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.397   \u001b[0m | \u001b[0m 0.732   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.3968  \u001b[0m | \u001b[0m 0.5987  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.3239  \u001b[0m | \u001b[95m 0.156   \u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.3239  \u001b[0m | \u001b[95m 0.156   \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.286   \u001b[0m | \u001b[95m 0.05808 \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.3974  \u001b[0m | \u001b[0m 0.8662  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.3968  \u001b[0m | \u001b[0m 0.6011  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.397   \u001b[0m | \u001b[0m 0.7081  \u001b[0m |\n",
      "| \u001b[95m 11      \u001b[0m | \u001b[95m-0.2636  \u001b[0m | \u001b[95m 0.02058 \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.3978  \u001b[0m | \u001b[0m 0.9699  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.3973  \u001b[0m | \u001b[0m 0.8324  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.3428  \u001b[0m | \u001b[0m 0.2123  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.3328  \u001b[0m | \u001b[0m 0.1818  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.3334  \u001b[0m | \u001b[0m 0.1834  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.3638  \u001b[0m | \u001b[0m 0.3042  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.3965  \u001b[0m | \u001b[0m 0.5248  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.3901  \u001b[0m | \u001b[0m 0.4319  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.3612  \u001b[0m | \u001b[0m 0.2912  \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m-0.2472  \u001b[0m | \u001b[95m 1.163e-0\u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.3073  \u001b[0m | \u001b[0m 0.1075  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.3702  \u001b[0m | \u001b[0m 0.3356  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.3629  \u001b[0m | \u001b[0m 0.2997  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.3329  \u001b[0m | \u001b[0m 0.1819  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.397   \u001b[0m | \u001b[0m 0.7241  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.2856  \u001b[0m | \u001b[0m 0.05731 \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.3969  \u001b[0m | \u001b[0m 0.6952  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.3971  \u001b[0m | \u001b[0m 0.7577  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.3969  \u001b[0m | \u001b[0m 0.6526  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.3752  \u001b[0m | \u001b[0m 0.3587  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-0.3971  \u001b[0m | \u001b[0m 0.757   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.3477  \u001b[0m | \u001b[0m 0.2303  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.3804  \u001b[0m | \u001b[0m 0.3823  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.3805  \u001b[0m | \u001b[0m 0.3828  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-0.397   \u001b[0m | \u001b[0m 0.7008  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.3964  \u001b[0m | \u001b[0m 0.5173  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-0.3977  \u001b[0m | \u001b[0m 0.9371  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.3969  \u001b[0m | \u001b[0m 0.6848  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-0.3527  \u001b[0m | \u001b[0m 0.2515  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.3595  \u001b[0m | \u001b[0m 0.2829  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-0.3976  \u001b[0m | \u001b[0m 0.9221  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-0.3968  \u001b[0m | \u001b[0m 0.6382  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-0.3967  \u001b[0m | \u001b[0m 0.5497  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-0.3673  \u001b[0m | \u001b[0m 0.3216  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.3963  \u001b[0m | \u001b[0m 0.5041  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-0.3065  \u001b[0m | \u001b[0m 0.1052  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.3969  \u001b[0m | \u001b[0m 0.6542  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.3696  \u001b[0m | \u001b[0m 0.3328  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.2967  \u001b[0m | \u001b[0m 0.08242 \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.3976  \u001b[0m | \u001b[0m 0.9353  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.3976  \u001b[0m | \u001b[0m 0.9139  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.3978  \u001b[0m | \u001b[0m 0.9709  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.3959  \u001b[0m | \u001b[0m 0.494   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.3976  \u001b[0m | \u001b[0m 0.918   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-0.3967  \u001b[0m | \u001b[0m 0.5746  \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-0.3967  \u001b[0m | \u001b[0m 0.5708  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-0.3969  \u001b[0m | \u001b[0m 0.663   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-0.3572  \u001b[0m | \u001b[0m 0.2723  \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-0.3973  \u001b[0m | \u001b[0m 0.8278  \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-0.3977  \u001b[0m | \u001b[0m 0.9622  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m-0.3589  \u001b[0m | \u001b[0m 0.2801  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m-0.2814  \u001b[0m | \u001b[0m 0.04816 \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-0.2493  \u001b[0m | \u001b[0m 0.004515\u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-0.2886  \u001b[0m | \u001b[0m 0.06442 \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-0.2766  \u001b[0m | \u001b[0m 0.04129 \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m-0.3979  \u001b[0m | \u001b[0m 0.9999  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m-0.2789  \u001b[0m | \u001b[0m 0.04456 \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-0.3967  \u001b[0m | \u001b[0m 0.5377  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m-0.3972  \u001b[0m | \u001b[0m 0.7899  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m-0.3563  \u001b[0m | \u001b[0m 0.2681  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m-0.3973  \u001b[0m | \u001b[0m 0.8424  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-0.3977  \u001b[0m | \u001b[0m 0.9575  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-0.3072  \u001b[0m | \u001b[0m 0.1072  \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-0.3977  \u001b[0m | \u001b[0m 0.9527  \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m-0.3854  \u001b[0m | \u001b[0m 0.4058  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-0.3967  \u001b[0m | \u001b[0m 0.5475  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-0.3934  \u001b[0m | \u001b[0m 0.4543  \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m-0.3969  \u001b[0m | \u001b[0m 0.6944  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-0.3978  \u001b[0m | \u001b[0m 0.9852  \u001b[0m |\n",
      "=====================================\n",
      "{'target': -0.24719560709406352, 'params': {'alpha': 1.1634755367141103e-05}}\n"
     ]
    }
   ],
   "source": [
    "# 실험해보고자하는 hyperparameter 집합\n",
    "pbounds = {'alpha': (1e-15, 1)}\n",
    "\n",
    "bo=BayesianOptimization(f=ElasticNet_cv, pbounds=pbounds, verbose=2, random_state=42)\n",
    "bo.maximize(init_points=20, n_iter=60, acq='ei', xi=0.01)\n",
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-label",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'target': -0.24719560709406352, 'params': {'alpha': 1.1634755367141103e-05}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-sperm",
   "metadata": {},
   "source": [
    "## SVR\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "corporate-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 탐색 대상 함수 (Support Vector Regressor)\n",
    "def SVR_cv(C, epsilon, gamma):\n",
    "\n",
    "    # 모델 정의\n",
    "    model = make_pipeline(RobustScaler(), SVR(C=C, epsilon=epsilon, gamma=gamma))\n",
    "\n",
    "    # metric 계산\n",
    "    rmse = np.sqrt(-cross_val_score(model, train, train_labels, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "\n",
    "    # 오차 최적화로 사용할 metric 반환\n",
    "    return -rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "urban-philippines",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |  epsilon  |   gamma   |\n",
      "-------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.3308  \u001b[0m | \u001b[0m 37.52   \u001b[0m | \u001b[0m 0.09507 \u001b[0m | \u001b[0m 0.0732  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.3025  \u001b[0m | \u001b[95m 59.91   \u001b[0m | \u001b[95m 0.0156  \u001b[0m | \u001b[95m 0.0156  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.3226  \u001b[0m | \u001b[0m 5.903   \u001b[0m | \u001b[0m 0.08662 \u001b[0m | \u001b[0m 0.06011 \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.341   \u001b[0m | \u001b[0m 70.84   \u001b[0m | \u001b[0m 0.002058\u001b[0m | \u001b[0m 0.09699 \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.3065  \u001b[0m | \u001b[0m 83.26   \u001b[0m | \u001b[0m 0.02123 \u001b[0m | \u001b[0m 0.01818 \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.3196  \u001b[0m | \u001b[0m 18.42   \u001b[0m | \u001b[0m 0.03042 \u001b[0m | \u001b[0m 0.05248 \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.3249  \u001b[0m | \u001b[0m 43.25   \u001b[0m | \u001b[0m 0.02912 \u001b[0m | \u001b[0m 0.06119 \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.3115  \u001b[0m | \u001b[0m 14.04   \u001b[0m | \u001b[0m 0.02921 \u001b[0m | \u001b[0m 0.03664 \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.3027  \u001b[0m | \u001b[0m 45.66   \u001b[0m | \u001b[0m 0.07852 \u001b[0m | \u001b[0m 0.01997 \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m-0.2773  \u001b[0m | \u001b[95m 51.47   \u001b[0m | \u001b[95m 0.05924 \u001b[0m | \u001b[95m 0.004645\u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.2847  \u001b[0m | \u001b[0m 60.79   \u001b[0m | \u001b[0m 0.01705 \u001b[0m | \u001b[0m 0.006505\u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.3346  \u001b[0m | \u001b[0m 94.89   \u001b[0m | \u001b[0m 0.09656 \u001b[0m | \u001b[0m 0.08084 \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.3272  \u001b[0m | \u001b[0m 30.53   \u001b[0m | \u001b[0m 0.009767\u001b[0m | \u001b[0m 0.06842 \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.3209  \u001b[0m | \u001b[0m 44.07   \u001b[0m | \u001b[0m 0.0122  \u001b[0m | \u001b[0m 0.04952 \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.3041  \u001b[0m | \u001b[0m 3.535   \u001b[0m | \u001b[0m 0.09093 \u001b[0m | \u001b[0m 0.02588 \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.3227  \u001b[0m | \u001b[0m 66.29   \u001b[0m | \u001b[0m 0.03117 \u001b[0m | \u001b[0m 0.05201 \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.3395  \u001b[0m | \u001b[0m 54.72   \u001b[0m | \u001b[0m 0.01849 \u001b[0m | \u001b[0m 0.09696 \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.3384  \u001b[0m | \u001b[0m 77.54   \u001b[0m | \u001b[0m 0.09395 \u001b[0m | \u001b[0m 0.08948 \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2892  \u001b[0m | \u001b[0m 59.83   \u001b[0m | \u001b[0m 0.09219 \u001b[0m | \u001b[0m 0.008849\u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.312   \u001b[0m | \u001b[0m 19.68   \u001b[0m | \u001b[0m 0.004523\u001b[0m | \u001b[0m 0.03253 \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.3206  \u001b[0m | \u001b[0m 51.38   \u001b[0m | \u001b[0m 0.008453\u001b[0m | \u001b[0m 0.04694 \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.2939  \u001b[0m | \u001b[0m 51.5    \u001b[0m | \u001b[0m 0.04067 \u001b[0m | \u001b[0m 0.01119 \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.321   \u001b[0m | \u001b[0m 51.46   \u001b[0m | \u001b[0m 0.04216 \u001b[0m | \u001b[0m 0.05046 \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.3095  \u001b[0m | \u001b[0m 94.3    \u001b[0m | \u001b[0m 0.03679 \u001b[0m | \u001b[0m 0.02213 \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.2959  \u001b[0m | \u001b[0m 51.47   \u001b[0m | \u001b[0m 0.08692 \u001b[0m | \u001b[0m 0.01333 \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.3051  \u001b[0m | \u001b[0m 60.78   \u001b[0m | \u001b[0m 0.03456 \u001b[0m | \u001b[0m 0.01962 \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.311   \u001b[0m | \u001b[0m 59.82   \u001b[0m | \u001b[0m 0.08284 \u001b[0m | \u001b[0m 0.02986 \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.3312  \u001b[0m | \u001b[0m 40.36   \u001b[0m | \u001b[0m 0.08407 \u001b[0m | \u001b[0m 0.07576 \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.3399  \u001b[0m | \u001b[0m 61.07   \u001b[0m | \u001b[0m 0.02215 \u001b[0m | \u001b[0m 0.09761 \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.3008  \u001b[0m | \u001b[0m 94.31   \u001b[0m | \u001b[0m 0.02684 \u001b[0m | \u001b[0m 0.01377 \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.2886  \u001b[0m | \u001b[0m 30.9    \u001b[0m | \u001b[0m 0.08611 \u001b[0m | \u001b[0m 0.009384\u001b[0m |\n",
      "| \u001b[95m 32      \u001b[0m | \u001b[95m-0.2657  \u001b[0m | \u001b[95m 51.49   \u001b[0m | \u001b[95m 0.06009 \u001b[0m | \u001b[95m 0.001859\u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.3123  \u001b[0m | \u001b[0m 51.51   \u001b[0m | \u001b[0m 0.08003 \u001b[0m | \u001b[0m 0.03253 \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.3197  \u001b[0m | \u001b[0m 61.27   \u001b[0m | \u001b[0m 0.006151\u001b[0m | \u001b[0m 0.04249 \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.2957  \u001b[0m | \u001b[0m 59.28   \u001b[0m | \u001b[0m 0.07196 \u001b[0m | \u001b[0m 0.0128  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-0.282   \u001b[0m | \u001b[0m 30.87   \u001b[0m | \u001b[0m 0.07121 \u001b[0m | \u001b[0m 0.006519\u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.2989  \u001b[0m | \u001b[0m 60.84   \u001b[0m | \u001b[0m 0.01826 \u001b[0m | \u001b[0m 0.01317 \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-0.3353  \u001b[0m | \u001b[0m 33.7    \u001b[0m | \u001b[0m 0.005813\u001b[0m | \u001b[0m 0.08785 \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.3127  \u001b[0m | \u001b[0m 88.04   \u001b[0m | \u001b[0m 0.08377 \u001b[0m | \u001b[0m 0.03208 \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-0.3108  \u001b[0m | \u001b[0m 30.87   \u001b[0m | \u001b[0m 0.04133 \u001b[0m | \u001b[0m 0.03159 \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.2923  \u001b[0m | \u001b[0m 60.82   \u001b[0m | \u001b[0m 0.05003 \u001b[0m | \u001b[0m 0.01007 \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-0.3381  \u001b[0m | \u001b[0m 52.72   \u001b[0m | \u001b[0m 0.02212 \u001b[0m | \u001b[0m 0.09359 \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-0.3358  \u001b[0m | \u001b[0m 7.125   \u001b[0m | \u001b[0m 0.07807 \u001b[0m | \u001b[0m 0.08725 \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-0.3084  \u001b[0m | \u001b[0m 59.89   \u001b[0m | \u001b[0m 0.09721 \u001b[0m | \u001b[0m 0.0251  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-0.3165  \u001b[0m | \u001b[0m 30.86   \u001b[0m | \u001b[0m 0.09121 \u001b[0m | \u001b[0m 0.04259 \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.2707  \u001b[0m | \u001b[0m 51.5    \u001b[0m | \u001b[0m 0.08678 \u001b[0m | \u001b[0m 0.002811\u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-0.2979  \u001b[0m | \u001b[0m 30.91   \u001b[0m | \u001b[0m 0.05914 \u001b[0m | \u001b[0m 0.01501 \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.3253  \u001b[0m | \u001b[0m 59.28   \u001b[0m | \u001b[0m 0.06855 \u001b[0m | \u001b[0m 0.06285 \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.324   \u001b[0m | \u001b[0m 84.71   \u001b[0m | \u001b[0m 0.02641 \u001b[0m | \u001b[0m 0.05266 \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.3267  \u001b[0m | \u001b[0m 60.81   \u001b[0m | \u001b[0m 0.05544 \u001b[0m | \u001b[0m 0.06631 \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.2825  \u001b[0m | \u001b[0m 51.55   \u001b[0m | \u001b[0m 0.09738 \u001b[0m | \u001b[0m 0.006113\u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.3067  \u001b[0m | \u001b[0m 48.84   \u001b[0m | \u001b[0m 0.02487 \u001b[0m | \u001b[0m 0.02157 \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.2884  \u001b[0m | \u001b[0m 13.64   \u001b[0m | \u001b[0m 0.09459 \u001b[0m | \u001b[0m 0.01005 \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.2995  \u001b[0m | \u001b[0m 13.67   \u001b[0m | \u001b[0m 0.08803 \u001b[0m | \u001b[0m 0.01801 \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.3183  \u001b[0m | \u001b[0m 73.41   \u001b[0m | \u001b[0m 0.09968 \u001b[0m | \u001b[0m 0.04498 \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-0.2987  \u001b[0m | \u001b[0m 51.57   \u001b[0m | \u001b[0m 0.06963 \u001b[0m | \u001b[0m 0.01554 \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-0.3082  \u001b[0m | \u001b[0m 76.71   \u001b[0m | \u001b[0m 0.02231 \u001b[0m | \u001b[0m 0.02051 \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-0.3364  \u001b[0m | \u001b[0m 48.87   \u001b[0m | \u001b[0m 0.08013 \u001b[0m | \u001b[0m 0.08758 \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-0.2943  \u001b[0m | \u001b[0m 54.52   \u001b[0m | \u001b[0m 0.03864 \u001b[0m | \u001b[0m 0.01132 \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-0.3193  \u001b[0m | \u001b[0m 13.63   \u001b[0m | \u001b[0m 0.0972  \u001b[0m | \u001b[0m 0.04909 \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-0.3117  \u001b[0m | \u001b[0m 54.56   \u001b[0m | \u001b[0m 0.0296  \u001b[0m | \u001b[0m 0.02828 \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m-0.3113  \u001b[0m | \u001b[0m 90.39   \u001b[0m | \u001b[0m 0.01117 \u001b[0m | \u001b[0m 0.02168 \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m-0.3235  \u001b[0m | \u001b[0m 54.51   \u001b[0m | \u001b[0m 0.06159 \u001b[0m | \u001b[0m 0.05839 \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-0.3273  \u001b[0m | \u001b[0m 78.47   \u001b[0m | \u001b[0m 0.04435 \u001b[0m | \u001b[0m 0.06661 \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-0.2714  \u001b[0m | \u001b[0m 13.61   \u001b[0m | \u001b[0m 0.08908 \u001b[0m | \u001b[0m 0.001173\u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-0.3304  \u001b[0m | \u001b[0m 76.06   \u001b[0m | \u001b[0m 0.06107 \u001b[0m | \u001b[0m 0.07538 \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m-0.3046  \u001b[0m | \u001b[0m 13.59   \u001b[0m | \u001b[0m 0.05727 \u001b[0m | \u001b[0m 0.02441 \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m-0.2978  \u001b[0m | \u001b[0m 51.5    \u001b[0m | \u001b[0m 0.04772 \u001b[0m | \u001b[0m 0.01411 \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-0.2975  \u001b[0m | \u001b[0m 13.62   \u001b[0m | \u001b[0m 0.06628 \u001b[0m | \u001b[0m 0.01645 \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m-0.2797  \u001b[0m | \u001b[0m 51.47   \u001b[0m | \u001b[0m 0.02921 \u001b[0m | \u001b[0m 0.005416\u001b[0m |\n",
      "| \u001b[95m 71      \u001b[0m | \u001b[95m-0.2617  \u001b[0m | \u001b[95m 51.44   \u001b[0m | \u001b[95m 0.03884 \u001b[0m | \u001b[95m 0.000635\u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m-0.3365  \u001b[0m | \u001b[0m 78.33   \u001b[0m | \u001b[0m 0.05366 \u001b[0m | \u001b[0m 0.08992 \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-0.2636  \u001b[0m | \u001b[0m 51.41   \u001b[0m | \u001b[0m 0.06472 \u001b[0m | \u001b[0m 0.001174\u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-0.2926  \u001b[0m | \u001b[0m 51.44   \u001b[0m | \u001b[0m 0.006978\u001b[0m | \u001b[0m 0.009608\u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-0.314   \u001b[0m | \u001b[0m 51.42   \u001b[0m | \u001b[0m 0.0668  \u001b[0m | \u001b[0m 0.03595 \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m-0.3027  \u001b[0m | \u001b[0m 48.83   \u001b[0m | \u001b[0m 0.02356 \u001b[0m | \u001b[0m 0.01728 \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-0.2708  \u001b[0m | \u001b[0m 51.37   \u001b[0m | \u001b[0m 0.06686 \u001b[0m | \u001b[0m 0.003082\u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-0.2753  \u001b[0m | \u001b[0m 51.44   \u001b[0m | \u001b[0m 0.07273 \u001b[0m | \u001b[0m 0.003981\u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m-0.2741  \u001b[0m | \u001b[0m 51.33   \u001b[0m | \u001b[0m 0.08118 \u001b[0m | \u001b[0m 0.003648\u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-0.2978  \u001b[0m | \u001b[0m 51.27   \u001b[0m | \u001b[0m 0.04905 \u001b[0m | \u001b[0m 0.0142  \u001b[0m |\n",
      "=============================================================\n",
      "{'target': -0.26173172662582117, 'params': {'C': 51.44116726098502, 'epsilon': 0.0388359599090226, 'gamma': 0.0006357750751616731}}\n"
     ]
    }
   ],
   "source": [
    "# 실험해보고자하는 hyperparameter 집합\n",
    "pbounds = {'C': (0.1, 100),\n",
    "          'epsilon': (1e-8, 0.1),\n",
    "          'gamma': (1e-8, 0.1)}\n",
    "\n",
    "bo=BayesianOptimization(f=SVR_cv, pbounds=pbounds, verbose=2, random_state=42)\n",
    "bo.maximize(init_points=20, n_iter=60, acq='ei', xi=0.01)\n",
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-picture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'target': -0.26173172662582117, 'params': {'C': 51.44116726098502, 'epsilon': 0.0388359599090226, 'gamma': 0.0006357750751616731}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-surveillance",
   "metadata": {},
   "source": [
    "## GBR\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "structured-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 탐색 대상 함수 (Gradient Boosting Regressor)\n",
    "def GBR_cv(n_estimators, max_depth, min_samples_leaf, min_samples_split,learning_rate=0.001, max_features='sqrt', loss='huber'):\n",
    "\n",
    "    # 모델 정의\n",
    "    model = GradientBoostingRegressor(n_estimators=int(n_estimators),\n",
    "                                      learning_rate=learning_rate,\n",
    "                                      max_depth=int(max_depth),\n",
    "                                      max_features=max_features,\n",
    "                                      min_samples_leaf=int(min_samples_leaf),\n",
    "                                      min_samples_split=int(min_samples_split),\n",
    "                                      loss=loss\n",
    "                                      )\n",
    "\n",
    "    # metric 계산\n",
    "    rmse = np.sqrt(-cross_val_score(model, train, train_labels, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "\n",
    "    # 오차 최적화로 사용할 metric 반환\n",
    "    return -rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "little-tourism",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | max_depth | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2117  \u001b[0m | \u001b[0m 0.03808 \u001b[0m | \u001b[0m 7.704   \u001b[0m | \u001b[0m 37.94   \u001b[0m | \u001b[0m 31.94   \u001b[0m | \u001b[0m 2.404e+0\u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2278  \u001b[0m | \u001b[0m 0.01644 \u001b[0m | \u001b[0m 2.349   \u001b[0m | \u001b[0m 43.98   \u001b[0m | \u001b[0m 32.05   \u001b[0m | \u001b[0m 7.373e+0\u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.2806  \u001b[0m | \u001b[0m 0.003038\u001b[0m | \u001b[0m 7.819   \u001b[0m | \u001b[0m 42.46   \u001b[0m | \u001b[0m 14.56   \u001b[0m | \u001b[0m 2.636e+0\u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2207  \u001b[0m | \u001b[0m 0.01916 \u001b[0m | \u001b[0m 3.825   \u001b[0m | \u001b[0m 28.61   \u001b[0m | \u001b[0m 24.44   \u001b[0m | \u001b[0m 3.621e+0\u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.1989  \u001b[0m | \u001b[95m 0.06157 \u001b[0m | \u001b[95m 2.837   \u001b[0m | \u001b[95m 18.15   \u001b[0m | \u001b[95m 21.49   \u001b[0m | \u001b[95m 5.105e+0\u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.2129  \u001b[0m | \u001b[0m 0.07873 \u001b[0m | \u001b[0m 3.198   \u001b[0m | \u001b[0m 28.14   \u001b[0m | \u001b[0m 31.66   \u001b[0m | \u001b[0m 1.418e+0\u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m-0.18    \u001b[0m | \u001b[95m 0.06115 \u001b[0m | \u001b[95m 3.023   \u001b[0m | \u001b[95m 7.927   \u001b[0m | \u001b[95m 47.7    \u001b[0m | \u001b[95m 9.691e+0\u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.1832  \u001b[0m | \u001b[0m 0.08103 \u001b[0m | \u001b[0m 3.828   \u001b[0m | \u001b[0m 9.395   \u001b[0m | \u001b[0m 35.79   \u001b[0m | \u001b[0m 4.961e+0\u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.1899  \u001b[0m | \u001b[0m 0.01308 \u001b[0m | \u001b[0m 4.971   \u001b[0m | \u001b[0m 6.547   \u001b[0m | \u001b[0m 45.92   \u001b[0m | \u001b[0m 3.329e+0\u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2069  \u001b[0m | \u001b[0m 0.06659 \u001b[0m | \u001b[0m 3.87    \u001b[0m | \u001b[0m 28.4    \u001b[0m | \u001b[0m 29.6    \u001b[0m | \u001b[0m 2.664e+0\u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.2002  \u001b[0m | \u001b[0m 0.09699 \u001b[0m | \u001b[0m 6.651   \u001b[0m | \u001b[0m 47.28   \u001b[0m | \u001b[0m 45.27   \u001b[0m | \u001b[0m 6.381e+0\u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.1919  \u001b[0m | \u001b[0m 0.09227 \u001b[0m | \u001b[0m 2.531   \u001b[0m | \u001b[0m 13.82   \u001b[0m | \u001b[0m 7.035   \u001b[0m | \u001b[0m 3.928e+0\u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.2157  \u001b[0m | \u001b[0m 0.03948 \u001b[0m | \u001b[0m 3.628   \u001b[0m | \u001b[0m 42.29   \u001b[0m | \u001b[0m 21.05   \u001b[0m | \u001b[0m 3.528e+0\u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.2083  \u001b[0m | \u001b[0m 0.05473 \u001b[0m | \u001b[0m 2.846   \u001b[0m | \u001b[0m 41.1    \u001b[0m | \u001b[0m 8.355   \u001b[0m | \u001b[0m 9.882e+0\u001b[0m |\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m-0.1779  \u001b[0m | \u001b[95m 0.07745 \u001b[0m | \u001b[95m 3.192   \u001b[0m | \u001b[95m 5.248   \u001b[0m | \u001b[95m 41.7    \u001b[0m | \u001b[95m 7.362e+0\u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.1795  \u001b[0m | \u001b[0m 0.07317 \u001b[0m | \u001b[0m 6.628   \u001b[0m | \u001b[0m 8.332   \u001b[0m | \u001b[0m 21.13   \u001b[0m | \u001b[0m 2.043e+0\u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.1902  \u001b[0m | \u001b[0m 0.08645 \u001b[0m | \u001b[0m 5.74    \u001b[0m | \u001b[0m 19.89   \u001b[0m | \u001b[0m 7.86    \u001b[0m | \u001b[0m 3.799e+0\u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.2011  \u001b[0m | \u001b[0m 0.03319 \u001b[0m | \u001b[0m 6.378   \u001b[0m | \u001b[0m 33.69   \u001b[0m | \u001b[0m 44.92   \u001b[0m | \u001b[0m 5.25e+03\u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2118  \u001b[0m | \u001b[0m 0.01284 \u001b[0m | \u001b[0m 6.279   \u001b[0m | \u001b[0m 39.24   \u001b[0m | \u001b[0m 30.26   \u001b[0m | \u001b[0m 7.939e+0\u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2059  \u001b[0m | \u001b[0m 0.04989 \u001b[0m | \u001b[0m 5.136   \u001b[0m | \u001b[0m 24.24   \u001b[0m | \u001b[0m 6.144   \u001b[0m | \u001b[0m 1.971e+0\u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m-0.1774  \u001b[0m | \u001b[95m 0.05183 \u001b[0m | \u001b[95m 5.869   \u001b[0m | \u001b[95m 7.611   \u001b[0m | \u001b[95m 36.31   \u001b[0m | \u001b[95m 7.365e+0\u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.1956  \u001b[0m | \u001b[0m 0.05155 \u001b[0m | \u001b[0m 2.117   \u001b[0m | \u001b[0m 14.35   \u001b[0m | \u001b[0m 20.95   \u001b[0m | \u001b[0m 5.103e+0\u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.1889  \u001b[0m | \u001b[0m 0.09037 \u001b[0m | \u001b[0m 3.091   \u001b[0m | \u001b[0m 11.54   \u001b[0m | \u001b[0m 39.95   \u001b[0m | \u001b[0m 2.041e+0\u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.1775  \u001b[0m | \u001b[0m 0.05123 \u001b[0m | \u001b[0m 5.397   \u001b[0m | \u001b[0m 6.457   \u001b[0m | \u001b[0m 23.33   \u001b[0m | \u001b[0m 7.351e+0\u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.1979  \u001b[0m | \u001b[0m 0.04561 \u001b[0m | \u001b[0m 6.659   \u001b[0m | \u001b[0m 20.25   \u001b[0m | \u001b[0m 12.18   \u001b[0m | \u001b[0m 2.062e+0\u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.1847  \u001b[0m | \u001b[0m 0.03074 \u001b[0m | \u001b[0m 6.561   \u001b[0m | \u001b[0m 14.82   \u001b[0m | \u001b[0m 39.59   \u001b[0m | \u001b[0m 7.338e+0\u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.1935  \u001b[0m | \u001b[0m 0.06605 \u001b[0m | \u001b[0m 2.443   \u001b[0m | \u001b[0m 6.931   \u001b[0m | \u001b[0m 7.877   \u001b[0m | \u001b[0m 2.027e+0\u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.1949  \u001b[0m | \u001b[0m 0.03047 \u001b[0m | \u001b[0m 6.803   \u001b[0m | \u001b[0m 25.87   \u001b[0m | \u001b[0m 34.65   \u001b[0m | \u001b[0m 9.68e+03\u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.1816  \u001b[0m | \u001b[0m 0.04143 \u001b[0m | \u001b[0m 4.058   \u001b[0m | \u001b[0m 10.3    \u001b[0m | \u001b[0m 41.79   \u001b[0m | \u001b[0m 9.722e+0\u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.1991  \u001b[0m | \u001b[0m 0.03033 \u001b[0m | \u001b[0m 4.046   \u001b[0m | \u001b[0m 32.11   \u001b[0m | \u001b[0m 44.73   \u001b[0m | \u001b[0m 9.709e+0\u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.1945  \u001b[0m | \u001b[0m 0.06054 \u001b[0m | \u001b[0m 5.437   \u001b[0m | \u001b[0m 24.08   \u001b[0m | \u001b[0m 46.72   \u001b[0m | \u001b[0m 4.986e+0\u001b[0m |\n",
      "| \u001b[95m 32      \u001b[0m | \u001b[95m-0.1766  \u001b[0m | \u001b[95m 0.02007 \u001b[0m | \u001b[95m 6.845   \u001b[0m | \u001b[95m 6.504   \u001b[0m | \u001b[95m 23.91   \u001b[0m | \u001b[95m 9.705e+0\u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.1787  \u001b[0m | \u001b[0m 0.0845  \u001b[0m | \u001b[0m 5.483   \u001b[0m | \u001b[0m 5.184   \u001b[0m | \u001b[0m 20.42   \u001b[0m | \u001b[0m 9.727e+0\u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.189   \u001b[0m | \u001b[0m 0.07565 \u001b[0m | \u001b[0m 3.481   \u001b[0m | \u001b[0m 15.87   \u001b[0m | \u001b[0m 8.292   \u001b[0m | \u001b[0m 4.94e+03\u001b[0m |\n",
      "| \u001b[95m 35      \u001b[0m | \u001b[95m-0.1757  \u001b[0m | \u001b[95m 0.07105 \u001b[0m | \u001b[95m 4.282   \u001b[0m | \u001b[95m 5.429   \u001b[0m | \u001b[95m 45.77   \u001b[0m | \u001b[95m 4.92e+03\u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-0.1954  \u001b[0m | \u001b[0m 0.06299 \u001b[0m | \u001b[0m 6.003   \u001b[0m | \u001b[0m 26.06   \u001b[0m | \u001b[0m 43.85   \u001b[0m | \u001b[0m 4.927e+0\u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.1824  \u001b[0m | \u001b[0m 0.01813 \u001b[0m | \u001b[0m 4.411   \u001b[0m | \u001b[0m 6.111   \u001b[0m | \u001b[0m 22.07   \u001b[0m | \u001b[0m 4.905e+0\u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-0.2007  \u001b[0m | \u001b[0m 0.05407 \u001b[0m | \u001b[0m 6.81    \u001b[0m | \u001b[0m 42.17   \u001b[0m | \u001b[0m 29.72   \u001b[0m | \u001b[0m 5.916e+0\u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.1796  \u001b[0m | \u001b[0m 0.08781 \u001b[0m | \u001b[0m 5.669   \u001b[0m | \u001b[0m 7.154   \u001b[0m | \u001b[0m 46.9    \u001b[0m | \u001b[0m 4.881e+0\u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-0.2391  \u001b[0m | \u001b[0m 0.002935\u001b[0m | \u001b[0m 5.867   \u001b[0m | \u001b[0m 25.9    \u001b[0m | \u001b[0m 48.66   \u001b[0m | \u001b[0m 4.988e+0\u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.2069  \u001b[0m | \u001b[0m 0.02435 \u001b[0m | \u001b[0m 5.745   \u001b[0m | \u001b[0m 43.27   \u001b[0m | \u001b[0m 43.33   \u001b[0m | \u001b[0m 8.297e+0\u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-0.2193  \u001b[0m | \u001b[0m 0.04373 \u001b[0m | \u001b[0m 7.01    \u001b[0m | \u001b[0m 33.3    \u001b[0m | \u001b[0m 10.85   \u001b[0m | \u001b[0m 1.259e+0\u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-0.1865  \u001b[0m | \u001b[0m 0.09843 \u001b[0m | \u001b[0m 4.249   \u001b[0m | \u001b[0m 14.28   \u001b[0m | \u001b[0m 38.48   \u001b[0m | \u001b[0m 7.071e+0\u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-0.1969  \u001b[0m | \u001b[0m 0.06541 \u001b[0m | \u001b[0m 7.11    \u001b[0m | \u001b[0m 21.94   \u001b[0m | \u001b[0m 48.29   \u001b[0m | \u001b[0m 2.886e+0\u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-0.2141  \u001b[0m | \u001b[0m 0.04688 \u001b[0m | \u001b[0m 6.568   \u001b[0m | \u001b[0m 37.8    \u001b[0m | \u001b[0m 45.59   \u001b[0m | \u001b[0m 1.945e+0\u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.1836  \u001b[0m | \u001b[0m 0.02956 \u001b[0m | \u001b[0m 7.829   \u001b[0m | \u001b[0m 13.88   \u001b[0m | \u001b[0m 48.14   \u001b[0m | \u001b[0m 9.786e+0\u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-0.1952  \u001b[0m | \u001b[0m 0.07771 \u001b[0m | \u001b[0m 2.062   \u001b[0m | \u001b[0m 14.84   \u001b[0m | \u001b[0m 27.85   \u001b[0m | \u001b[0m 4.306e+0\u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.2033  \u001b[0m | \u001b[0m 0.06291 \u001b[0m | \u001b[0m 2.167   \u001b[0m | \u001b[0m 28.49   \u001b[0m | \u001b[0m 32.48   \u001b[0m | \u001b[0m 9.982e+0\u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.2042  \u001b[0m | \u001b[0m 0.0545  \u001b[0m | \u001b[0m 2.701   \u001b[0m | \u001b[0m 23.03   \u001b[0m | \u001b[0m 34.94   \u001b[0m | \u001b[0m 6.369e+0\u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.1898  \u001b[0m | \u001b[0m 0.07972 \u001b[0m | \u001b[0m 4.84    \u001b[0m | \u001b[0m 18.21   \u001b[0m | \u001b[0m 36.98   \u001b[0m | \u001b[0m 9.982e+0\u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.2216  \u001b[0m | \u001b[0m 0.05987 \u001b[0m | \u001b[0m 2.79    \u001b[0m | \u001b[0m 42.12   \u001b[0m | \u001b[0m 16.24   \u001b[0m | \u001b[0m 2.882e+0\u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.1822  \u001b[0m | \u001b[0m 0.03468 \u001b[0m | \u001b[0m 7.128   \u001b[0m | \u001b[0m 8.668   \u001b[0m | \u001b[0m 23.99   \u001b[0m | \u001b[0m 2.78e+03\u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.2247  \u001b[0m | \u001b[0m 0.04365 \u001b[0m | \u001b[0m 6.226   \u001b[0m | \u001b[0m 45.62   \u001b[0m | \u001b[0m 32.93   \u001b[0m | \u001b[0m 1.632e+0\u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.1957  \u001b[0m | \u001b[0m 0.02749 \u001b[0m | \u001b[0m 4.482   \u001b[0m | \u001b[0m 7.919   \u001b[0m | \u001b[0m 39.86   \u001b[0m | \u001b[0m 1.172e+0\u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.1863  \u001b[0m | \u001b[0m 0.0292  \u001b[0m | \u001b[0m 2.292   \u001b[0m | \u001b[0m 9.294   \u001b[0m | \u001b[0m 45.44   \u001b[0m | \u001b[0m 9.764e+0\u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-0.2115  \u001b[0m | \u001b[0m 0.02832 \u001b[0m | \u001b[0m 2.782   \u001b[0m | \u001b[0m 24.8    \u001b[0m | \u001b[0m 25.3    \u001b[0m | \u001b[0m 8.201e+0\u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-0.2025  \u001b[0m | \u001b[0m 0.09811 \u001b[0m | \u001b[0m 2.732   \u001b[0m | \u001b[0m 20.38   \u001b[0m | \u001b[0m 5.199   \u001b[0m | \u001b[0m 3.933e+0\u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-0.1872  \u001b[0m | \u001b[0m 0.05126 \u001b[0m | \u001b[0m 5.916   \u001b[0m | \u001b[0m 17.54   \u001b[0m | \u001b[0m 44.18   \u001b[0m | \u001b[0m 5.507e+0\u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-0.1948  \u001b[0m | \u001b[0m 0.02883 \u001b[0m | \u001b[0m 7.245   \u001b[0m | \u001b[0m 28.89   \u001b[0m | \u001b[0m 27.24   \u001b[0m | \u001b[0m 9.633e+0\u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-0.1908  \u001b[0m | \u001b[0m 0.05143 \u001b[0m | \u001b[0m 3.481   \u001b[0m | \u001b[0m 15.21   \u001b[0m | \u001b[0m 27.05   \u001b[0m | \u001b[0m 5.422e+0\u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-0.2248  \u001b[0m | \u001b[0m 0.00961 \u001b[0m | \u001b[0m 7.288   \u001b[0m | \u001b[0m 42.32   \u001b[0m | \u001b[0m 47.32   \u001b[0m | \u001b[0m 5.563e+0\u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m-0.1823  \u001b[0m | \u001b[0m 0.08447 \u001b[0m | \u001b[0m 7.027   \u001b[0m | \u001b[0m 6.343   \u001b[0m | \u001b[0m 38.51   \u001b[0m | \u001b[0m 7.418e+0\u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m-0.2101  \u001b[0m | \u001b[0m 0.01556 \u001b[0m | \u001b[0m 5.61    \u001b[0m | \u001b[0m 43.71   \u001b[0m | \u001b[0m 35.96   \u001b[0m | \u001b[0m 9.113e+0\u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-0.1924  \u001b[0m | \u001b[0m 0.05573 \u001b[0m | \u001b[0m 5.99    \u001b[0m | \u001b[0m 14.98   \u001b[0m | \u001b[0m 27.91   \u001b[0m | \u001b[0m 1.394e+0\u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-0.1848  \u001b[0m | \u001b[0m 0.04818 \u001b[0m | \u001b[0m 6.602   \u001b[0m | \u001b[0m 12.63   \u001b[0m | \u001b[0m 41.46   \u001b[0m | \u001b[0m 6.208e+0\u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-0.2141  \u001b[0m | \u001b[0m 0.01178 \u001b[0m | \u001b[0m 3.598   \u001b[0m | \u001b[0m 13.49   \u001b[0m | \u001b[0m 26.31   \u001b[0m | \u001b[0m 2.153e+0\u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m-0.1934  \u001b[0m | \u001b[0m 0.09136 \u001b[0m | \u001b[0m 4.476   \u001b[0m | \u001b[0m 25.09   \u001b[0m | \u001b[0m 36.11   \u001b[0m | \u001b[0m 9.122e+0\u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m-0.1988  \u001b[0m | \u001b[0m 0.02364 \u001b[0m | \u001b[0m 4.589   \u001b[0m | \u001b[0m 8.031   \u001b[0m | \u001b[0m 39.46   \u001b[0m | \u001b[0m 1.17e+03\u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-0.1894  \u001b[0m | \u001b[0m 0.02709 \u001b[0m | \u001b[0m 6.966   \u001b[0m | \u001b[0m 17.26   \u001b[0m | \u001b[0m 46.7    \u001b[0m | \u001b[0m 5.506e+0\u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m-0.1798  \u001b[0m | \u001b[0m 0.07286 \u001b[0m | \u001b[0m 3.24    \u001b[0m | \u001b[0m 6.706   \u001b[0m | \u001b[0m 48.31   \u001b[0m | \u001b[0m 4.883e+0\u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m-0.1839  \u001b[0m | \u001b[0m 0.01041 \u001b[0m | \u001b[0m 4.369   \u001b[0m | \u001b[0m 8.44    \u001b[0m | \u001b[0m 41.12   \u001b[0m | \u001b[0m 9.723e+0\u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m-0.1813  \u001b[0m | \u001b[0m 0.006855\u001b[0m | \u001b[0m 6.999   \u001b[0m | \u001b[0m 7.31    \u001b[0m | \u001b[0m 49.24   \u001b[0m | \u001b[0m 9.691e+0\u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-0.2016  \u001b[0m | \u001b[0m 0.0206  \u001b[0m | \u001b[0m 2.392   \u001b[0m | \u001b[0m 10.01   \u001b[0m | \u001b[0m 47.24   \u001b[0m | \u001b[0m 4.92e+03\u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-0.1954  \u001b[0m | \u001b[0m 0.005775\u001b[0m | \u001b[0m 3.513   \u001b[0m | \u001b[0m 5.53    \u001b[0m | \u001b[0m 37.4    \u001b[0m | \u001b[0m 7.359e+0\u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-0.1802  \u001b[0m | \u001b[0m 0.01368 \u001b[0m | \u001b[0m 4.394   \u001b[0m | \u001b[0m 6.612   \u001b[0m | \u001b[0m 44.69   \u001b[0m | \u001b[0m 7.36e+03\u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m-0.1848  \u001b[0m | \u001b[0m 0.05242 \u001b[0m | \u001b[0m 2.851   \u001b[0m | \u001b[0m 9.703   \u001b[0m | \u001b[0m 36.55   \u001b[0m | \u001b[0m 7.364e+0\u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-0.1816  \u001b[0m | \u001b[0m 0.05823 \u001b[0m | \u001b[0m 5.46    \u001b[0m | \u001b[0m 7.555   \u001b[0m | \u001b[0m 26.14   \u001b[0m | \u001b[0m 7.348e+0\u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-0.1815  \u001b[0m | \u001b[0m 0.07812 \u001b[0m | \u001b[0m 4.649   \u001b[0m | \u001b[0m 6.157   \u001b[0m | \u001b[0m 25.43   \u001b[0m | \u001b[0m 7.356e+0\u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m-0.1779  \u001b[0m | \u001b[0m 0.01581 \u001b[0m | \u001b[0m 7.784   \u001b[0m | \u001b[0m 9.153   \u001b[0m | \u001b[0m 25.0    \u001b[0m | \u001b[0m 9.709e+0\u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-0.1841  \u001b[0m | \u001b[0m 0.08797 \u001b[0m | \u001b[0m 2.097   \u001b[0m | \u001b[0m 7.929   \u001b[0m | \u001b[0m 25.79   \u001b[0m | \u001b[0m 7.353e+0\u001b[0m |\n",
      "=====================================================================================\n",
      "{'target': -0.1757488282065423, 'params': {'learning_rate': 0.07105448853347894, 'max_depth': 4.2815300710953945, 'min_samples_leaf': 5.429323528975727, 'min_samples_split': 45.77064151175414, 'n_estimators': 4919.741973374068}}\n"
     ]
    }
   ],
   "source": [
    "# 실험해보고자하는 hyperparameter 집합\n",
    "\n",
    "pbounds = {'n_estimators': (1000, 10000),\n",
    "           'learning_rate': (0.001, 0.1),\n",
    "           'max_depth': (2, 8),\n",
    "           'min_samples_leaf': (5, 50),\n",
    "           'min_samples_split': (5, 50)\n",
    "           }\n",
    "\n",
    "bo=BayesianOptimization(f=GBR_cv, pbounds=pbounds, verbose=2, random_state=42)\n",
    "bo.maximize(init_points=20, n_iter=60, acq='ei', xi=0.01)\n",
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'target': -0.1757488282065423, 'params': {'learning_rate': 0.07105448853347894, 'max_depth': 4.2815300710953945, 'min_samples_leaf': 5.429323528975727, 'min_samples_split': 45.77064151175414, 'n_estimators': 4919.741973374068}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-slovak",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "gross-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 탐색 대상 함수 (Gradient Boosting Regressor)\n",
    "def RF_cv(n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features=None, oob_score='True'):\n",
    "\n",
    "    # 모델 정의\n",
    "    model = RandomForestRegressor(n_estimators=int(n_estimators),\n",
    "                                      max_depth=int(max_depth),\n",
    "                                      min_samples_split=int(min_samples_split),\n",
    "                                      min_samples_leaf=int(min_samples_leaf),\n",
    "                                      max_features=max_features,\n",
    "                                      oob_score=oob_score\n",
    "                                      )\n",
    "\n",
    "    # metric 계산\n",
    "    rmse = np.sqrt(-cross_val_score(model, train, train_labels, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "\n",
    "    # 오차 최적화로 사용할 metric 반환\n",
    "    return -rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "pursuant-arkansas",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2373  \u001b[0m | \u001b[0m 17.49   \u001b[0m | \u001b[0m 7.704   \u001b[0m | \u001b[0m 6.392   \u001b[0m | \u001b[0m 3.993e+0\u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m-0.2084  \u001b[0m | \u001b[95m 13.12   \u001b[0m | \u001b[95m 2.936   \u001b[0m | \u001b[95m 2.349   \u001b[0m | \u001b[95m 5.331e+0\u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.2313  \u001b[0m | \u001b[0m 22.02   \u001b[0m | \u001b[0m 6.248   \u001b[0m | \u001b[0m 2.124   \u001b[0m | \u001b[0m 5.85e+03\u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2137  \u001b[0m | \u001b[0m 26.65   \u001b[0m | \u001b[0m 3.274   \u001b[0m | \u001b[0m 3.091   \u001b[0m | \u001b[0m 1.917e+0\u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.2258  \u001b[0m | \u001b[0m 16.08   \u001b[0m | \u001b[0m 5.149   \u001b[0m | \u001b[0m 4.592   \u001b[0m | \u001b[0m 2.456e+0\u001b[0m |\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m-0.2082  \u001b[0m | \u001b[95m 22.24   \u001b[0m | \u001b[95m 2.837   \u001b[0m | \u001b[95m 3.753   \u001b[0m | \u001b[95m 2.832e+0\u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.2314  \u001b[0m | \u001b[0m 19.12   \u001b[0m | \u001b[0m 6.711   \u001b[0m | \u001b[0m 3.198   \u001b[0m | \u001b[0m 3.571e+0\u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2086  \u001b[0m | \u001b[0m 21.85   \u001b[0m | \u001b[0m 2.279   \u001b[0m | \u001b[0m 5.645   \u001b[0m | \u001b[0m 1.853e+0\u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (11.30103185970559, 7.69331322352, 7.793792198447356, 5041.986740582306)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-df5cc3d45f7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mbo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBayesianOptimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRF_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpbounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mbo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ei'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-c450208606e5>\u001b[0m in \u001b[0;36mRF_cv\u001b[1;34m(n_estimators, max_depth, min_samples_split, min_samples_leaf, max_features, oob_score)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# metric 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"neg_mean_squared_error\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;31m# 오차 최적화로 사용할 metric 반환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 242\u001b[1;33m     scores = parallel(\n\u001b[0m\u001b[0;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    387\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                                         indices=indices)\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \"\"\"\n\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1243\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 실험해보고자하는 hyperparameter 집합\n",
    "pbounds = {'n_estimators': (1000, 6000),\n",
    "           'max_depth': (10, 30),\n",
    "           'min_samples_split': (2, 8),\n",
    "           'min_samples_leaf': (2, 8)\n",
    "           }\n",
    "\n",
    "bo=BayesianOptimization(f=RF_cv, pbounds=pbounds, verbose=2, random_state=42)\n",
    "bo.maximize(init_points=10, n_iter=30, acq='ei', xi=0.01)\n",
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'target': -0.2080683544796602, 'params': {'max_depth': 22.237057894447588, 'min_samples_leaf': 2.836963163912251, 'min_samples_split': 3.752867891211309, 'n_estimators': 2831.8092164684585}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-glossary",
   "metadata": {},
   "source": [
    "## KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "pointed-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 탐색 대상 함수 (K-Neighbors)\n",
    "def KNR_cv(n_neighbors, weights='distance'):\n",
    "\n",
    "    # 모델 정의\n",
    "    model = KNeighborsRegressor(n_neighbors=int(n_neighbors),\n",
    "                                weights=weights\n",
    "                                      )\n",
    "\n",
    "    # metric 계산\n",
    "    rmse = np.sqrt(-cross_val_score(model, train, train_labels, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "\n",
    "    # 오차 최적화로 사용할 metric 반환\n",
    "    return -rmse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "collected-opera",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | n_neig... |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.2759  \u001b[0m | \u001b[0m 5.622   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.2791  \u001b[0m | \u001b[0m 9.655   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.2776  \u001b[0m | \u001b[0m 8.124   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2763  \u001b[0m | \u001b[0m 7.191   \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m-0.2751  \u001b[0m | \u001b[95m 4.092   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.2751  \u001b[0m | \u001b[0m 4.092   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.2774  \u001b[0m | \u001b[0m 3.407   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.2791  \u001b[0m | \u001b[0m 9.063   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.2763  \u001b[0m | \u001b[0m 7.208   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.2763  \u001b[0m | \u001b[0m 7.957   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.2774  \u001b[0m | \u001b[0m 3.144   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.2791  \u001b[0m | \u001b[0m 9.789   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.2776  \u001b[0m | \u001b[0m 8.827   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.2751  \u001b[0m | \u001b[0m 4.486   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.2751  \u001b[0m | \u001b[0m 4.273   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.2751  \u001b[0m | \u001b[0m 4.284   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.2759  \u001b[0m | \u001b[0m 5.13    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.673   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.024   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.2759  \u001b[0m | \u001b[0m 5.039   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.35    \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.2763  \u001b[0m | \u001b[0m 7.615   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.2774  \u001b[0m | \u001b[0m 3.747   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.2776  \u001b[0m | \u001b[0m 8.495   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.2791  \u001b[0m | \u001b[0m 10.0    \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.2751  \u001b[0m | \u001b[0m 4.753   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.2774  \u001b[0m | \u001b[0m 3.002   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.2759  \u001b[0m | \u001b[0m 5.399   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.2791  \u001b[0m | \u001b[0m 9.35    \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.895   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-0.2759  \u001b[0m | \u001b[0m 5.511   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m-0.2776  \u001b[0m | \u001b[0m 8.299   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-0.2751  \u001b[0m | \u001b[0m 4.612   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m-0.2759  \u001b[0m | \u001b[0m 5.676   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.2759  \u001b[0m | \u001b[0m 5.679   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-0.2763  \u001b[0m | \u001b[0m 7.906   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.621   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m-0.2791  \u001b[0m | \u001b[0m 9.56    \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m-0.2763  \u001b[0m | \u001b[0m 7.793   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m-0.2751  \u001b[0m | \u001b[0m 4.76    \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.2751  \u001b[0m | \u001b[0m 4.98    \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m-0.2763  \u001b[0m | \u001b[0m 7.427   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.185   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m-0.2774  \u001b[0m | \u001b[0m 3.918   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-0.2774  \u001b[0m | \u001b[0m 3.574   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.2776  \u001b[0m | \u001b[0m 8.665   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-0.2751  \u001b[0m | \u001b[0m 4.761   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-0.2759  \u001b[0m | \u001b[0m 5.875   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.2763  \u001b[0m | \u001b[0m 7.022   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.476   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.2791  \u001b[0m | \u001b[0m 9.205   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-0.2759  \u001b[0m | \u001b[0m 5.266   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m-0.2774  \u001b[0m | \u001b[0m 3.276   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.458   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m-0.2791  \u001b[0m | \u001b[0m 9.426   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-0.2763  \u001b[0m | \u001b[0m 7.022   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.996   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-0.2776  \u001b[0m | \u001b[0m 8.941   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.786   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m-0.2763  \u001b[0m | \u001b[0m 7.52    \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-0.2751  \u001b[0m | \u001b[0m 4.88    \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m-0.2776  \u001b[0m | \u001b[0m 8.397   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m-0.2791  \u001b[0m | \u001b[0m 9.899   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m-0.2751  \u001b[0m | \u001b[0m 4.398   \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m-0.2763  \u001b[0m | \u001b[0m 7.327   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-0.2751  \u001b[0m | \u001b[0m 4.006   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.104   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m-0.2774  \u001b[0m | \u001b[0m 3.661   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m-0.2763  \u001b[0m | \u001b[0m 7.705   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m-0.2759  \u001b[0m | \u001b[0m 5.792   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m-0.2776  \u001b[0m | \u001b[0m 8.209   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.268   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m-0.2776  \u001b[0m | \u001b[0m 8.588   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m-0.2774  \u001b[0m | \u001b[0m 3.751   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m-0.2791  \u001b[0m | \u001b[0m 9.669   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m-0.2759  \u001b[0m | \u001b[0m 5.84    \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.832   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m-0.2756  \u001b[0m | \u001b[0m 6.18    \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m-0.2763  \u001b[0m | \u001b[0m 7.861   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m-0.2791  \u001b[0m | \u001b[0m 9.896   \u001b[0m |\n",
      "=====================================\n",
      "{'target': -0.27512379240601337, 'params': {'n_neighbors': 4.092130483097056}}\n"
     ]
    }
   ],
   "source": [
    "# 실험해보고자하는 hyperparameter 집합\n",
    "pbounds = {'n_neighbors': (3, 10)\n",
    "           }\n",
    "\n",
    "bo=BayesianOptimization(f=KNR_cv, pbounds=pbounds, verbose=2, random_state=42)\n",
    "bo.maximize(init_points=20, n_iter=60, acq='ei', xi=0.01)\n",
    "print(bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'target': -0.27512379240601337, 'params': {'n_neighbors': 4.092130483097056}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-affect",
   "metadata": {},
   "source": [
    "## Set Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "brave-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cross validation folds\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "quick-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define error metrics\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def mse(y, y_pred):\n",
    "    return np.mean(np.square(y-y_pred))\n",
    "\n",
    "def cv_rmse(model, train=train):\n",
    "    rmse = np.sqrt(-cross_val_score(model, train, train_labels, scoring=\"neg_mean_squared_error\", cv=kf))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "civilian-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Regressor\n",
    "xgboost = XGBRegressor(learning_rate=0.076,\n",
    "                       n_estimators=6000,\n",
    "                       max_depth=6,\n",
    "                       min_child_weight=2,\n",
    "                       gamma=0.021071952664826532,\n",
    "                       subsample=0.7777929105084442,\n",
    "                       colsample_bytree=0.5152651581814524,\n",
    "                       objective='reg:linear',\n",
    "                       nthread=-1,\n",
    "                       scale_pos_weight=1,\n",
    "                       seed=27,\n",
    "                       reg_alpha=1.3188365258147017,\n",
    "                       reg_lambda=1.4406194115140336,\n",
    "                       verbosity = 0,\n",
    "                       random_state=42)\n",
    "\n",
    "# Ridge Lasso ElasticNet 3인방은 비슷하기 때문에 3 중에서 성능이 제일 좋은 것만 가져갔습니다. - Ridge\n",
    "\n",
    "# Ridge Regressor\n",
    "ridge = make_pipeline(RobustScaler(), Ridge(alpha=0.5817780380698264))\n",
    "\n",
    "# Lasso Regressor\n",
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha=1.1634755367141103e-05))\n",
    "\n",
    "# Elastic Net Regressor\n",
    "elasticnet = make_pipeline(RobustScaler(), ElasticNet(alpha=1.1634755367141103e-05))\n",
    "\n",
    "# Support Vector Regressor\n",
    "svr = make_pipeline(RobustScaler(), SVR(C=51.44116726098502, epsilon=0.0388359599090226, gamma=0.0006357750751616731))\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=5000,\n",
    "                                learning_rate=0.07105448853347894,\n",
    "                                max_depth=4,\n",
    "                                max_features='sqrt',\n",
    "                                min_samples_leaf=5,\n",
    "                                min_samples_split=45,\n",
    "                                loss='huber',\n",
    "                                random_state=42) \n",
    "\n",
    "# Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=3000,\n",
    "                          max_depth=22,\n",
    "                          min_samples_split=3,\n",
    "                          min_samples_leaf=2,\n",
    "                          max_features=None,\n",
    "                          oob_score=True,\n",
    "                          random_state=42)\n",
    "\n",
    "#K-Neighbors Regressor\n",
    "kn = KNeighborsRegressor(n_neighbors=4, weights='distance')\n",
    "\n",
    "# Stack up all the models above, optimized using xgboost\n",
    "stack_gen = StackingCVRegressor(regressors=(xgboost, ridge, svr, gbr, rf, kn),\n",
    "                                meta_regressor=gbr,\n",
    "                                use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-seventh",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "hybrid-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "explicit-bullet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost: 0.1928 (0.0106)\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(xgboost)\n",
    "print(\"xgboost: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['xgb'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "advisory-bundle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge: 0.2276 (0.0155)\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(ridge)\n",
    "print(\"ridge: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['ridge'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "stable-integration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso: 0.2489 (0.0182)\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(lasso)\n",
    "print(\"lasso: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['lasso'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "adapted-thread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticnet: 0.2548 (0.0187)\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(elasticnet)\n",
    "print(\"elasticnet: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['elasticnet'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "certified-extent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR: 0.2594 (0.0100)\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(svr)\n",
    "print(\"SVR: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['svr'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "electoral-dinner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbr: 0.1855 (0.0093)\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(gbr)\n",
    "print(\"gbr: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['gbr'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "spanish-ebony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: 0.2127 (0.0129)\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(rf)\n",
    "print(\"rf: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['rf'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "established-version",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kn: 0.2794 (0.0133)\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(kn)\n",
    "print(\"kn: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['kn'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-decline",
   "metadata": {},
   "source": [
    "# Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "informational-peeing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete : stack_gen\n"
     ]
    }
   ],
   "source": [
    "stack_gen_model = stack_gen.fit(np.array(train), np.array(train_labels))\n",
    "print('complete : stack_gen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "tired-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete : xgboost\n"
     ]
    }
   ],
   "source": [
    "xgb_model_full_data = xgboost.fit(train, train_labels)\n",
    "print('complete : xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "alone-architecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete : Ridge\n"
     ]
    }
   ],
   "source": [
    "ridge_model_full_data = ridge.fit(train, train_labels)\n",
    "print('complete : Ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "revised-calculator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete : Svr\n"
     ]
    }
   ],
   "source": [
    "svr_model_full_data = svr.fit(train, train_labels)\n",
    "print('complete : Svr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "reliable-lying",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete : GradientBoosting\n"
     ]
    }
   ],
   "source": [
    "gbr_model_full_data = gbr.fit(train, train_labels)\n",
    "print('complete : GradientBoosting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "backed-liquid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete : RandomForest\n"
     ]
    }
   ],
   "source": [
    "rf_model_full_data = rf.fit(train, train_labels)\n",
    "print('complete : RandomForest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "covered-greene",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete : KNR\n"
     ]
    }
   ],
   "source": [
    "kn_model_full_data = kn.fit(train, train_labels)\n",
    "print('complete : KNR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-thanks",
   "metadata": {},
   "source": [
    "# Blend Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "antique-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to prevent overfitting\n",
    "def blended_predictions(X):\n",
    "    return ((0.15 * xgb_model_full_data.predict(X)) + \\\n",
    "            (0.1 * ridge_model_full_data.predict(X)) + \\\n",
    "            (0.05 * svr_model_full_data.predict(X)) + \\\n",
    "            (0.2 * gbr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * rf_model_full_data.predict(X)) + \\\n",
    "            (0.05 * kn_model_full_data.predict(X)) + \\\n",
    "            (0.35 * stack_gen_model.predict(np.array(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "passing-psychology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE score on train data:\n",
      "0.08796384201856416\n",
      "MSE score on train data:\n",
      "17359.71295485046\n",
      "RMSE score on train data:\n",
      "131.75626343688737\n"
     ]
    }
   ],
   "source": [
    "# Get final precitions from the blended model\n",
    "blended_score_rmsle = rmsle(train_labels, blended_predictions(train))\n",
    "blended_score_mse = mse(np.expm1(train_labels), np.expm1(blended_predictions(train)))\n",
    "rmse = np.sqrt(blended_score_mse)\n",
    "scores['blended'] = (blended_score_rmsle, 0)\n",
    "print('RMSLE score on train data:')\n",
    "print(blended_score_rmsle)\n",
    "print('MSE score on train data:')\n",
    "print(blended_score_mse)\n",
    "print('RMSE score on train data:')\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "requested-beginning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9644307867120421\n"
     ]
    }
   ],
   "source": [
    "# Let's see how accurate is our model.\n",
    "from sklearn import metrics\n",
    "\n",
    "accuracy=metrics.r2_score(np.expm1(train_labels),np.expm1(blended_predictions(train)))\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "rising-gregory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the predictions for each model\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(24, 12))\n",
    "\n",
    "ax = sns.pointplot(x=list(scores.keys()), y=[score for score, _ in scores.values()], markers=['o'], linestyles=['-'])\n",
    "for i, score in enumerate(scores.values()):\n",
    "    ax.text(i, score[0] + 0.002, '{:.6f}'.format(score[0]), horizontalalignment='left', size='large', color='black', weight='semibold')\n",
    "\n",
    "plt.ylabel('Score (RMSE)', size=20, labelpad=12.5)\n",
    "plt.xlabel('Model', size=20, labelpad=12.5)\n",
    "plt.tick_params(axis='x', labelsize=13.5)\n",
    "plt.tick_params(axis='y', labelsize=12.5)\n",
    "\n",
    "plt.title('Scores of Models', size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "suitable-bennett",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.2639864  7.1498839  6.25075645 6.77254682 7.31128266 7.21647068\n",
      " 6.5837576  6.05106496 7.14477562 5.86349825 7.66180347 6.5672287\n",
      " 7.3768051  6.50634005 7.57187734 6.94152767 7.1419006  6.88962931\n",
      " 6.62572395 7.60988502 7.65398384 6.52537104 7.16977232 6.37474159\n",
      " 6.93158145 6.83528326 6.79086617 6.57755831 7.37026088 7.02755769\n",
      " 6.12687361 7.4564175  7.4417507  6.84318186 6.92850816 6.60648817\n",
      " 6.54137543 6.2600437  7.08762617 5.58020282 7.55193237 6.24971736\n",
      " 6.46724708 7.62975635 6.36665156 6.99745909 7.45060195 5.55943356\n",
      " 6.82489187 7.31192567 7.32780971 6.24961189 6.64013218 7.15601463\n",
      " 6.30096955 6.92042219 5.55943356 6.84882466 6.83053178 6.77254682\n",
      " 7.40165225 6.75965592 6.08564357 6.52842787 5.69107171 7.61028403\n",
      " 6.32893631 6.77141894 6.96758359 7.87960126 8.0772602  6.88086929\n",
      " 6.27503286 6.65952069 5.81490481 6.05980987 6.64097009 7.4047352\n",
      " 7.16168111 7.37088622 7.05721031 6.45274587 6.0088102  6.53635467\n",
      " 5.7086696  7.35849311 6.31712087 7.9693496  6.95387977 6.76216643\n",
      " 7.35627662 8.142516   6.7838486  6.64704511 6.9817385  6.06761409\n",
      " 6.99253819 6.5962778  6.48122944 6.97271084 5.8235516  6.21252832\n",
      " 6.46257252 7.60710787 6.83418414 6.50634005 7.18291302 6.37635382\n",
      " 7.04229725 6.06947833 7.34729435 7.10681949 6.91495962 7.88431756\n",
      " 5.72497028 7.67720447 7.24503972 7.46974105 6.79152005 6.63264104\n",
      " 8.50707815 6.93042991 6.6806217  7.17364732 6.80969245 6.14766809\n",
      " 7.17187494 6.42540233 7.32377796 6.93647785 7.30304074 6.12687361\n",
      " 6.87093826 7.30470755 6.73794121 6.05108877 7.64606374 5.825799\n",
      " 7.20913994 5.97081444 6.22950641 7.02335242 7.06938727 6.68508713\n",
      " 6.910889   7.53904308 7.33275416 6.041834   6.30083521 6.80156434\n",
      " 7.59885614 6.47646737 5.60939883 7.35437154 7.18202017 7.40675013\n",
      " 7.30470755 7.07834006 6.86843306 5.94716639 7.28292117 6.72495961\n",
      " 6.8154156  7.30412548 8.11721683 6.94276751 7.52373833 6.49632906\n",
      " 6.55952984 6.51307007 5.93152765 7.62722664 6.85715428 7.33717786\n",
      " 6.43782965 5.84669828 5.70185599 6.48396043 7.56405994 6.9972554\n",
      " 6.16467886 6.91978074 6.38694214 6.83728222 6.5897966  6.35713801\n",
      " 6.55365073 7.33611765 7.74971131 6.521507   7.01571214 5.99155472\n",
      " 6.89652917 6.79158662 6.86097538 6.48328995 5.62526533 6.49048859\n",
      " 6.82705504 7.31250313 6.92687308 6.62238356 6.43454455 6.69353079\n",
      " 6.80058044 6.13310236 6.74809846 7.62986705 6.84155903 6.34739875\n",
      " 6.35845218 7.09823493 7.05751405 6.53801517 5.87122515 6.96071467\n",
      " 7.0308611  7.22302289 6.91530169 6.09275344 7.50818305 7.2222548\n",
      " 7.34722034 6.83182486 6.94135787 7.52026743 6.86129321 6.11052858\n",
      " 6.93787912 6.04580511 7.40122229 7.52373833 6.77788392 7.30392665\n",
      " 7.25592153 6.74502466 6.72384814 6.63222725 7.37414263 6.68136978\n",
      " 7.20616288 7.73983096 7.58848184 7.62929976 7.54903838 5.96816142\n",
      " 6.46462009 5.97126204 7.04810583 6.40506207 5.88737361 7.4607564\n",
      " 7.20616368 6.75607193 5.67386704 7.74240302 7.24183068 7.04668036\n",
      " 7.96951882 7.44427984 7.01423891]\n"
     ]
    }
   ],
   "source": [
    "predicted_prices = blended_predictions(test)\n",
    "print(predicted_prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "freelance-startup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1426., 1272.,  517.,  872., 1496., 1360.,  722.,  423., 1266.,\n",
       "        350., 2124.,  710., 1597.,  668., 1941., 1033., 1262.,  981.,\n",
       "        753., 2017., 2108.,  681., 1298.,  585., 1023.,  929.,  888.,\n",
       "        717., 1587., 1126.,  457., 1729., 1704.,  936., 1019.,  738.,\n",
       "        692.,  522., 1196.,  264., 1903.,  516.,  642., 2057.,  581.,\n",
       "       1092., 1719.,  258.,  919., 1497., 1521.,  516.,  764., 1280.,\n",
       "        544., 1011.,  258.,  941.,  924.,  872., 1637.,  861.,  438.,\n",
       "        683.,  295., 2017.,  559.,  871., 1060., 2641., 3219.,  972.,\n",
       "        530.,  779.,  334.,  427.,  764., 1642., 1288., 1588., 1160.,\n",
       "        633.,  405.,  688.,  300., 1568.,  552., 2889., 1046.,  863.,\n",
       "       1564., 3436.,  882.,  769., 1075.,  430., 1087.,  731.,  651.,\n",
       "       1066.,  337.,  497.,  639., 2011.,  928.,  668., 1315.,  586.,\n",
       "       1143.,  431., 1550., 1219., 1006., 2654.,  305., 2157., 1400.,\n",
       "       1753.,  889.,  758., 4948., 1021.,  795., 1303.,  905.,  466.,\n",
       "       1301.,  616., 1514., 1028., 1483.,  457.,  962., 1486.,  842.,\n",
       "        423., 2091.,  337., 1350.,  390.,  506., 1121., 1174.,  799.,\n",
       "       1002., 1879., 1528.,  419.,  544.,  898., 1994.,  648.,  271.,\n",
       "       1562., 1314., 1646., 1486., 1184.,  960.,  381., 1454.,  831.,\n",
       "        910., 1485., 3350., 1034., 1850.,  661.,  704.,  672.,  375.,\n",
       "       2052.,  949., 1535.,  624.,  345.,  298.,  653., 1926., 1092.,\n",
       "        474., 1011.,  593.,  930.,  726.,  575.,  700., 1533., 2319.,\n",
       "        678., 1112.,  399.,  987.,  889.,  953.,  653.,  276.,  657.,\n",
       "        921., 1497., 1018.,  750.,  621.,  806.,  897.,  459.,  851.,\n",
       "       2057.,  934.,  570.,  576., 1208., 1160.,  689.,  353., 1053.,\n",
       "       1130., 1369., 1006.,  441., 1821., 1368., 1550.,  925., 1033.,\n",
       "       1844.,  953.,  449., 1029.,  421., 1636., 1850.,  877., 1485.,\n",
       "       1415.,  848.,  831.,  758., 1593.,  796., 1346., 2297., 1974.,\n",
       "       2056., 1897.,  389.,  641.,  391., 1149.,  603.,  359., 1737.,\n",
       "       1346.,  858.,  290., 2303., 1395., 1148., 2890., 1709., 1111.])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor(np.expm1(blended_predictions(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "changed-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = np.floor(np.expm1(blended_predictions(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "assigned-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "MK = pd.DataFrame({'price': submission})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "retained-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "MK.to_csv('김민구_2차.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conditional-radiation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
